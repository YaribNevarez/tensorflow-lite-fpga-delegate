{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbiM6lilQxtQ",
        "outputId": "ede20a3d-6cc7-4d96-c754-cbc1a79a6008"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-02 11:34:17.967183: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-02 11:34:17.967224: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import SeparableConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "google_colab = False\n",
        "if google_colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fh2Y7AaGvoUK"
      },
      "outputs": [],
      "source": [
        "import struct\n",
        "\n",
        "def bin2float(b):\n",
        "    ''' Convert binary string to a float.\n",
        "\n",
        "    Attributes:\n",
        "        :b: Binary string to transform.\n",
        "    '''\n",
        "    h = int(b, 2).to_bytes(8, byteorder=\"big\")\n",
        "    return struct.unpack('>d', h)[0]\n",
        "\n",
        "\n",
        "def float2bin(f):\n",
        "    ''' Convert float to 64-bit binary string.\n",
        "\n",
        "    Attributes:\n",
        "        :f: Float number to transform.\n",
        "    '''\n",
        "    [d] = struct.unpack(\">Q\", struct.pack(\">d\", f))\n",
        "    return f'{d:064b}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7Y8p19yiv2rs"
      },
      "outputs": [],
      "source": [
        "def quantize_float (float_number, mantissa_bits):\n",
        "    if mantissa_bits < 0:\n",
        "      mantissa_bits = 0\n",
        "    coefficient = float2bin(float_number)\n",
        "    sign = int (coefficient[:1], 2)\n",
        "    if 0 < mantissa_bits:\n",
        "        custom_mantissa = int (coefficient[12 : 12 + mantissa_bits], 2)\n",
        "    else:\n",
        "        custom_mantissa = 0\n",
        "    residual_mantissa = int (coefficient[12 + mantissa_bits:], 2)\n",
        "    exponent = int (coefficient[1:12], 2) - 1023\n",
        "    if (pow (2, (52 - (mantissa_bits + 1))) - 1) < residual_mantissa:\n",
        "        custom_mantissa += 1\n",
        "        if (pow (2, mantissa_bits) - 1) < custom_mantissa:\n",
        "            custom_mantissa = 0\n",
        "            exponent += 1\n",
        "    return pow(-1, sign) * (1 + custom_mantissa * pow(2, - mantissa_bits)) * pow(2, exponent)\n",
        "\n",
        "def quantize_model(model, mantissa_bits):\n",
        "  for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "      layer_weight = layer.get_weights()\n",
        "      if len(layer_weight) == 2:\n",
        "        filter_matrix = layer_weight[0]\n",
        "        bias_matrix = layer_weight[1]\n",
        "        if filter_matrix.ndim == 4:\n",
        "          for id_i, i in enumerate(filter_matrix):\n",
        "            for id_j, j in enumerate(i):\n",
        "              for id_k, k in enumerate(j):\n",
        "                for id_l ,l in enumerate(k):\n",
        "                  filter_matrix[id_i][id_j][id_k][id_l] = quantize_float (l, mantissa_bits)\n",
        "                  bias_matrix[id_l] = quantize_float (bias_matrix[id_l], mantissa_bits)\n",
        "        layer_weight[0] = filter_matrix\n",
        "        layer_weight[1] = bias_matrix\n",
        "        layer.set_weights(layer_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IuN7OgXSQ9i2"
      },
      "outputs": [],
      "source": [
        "filename = \"tiny_vgg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vaA7sG9xenUF"
      },
      "outputs": [],
      "source": [
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto', restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mHKtRDtPn0eQ"
      },
      "outputs": [],
      "source": [
        "epoch_count = 0\n",
        "quantize = False\n",
        "mantissa_bits = 2\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    global epoch_count\n",
        "    global quantize\n",
        "    global mantissa_bits\n",
        "    epoch_count += 1\n",
        "    quantize = 1 < epoch_count\n",
        "    if quantize:\n",
        "      quantize_model(self.model, mantissa_bits)\n",
        "      #mantissa_bits -= 1\n",
        "  def on_train_end(self, logs={}):\n",
        "    quantize_model(self.model, mantissa_bits)\n",
        "  def on_batch_end(self, epoch, logs=None):\n",
        "    if quantize:\n",
        "      quantize_model(self.model, mantissa_bits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WPVVK7cLRHlR"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(filename):\n",
        "  os.mkdir(filename)\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "# define cnn model\n",
        "def define_model_CNN():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(40, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(50, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(60, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(60, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(120, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(120, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\t#opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\topt = \"adam\"\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tpyplot.savefig(filename + '/' + filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model_CNN()\n",
        "\t# fit model\n",
        "\thistory = model.fit(trainX, trainY, epochs=20, batch_size=64, validation_data=(testX, testY), verbose=1, callbacks=[MyCallback()])\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\t# Save the entire model to a HDF5 file.\n",
        "\tmodel.save(filename + \"/\" + filename + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsUR8C6RRJVc",
        "outputId": "f4b2312f-ee7b-41d7-8715-6afdbcdb31b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "500/500 [==============================] - 141s 281ms/step - loss: 1.5510 - accuracy: 0.4293 - val_loss: 1.2332 - val_accuracy: 0.5553\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 117s 233ms/step - loss: 1.1706 - accuracy: 0.5779 - val_loss: 1.1161 - val_accuracy: 0.5974\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 118s 237ms/step - loss: 0.9990 - accuracy: 0.6431 - val_loss: 0.9811 - val_accuracy: 0.6558\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 118s 237ms/step - loss: 0.8757 - accuracy: 0.6890 - val_loss: 0.9348 - val_accuracy: 0.6768\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 120s 239ms/step - loss: 0.7931 - accuracy: 0.7204 - val_loss: 0.8942 - val_accuracy: 0.6851\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 118s 235ms/step - loss: 0.7264 - accuracy: 0.7432 - val_loss: 0.8495 - val_accuracy: 0.7103\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 119s 239ms/step - loss: 0.6669 - accuracy: 0.7657 - val_loss: 0.8438 - val_accuracy: 0.7134\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 115s 230ms/step - loss: 0.6068 - accuracy: 0.7855 - val_loss: 0.8353 - val_accuracy: 0.7239\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 98s 196ms/step - loss: 0.5686 - accuracy: 0.7983 - val_loss: 0.8580 - val_accuracy: 0.7192\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 102s 204ms/step - loss: 0.5242 - accuracy: 0.8150 - val_loss: 0.8698 - val_accuracy: 0.7184\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 114s 227ms/step - loss: 0.4939 - accuracy: 0.8251 - val_loss: 0.8649 - val_accuracy: 0.7191\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 0.4518 - accuracy: 0.8394 - val_loss: 0.9586 - val_accuracy: 0.6987\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.4195 - accuracy: 0.8514Restoring model weights from the end of the best epoch.\n",
            "500/500 [==============================] - 84s 169ms/step - loss: 0.4195 - accuracy: 0.8514 - val_loss: 0.8932 - val_accuracy: 0.7336\n",
            "Epoch 00013: early stopping\n",
            "> 72.390\n"
          ]
        }
      ],
      "source": [
        "# entry point, run the test harness\n",
        "# load dataset\n",
        "trainX, trainY, testX, testY = load_dataset()\n",
        "\n",
        "# prepare pixel data\n",
        "trainX, testX = prep_pixels(trainX, testX)\n",
        "\n",
        "# define model\n",
        "model = define_model_CNN()\n",
        "# fit model\n",
        "#history = model.fit(trainX, trainY, epochs=20, batch_size=8, validation_data=(testX, testY), verbose=1, callbacks=[MyCallback(), monitor])\n",
        "history = model.fit(trainX, trainY, epochs=20, batch_size=100, validation_data=(testX, testY), verbose=1, callbacks=[monitor])\n",
        "#history = model.fit(trainX, trainY, epochs=15, batch_size=100, validation_data=(testX, testY), verbose=1, callbacks=[MyCallback()])\n",
        "#history = model.fit(trainX, trainY, epochs=15, batch_size=100, validation_data=(testX, testY), verbose=1)\n",
        "\n",
        "# evaluate model\n",
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))\n",
        "# learning curves\n",
        "summarize_diagnostics(history)\n",
        "# Save the entire model to a HDF5 file.\n",
        "model.save(filename + \"/\" + filename + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "GCLycpCTcGdR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Predicted: [[1.2714170e-03 6.4237749e-05 2.5651827e-01 1.3353398e-01 2.4132918e-01\n",
            "  1.5140045e-01 4.0277380e-02 1.7277840e-01 1.6187595e-03 1.2079814e-03]]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "img_path = \"dog.jpg\"\n",
        "img = image.load_img(img_path, target_size=(32, 32))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x.astype('float32')\n",
        "x = x / 255.0\n",
        "\n",
        "model = load_model(filename + \"/\" + filename + '.h5')\n",
        "\n",
        "output_data = model.predict(x)\n",
        "\n",
        "print('TensorFlow Predicted:', output_data)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_model(model):\n",
        "  for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "      layer_weight = layer.get_weights()\n",
        "      if len(layer_weight) == 2:\n",
        "        filter_matrix = layer_weight[0]\n",
        "        bias_matrix = layer_weight[1]\n",
        "        print (filter_matrix)\n",
        "        print (bias_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[[-0.17313585 -0.4730001   0.09522478 ...  0.221571   -0.36475548\n",
            "    -0.15954335]\n",
            "   [ 0.18617469  0.05973793 -0.2755211  ... -0.19283012  0.39018962\n",
            "     0.25339538]\n",
            "   [ 0.2566992  -0.35420078  0.2826037  ... -0.15302898  0.23398952\n",
            "    -0.2548966 ]]\n",
            "\n",
            "  [[ 0.32719958  0.05793207  0.28410858 ...  0.0903483  -0.42995209\n",
            "     0.30832762]\n",
            "   [ 0.34696755  0.05606928  0.33908302 ... -0.18209797  0.19997977\n",
            "    -0.21564764]\n",
            "   [ 0.2903308   0.16964306 -0.35185635 ... -0.12426452 -0.43748933\n",
            "     0.33033544]]\n",
            "\n",
            "  [[ 0.12616694 -0.29489005  0.03006172 ...  0.27736777  0.09093908\n",
            "    -0.53201765]\n",
            "   [ 0.00667204  0.43232036 -0.20501167 ...  0.2236231   0.41280004\n",
            "     0.32302523]\n",
            "   [ 0.02313158  0.40888655 -0.02568693 ... -0.28755662  0.3731589\n",
            "     0.2263091 ]]]\n",
            "\n",
            "\n",
            " [[[-0.4835316   0.2505895  -0.38957202 ...  0.1448418   0.33771473\n",
            "     0.04717212]\n",
            "   [ 0.09083016  0.42694005 -0.18707928 ...  0.33675405 -0.20298956\n",
            "     0.18005446]\n",
            "   [-0.5130808  -0.3371796   0.37311298 ... -0.37485963 -0.16418576\n",
            "     0.36823353]]\n",
            "\n",
            "  [[-0.18395615  0.07250116  0.2626195  ...  0.30666932 -0.07404272\n",
            "    -0.29268906]\n",
            "   [ 0.08192943  0.15141879  0.31139797 ... -0.12369587  0.38418683\n",
            "     0.02453897]\n",
            "   [-0.24661826 -0.23198158  0.484131   ... -0.33149138 -0.2461608\n",
            "    -0.529006  ]]\n",
            "\n",
            "  [[ 0.03876095 -0.19074035 -0.29491115 ...  0.06415407  0.10844855\n",
            "     0.1346676 ]\n",
            "   [ 0.0898848   0.14584804  0.3954615  ... -0.2734309  -0.06910253\n",
            "     0.36649352]\n",
            "   [-0.09319227 -0.0281483  -0.40349403 ... -0.25737637  0.30976817\n",
            "    -0.30629238]]]\n",
            "\n",
            "\n",
            " [[[ 0.22998971  0.0165803   0.28081816 ...  0.25296584 -0.2963888\n",
            "    -0.10701258]\n",
            "   [-0.24299955  0.01312293 -0.33845878 ... -0.46585178  0.32204413\n",
            "    -0.30475473]\n",
            "   [ 0.09579759 -0.40669212  0.20908736 ...  0.45537975 -0.30360472\n",
            "     0.14047562]]\n",
            "\n",
            "  [[-0.21954355  0.09092914 -0.00483608 ... -0.09464214 -0.1595779\n",
            "     0.40252003]\n",
            "   [-0.25152165  0.12484358 -0.30681044 ... -0.24443258  0.3499939\n",
            "     0.1534411 ]\n",
            "   [ 0.21306877  0.23532473 -0.4290664  ... -0.07849833 -0.4407556\n",
            "     0.15701972]]\n",
            "\n",
            "  [[ 0.09495381 -0.2811134  -0.43384212 ...  0.48282456 -0.25969365\n",
            "     0.1911702 ]\n",
            "   [ 0.39626738  0.24639691  0.42544803 ... -0.36150905 -0.31904212\n",
            "    -0.27135727]\n",
            "   [-0.3645589  -0.27523884  0.00668456 ...  0.27267805  0.18487586\n",
            "    -0.4332518 ]]]]\n",
            "[-0.09619248 -0.0057295  -0.02534803 -0.03879922 -0.01342278 -0.08168904\n",
            " -0.029686   -0.05624326  0.00896199 -0.04661677  0.03762098 -0.00056167\n",
            "  0.00686267 -0.04850934  0.17439008 -0.12654245 -0.1524302  -0.02700883\n",
            "  0.00084635 -0.00670567  0.04245566 -0.05614599 -0.01804494 -0.0986596\n",
            " -0.00957186 -0.00448718 -0.00593191  0.0485248   0.00642037  0.02193674\n",
            " -0.00395956  0.03088947  0.01049848  0.07560853 -0.02555206  0.01462651\n",
            "  0.07138101 -0.01305871  0.01956516 -0.09089921]\n",
            "[[[[-1.72230005e-01  1.02330670e-01 -5.63698225e-02 ...  5.80355637e-02\n",
            "    -9.99008641e-02  5.76724596e-02]\n",
            "   [-1.17939234e-01 -1.60813719e-01  1.32764922e-04 ...  1.32525200e-02\n",
            "     5.92808332e-03  4.82000746e-02]\n",
            "   [-4.54051718e-02 -1.32094666e-01  3.63348424e-02 ...  2.64405347e-02\n",
            "     7.91837424e-02  8.81745294e-02]\n",
            "   ...\n",
            "   [-7.19832722e-03 -1.20556973e-01  4.23964262e-02 ...  1.05436862e-01\n",
            "     5.36697544e-02  1.49275616e-01]\n",
            "   [-1.33127153e-01 -5.69437980e-05 -7.55763650e-02 ...  1.33240283e-01\n",
            "    -1.18940346e-01  2.84333061e-02]\n",
            "   [ 5.27087972e-02  9.82423648e-02 -5.58561012e-02 ... -1.05728261e-01\n",
            "     6.52547032e-02 -1.29340021e-02]]\n",
            "\n",
            "  [[-5.24558760e-02 -1.58483878e-01 -3.61853950e-02 ... -8.30886960e-02\n",
            "    -1.28539011e-01 -9.27549507e-03]\n",
            "   [-1.20668262e-01 -8.22832957e-02 -7.39374310e-02 ... -2.89850850e-02\n",
            "     1.49275502e-02  1.37258962e-01]\n",
            "   [-1.22577436e-01  6.42768815e-02 -1.45496160e-01 ... -2.92465964e-04\n",
            "    -1.38551667e-01 -6.54217750e-02]\n",
            "   ...\n",
            "   [-6.94924593e-02  1.07669674e-01 -2.93394318e-03 ...  2.30906755e-01\n",
            "    -4.23375145e-03  9.96201113e-02]\n",
            "   [-4.34599519e-02 -6.39542565e-02 -2.14344993e-01 ...  2.28770133e-02\n",
            "     6.75888360e-02 -5.20676561e-02]\n",
            "   [-8.14834237e-02  9.68406126e-02  7.02964589e-02 ... -7.19192252e-02\n",
            "    -1.46160023e-02  1.12958103e-01]]\n",
            "\n",
            "  [[ 3.36115211e-02  2.48386543e-02  2.53584646e-02 ... -5.18625937e-02\n",
            "    -6.76627979e-02  1.39409438e-01]\n",
            "   [ 1.38132405e-02 -8.41060579e-02 -5.82495108e-02 ...  3.68946902e-02\n",
            "    -2.29705051e-02 -5.62930554e-02]\n",
            "   [-1.66280940e-01 -7.63037279e-02 -9.61759165e-02 ...  1.07246891e-01\n",
            "    -3.79579887e-02  4.50767167e-02]\n",
            "   ...\n",
            "   [ 6.10887073e-03 -5.58533880e-04 -4.47068103e-02 ...  2.49355942e-01\n",
            "     1.82084739e-02  1.10859595e-01]\n",
            "   [-1.07146874e-01 -1.18747018e-01 -5.48721068e-02 ...  5.70937730e-02\n",
            "    -3.43916006e-02 -1.14311814e-01]\n",
            "   [-1.30575582e-01 -1.29701808e-01 -7.53619708e-03 ...  7.04681501e-02\n",
            "     1.02141172e-01  2.12487648e-03]]]\n",
            "\n",
            "\n",
            " [[[-1.29978582e-01  3.58937797e-03  5.16719930e-03 ...  5.42826811e-03\n",
            "    -1.58514693e-01  1.61456004e-01]\n",
            "   [-3.90535295e-02 -4.44508418e-02  1.08911134e-01 ... -9.42601487e-02\n",
            "     8.23666230e-02  3.68765965e-02]\n",
            "   [ 1.22334920e-01 -1.79665074e-01  1.12662554e-01 ... -5.20734116e-02\n",
            "    -1.86021328e-01  2.13543132e-01]\n",
            "   ...\n",
            "   [ 7.99546838e-02 -5.17549068e-02 -5.25489450e-02 ... -2.36557014e-02\n",
            "    -1.63304023e-02 -3.09569761e-02]\n",
            "   [-2.15658471e-01 -1.35738209e-01 -8.92924368e-02 ... -1.21122867e-01\n",
            "    -4.16554734e-02 -7.95319118e-03]\n",
            "   [-2.69027203e-02 -9.35639739e-02  1.17182329e-01 ... -4.64858226e-02\n",
            "    -7.17195272e-02  9.93879661e-02]]\n",
            "\n",
            "  [[-1.57738507e-01  3.50049995e-02  7.20005184e-02 ...  1.01454377e-01\n",
            "    -1.49645098e-02  1.05275899e-01]\n",
            "   [ 7.07604736e-02 -1.21924751e-01  2.60821041e-02 ... -7.50769302e-02\n",
            "    -7.87772983e-02  1.11285701e-01]\n",
            "   [-9.11293030e-02  6.92842528e-02 -1.05710082e-01 ... -6.11742027e-02\n",
            "     6.07244037e-02  5.49908690e-02]\n",
            "   ...\n",
            "   [-9.73631889e-02 -1.46693569e-02 -1.42412379e-01 ...  1.12273633e-01\n",
            "    -1.76908702e-01  1.57979112e-02]\n",
            "   [ 5.62016293e-02 -1.89049214e-01 -2.35918034e-02 ...  6.98793679e-02\n",
            "    -1.90556294e-03  1.18821412e-01]\n",
            "   [-2.67571118e-02 -4.21823561e-02  1.17310144e-01 ... -1.00516699e-01\n",
            "    -1.54021606e-01  1.18006669e-01]]\n",
            "\n",
            "  [[-1.47441849e-02 -5.74500486e-02  8.29425901e-02 ...  1.57125488e-01\n",
            "     8.55755061e-02  1.19533159e-01]\n",
            "   [-1.37641639e-01 -1.41487584e-01 -2.62290165e-02 ... -1.24372907e-01\n",
            "     2.67294585e-03  4.89480011e-02]\n",
            "   [-6.87434599e-02  9.09277052e-03 -1.04528321e-02 ...  1.13598309e-01\n",
            "     5.94180264e-02 -1.73369274e-02]\n",
            "   ...\n",
            "   [-1.50643632e-01  1.38946921e-01 -5.70790991e-02 ...  1.02537513e-01\n",
            "    -1.28341183e-01 -6.76543787e-02]\n",
            "   [-2.40325951e-03 -7.91767389e-02 -7.81917050e-02 ...  7.85145387e-02\n",
            "    -1.35187805e-01  1.31973520e-01]\n",
            "   [ 9.18656513e-02 -3.85761112e-02  3.46928090e-02 ... -1.03074037e-01\n",
            "     2.35647596e-02 -2.48089433e-02]]]\n",
            "\n",
            "\n",
            " [[[ 7.85760880e-02  2.30477974e-02 -6.31630793e-02 ... -1.12897843e-01\n",
            "    -1.08146286e-02  7.85911828e-02]\n",
            "   [ 7.81505480e-02  5.62450616e-03  3.26939449e-02 ...  3.48531790e-02\n",
            "    -8.35218467e-03 -2.02926435e-03]\n",
            "   [ 7.89213106e-02 -1.50019154e-01 -1.14137366e-01 ... -4.33867313e-02\n",
            "    -2.30812579e-02 -7.30154961e-02]\n",
            "   ...\n",
            "   [-5.60473054e-05 -2.02841640e-01  9.02243406e-02 ...  6.84976801e-02\n",
            "    -1.34133264e-01  6.03139624e-02]\n",
            "   [-7.43438583e-03 -2.72534620e-02  1.83513001e-01 ... -2.22276133e-02\n",
            "     1.82823762e-01  1.79157078e-01]\n",
            "   [ 3.38345468e-02 -5.67942746e-02 -2.06388123e-02 ... -9.14623737e-02\n",
            "    -9.96955559e-02 -2.52796453e-03]]\n",
            "\n",
            "  [[ 1.23337181e-02  1.54243559e-01  1.62677541e-01 ... -1.40777305e-01\n",
            "     6.66239634e-02  1.27020657e-01]\n",
            "   [ 1.03153229e-01  7.73131400e-02  3.15117761e-02 ... -3.82045377e-03\n",
            "     3.98440547e-02 -6.55794516e-02]\n",
            "   [-1.76218912e-01 -9.59637314e-02 -1.27564952e-01 ...  1.09425135e-01\n",
            "    -3.84321846e-02  1.92700893e-01]\n",
            "   ...\n",
            "   [-1.47416160e-01 -4.84679528e-02  3.34021337e-02 ...  7.54638314e-02\n",
            "    -5.76365776e-02  2.15769950e-02]\n",
            "   [ 9.17254761e-02 -2.21377030e-01  1.56389102e-01 ...  8.71819705e-02\n",
            "    -4.58562262e-02  1.25947446e-01]\n",
            "   [-2.56910659e-02 -3.57673876e-02  7.99092874e-02 ...  3.80140208e-02\n",
            "    -1.54397950e-01 -3.69370952e-02]]\n",
            "\n",
            "  [[ 1.17655344e-01  1.12027852e-02  1.00263871e-01 ...  2.90970169e-02\n",
            "     2.14446299e-02  1.00965612e-01]\n",
            "   [-5.27560189e-02 -9.74982902e-02 -5.01203798e-02 ... -1.15192542e-02\n",
            "     6.69821799e-02  1.00576125e-01]\n",
            "   [-2.95348968e-02  1.80572812e-02 -9.52337980e-02 ...  4.22801226e-02\n",
            "    -3.06708608e-02 -7.25243986e-02]\n",
            "   ...\n",
            "   [-1.99036911e-01  2.73460262e-02 -1.29715400e-02 ... -1.02258265e-01\n",
            "    -9.89353359e-02 -1.38391620e-02]\n",
            "   [-1.09687187e-01 -1.79401770e-01  1.09471001e-01 ...  8.22144561e-03\n",
            "     5.01818396e-02  4.34358530e-02]\n",
            "   [ 4.39956374e-02  4.50904220e-02 -5.72149120e-02 ...  5.44364974e-02\n",
            "    -1.18636802e-01  8.43778327e-02]]]]\n",
            "[ 2.44903080e-02  2.30208598e-02  8.67353231e-02  1.10444002e-01\n",
            " -1.09161168e-01  3.96250654e-03 -5.89653738e-02 -8.19967035e-03\n",
            " -6.65078908e-02 -1.27034681e-02 -3.05252732e-04  1.24838516e-01\n",
            " -4.12752368e-02  1.40297189e-02  3.03017441e-02  9.13297832e-02\n",
            "  1.67532489e-02 -2.41428968e-02  1.13235876e-01  1.00299835e-01\n",
            "  6.89151064e-02  1.53847905e-02  2.94452906e-02  1.42047226e-01\n",
            " -3.47327627e-03 -5.64723499e-02 -9.11094695e-02  1.47909927e-03\n",
            "  3.57761644e-02  3.06065883e-02  1.56422541e-01 -4.28449810e-02\n",
            "  1.06360270e-02  1.38096223e-02  7.57250190e-02  2.32571345e-02\n",
            " -7.51951593e-05 -4.33317088e-02  2.65940791e-03 -5.56760803e-02\n",
            " -1.80104712e-03  2.31268350e-02 -3.63449520e-03 -4.30538952e-02\n",
            "  4.62599583e-02  6.39251024e-02  4.94009291e-04 -6.48484826e-02\n",
            "  9.01837926e-03 -6.14991784e-02]\n",
            "[[[[-2.73235375e-03  3.15096043e-02 -1.46546721e-01 ...  1.51285008e-01\n",
            "    -1.87647995e-02 -7.34145343e-02]\n",
            "   [ 8.06893408e-03  7.84998946e-03 -1.18016534e-01 ... -9.94132608e-02\n",
            "    -1.21973954e-01  1.03498287e-01]\n",
            "   [ 5.58289886e-02 -3.49327438e-02  1.03629340e-04 ... -9.41811949e-02\n",
            "    -2.21644081e-02 -1.07010841e-01]\n",
            "   ...\n",
            "   [ 1.12451777e-01  8.92729089e-02 -4.83785123e-02 ...  6.36789426e-02\n",
            "    -1.02245092e-01  1.11833729e-01]\n",
            "   [ 1.85347199e-01 -4.87964004e-02  1.16168372e-01 ...  8.87173638e-02\n",
            "     1.40928447e-01  1.42723201e-02]\n",
            "   [-4.26282734e-02  1.58502504e-01 -5.59767149e-02 ...  1.44977309e-02\n",
            "    -9.53258276e-02 -1.21211410e-02]]\n",
            "\n",
            "  [[-7.78854564e-02  8.57980549e-03 -8.12188163e-02 ...  4.93686423e-02\n",
            "    -5.90833351e-02  4.08451296e-02]\n",
            "   [ 5.68564273e-02  1.85589731e-01 -7.57147074e-02 ... -8.14097151e-02\n",
            "     5.88573925e-02  2.13486496e-02]\n",
            "   [ 5.91796637e-02 -6.71306327e-02 -2.64864806e-02 ... -5.67995831e-02\n",
            "     3.82247493e-02  1.77980047e-02]\n",
            "   ...\n",
            "   [ 4.65802178e-02 -1.64512724e-01  6.78150728e-03 ... -3.02184410e-02\n",
            "    -8.92234668e-02 -8.33945535e-03]\n",
            "   [-7.75463581e-02  9.75153148e-02  1.07416146e-01 ... -1.02777645e-01\n",
            "     7.03052804e-02  1.07845552e-01]\n",
            "   [-1.53637558e-01  6.05463833e-02  1.47755938e-02 ...  1.26876207e-02\n",
            "    -2.04927191e-01 -1.26174569e-01]]\n",
            "\n",
            "  [[-1.59670457e-01 -1.31131634e-01 -6.87587634e-02 ... -1.04794897e-01\n",
            "    -9.99275669e-02 -1.12821804e-02]\n",
            "   [-8.40584412e-02 -9.62154120e-02 -9.65137631e-02 ... -1.13437273e-01\n",
            "    -2.11315915e-01  2.06834283e-02]\n",
            "   [ 1.97233111e-01 -1.28108293e-01  5.02239838e-02 ... -1.00105755e-01\n",
            "    -4.98741120e-02  7.23503670e-03]\n",
            "   ...\n",
            "   [-5.83287254e-02 -1.72380969e-01 -1.64279416e-02 ... -1.65302381e-01\n",
            "    -2.14005604e-01  7.37220868e-02]\n",
            "   [-1.37935519e-01 -9.38136876e-02 -6.06821366e-02 ... -3.65184434e-03\n",
            "     2.30386090e-02  7.16149658e-02]\n",
            "   [ 7.96273351e-02 -3.07804886e-02 -9.57456976e-02 ... -7.91338533e-02\n",
            "    -1.82792604e-01  1.24461271e-01]]]\n",
            "\n",
            "\n",
            " [[[-5.69679178e-02  4.79998300e-03 -4.30960134e-02 ...  1.17047541e-02\n",
            "    -7.41362514e-04 -5.10047488e-02]\n",
            "   [-2.14319170e-01  1.32523931e-03 -1.43049071e-02 ...  6.05025999e-02\n",
            "     1.57769516e-01 -8.57216865e-02]\n",
            "   [-6.06180429e-02  1.17521748e-01  2.23424826e-02 ...  2.24412978e-01\n",
            "     8.09724722e-03  4.16228212e-02]\n",
            "   ...\n",
            "   [-4.75032032e-02 -5.19822426e-02  1.34352416e-01 ... -5.84941208e-02\n",
            "     7.09743984e-03  1.25161126e-01]\n",
            "   [ 4.76640090e-03  5.63867739e-04 -4.96238656e-02 ...  1.38308611e-02\n",
            "    -3.52396704e-02  1.73486192e-02]\n",
            "   [ 1.20934010e-01  4.57846858e-02  9.65281650e-02 ...  4.42221761e-02\n",
            "    -4.72660549e-02  8.01990405e-02]]\n",
            "\n",
            "  [[-2.46586323e-01  1.88838035e-01 -1.20131493e-01 ... -5.42363636e-02\n",
            "     7.56472126e-02 -1.78082198e-01]\n",
            "   [-2.12490670e-02  2.21394617e-02 -1.45933107e-01 ... -9.21426490e-02\n",
            "    -7.31809735e-02 -4.00630198e-02]\n",
            "   [ 7.42153171e-03 -4.74938229e-02 -1.07011929e-01 ...  1.26569663e-04\n",
            "    -3.77499051e-02 -8.85689817e-03]\n",
            "   ...\n",
            "   [ 5.29299788e-02 -5.09385876e-02  7.34121054e-02 ... -2.27487348e-02\n",
            "    -1.40306458e-01 -3.67973819e-02]\n",
            "   [-1.46210358e-01  1.56451479e-01 -6.85242862e-02 ... -1.04276098e-01\n",
            "     8.53691250e-02 -5.97798079e-02]\n",
            "   [-7.11504295e-02  3.33221965e-02  3.85510884e-02 ... -8.09685811e-02\n",
            "     5.51072210e-02  3.72669548e-02]]\n",
            "\n",
            "  [[-5.61517924e-02  1.12935297e-01 -1.35861889e-01 ... -7.59979757e-03\n",
            "    -3.62818688e-02 -1.89588163e-02]\n",
            "   [-1.59698009e-01  2.66284198e-02 -1.18556499e-01 ... -1.18006378e-01\n",
            "    -1.53175756e-01 -1.36903882e-01]\n",
            "   [ 1.02165408e-01  3.93444076e-02  2.18861308e-02 ... -2.76013389e-02\n",
            "     3.18869539e-02  2.38967892e-02]\n",
            "   ...\n",
            "   [-1.24304339e-01 -1.57894596e-01 -1.85518358e-02 ...  7.89791942e-02\n",
            "    -2.06128776e-01 -8.64871517e-02]\n",
            "   [-1.25064269e-01 -5.28348843e-03 -5.23631945e-02 ... -3.43131013e-02\n",
            "     1.00621469e-01 -8.94046426e-02]\n",
            "   [-1.05830617e-01  3.71343344e-02  1.13999404e-01 ...  1.55085679e-02\n",
            "    -3.99319120e-02 -4.33138013e-02]]]\n",
            "\n",
            "\n",
            " [[[ 1.78530589e-01 -1.10782392e-01 -4.40646261e-02 ...  1.41423285e-01\n",
            "    -4.15703543e-02  1.32625878e-01]\n",
            "   [ 2.08704397e-02 -1.40296414e-01  2.36581024e-02 ...  1.82645004e-02\n",
            "    -2.07516551e-02 -4.55165654e-02]\n",
            "   [-4.49770056e-02 -3.03374305e-02  3.65807265e-02 ... -2.53711455e-02\n",
            "     6.62102774e-02 -5.84893897e-02]\n",
            "   ...\n",
            "   [ 6.39362633e-02 -5.28079681e-02 -4.28172089e-02 ... -1.26494735e-01\n",
            "    -1.22364447e-01 -1.09162014e-02]\n",
            "   [-1.04735889e-01  1.00778215e-01  6.23044521e-02 ...  1.57972232e-01\n",
            "    -3.61684710e-02  8.61482322e-03]\n",
            "   [ 1.15449160e-01 -3.33872736e-02  3.43059897e-02 ...  8.03442970e-02\n",
            "    -3.88812199e-02  8.12071338e-02]]\n",
            "\n",
            "  [[-2.70692199e-01 -2.44214639e-01 -1.27077652e-02 ...  4.54082480e-03\n",
            "    -2.73553226e-02 -2.11324287e-03]\n",
            "   [-1.94598198e-01 -2.09417641e-01  8.09822232e-05 ...  1.03962153e-01\n",
            "    -1.10087372e-01 -1.36437073e-01]\n",
            "   [ 5.57744652e-02  1.94977783e-02  9.05004218e-02 ... -1.59574434e-01\n",
            "     5.79867102e-02  5.85352592e-02]\n",
            "   ...\n",
            "   [-2.59292102e-03 -1.18809836e-02 -5.36648557e-02 ...  5.40810712e-02\n",
            "     2.54428536e-02  9.18451920e-02]\n",
            "   [-2.25491092e-01 -1.81657210e-01  5.59040643e-02 ...  2.26674788e-02\n",
            "    -9.46592465e-02 -2.26873644e-02]\n",
            "   [-3.29514295e-02 -1.43705368e-01  7.07565099e-02 ...  7.83173889e-02\n",
            "    -6.81696087e-03  1.32486820e-01]]\n",
            "\n",
            "  [[ 2.52936445e-02 -2.27913350e-01 -7.04910383e-02 ... -1.05998274e-02\n",
            "    -1.38594583e-01 -1.40297264e-01]\n",
            "   [ 1.94076970e-02 -3.04716796e-01 -2.11064845e-01 ...  1.52736261e-01\n",
            "    -1.44130275e-01  8.61741528e-02]\n",
            "   [ 1.22182027e-01  8.18455499e-03 -5.79714701e-02 ... -1.00802831e-01\n",
            "    -1.01076424e-01  4.61379141e-02]\n",
            "   ...\n",
            "   [-1.30978525e-01 -2.31017902e-01  4.93968651e-02 ... -4.86708395e-02\n",
            "    -1.22467138e-01  6.54795691e-02]\n",
            "   [-1.04819767e-01 -1.58300862e-01 -1.16256505e-01 ...  9.47462320e-02\n",
            "     5.07675409e-02  2.45330986e-02]\n",
            "   [-1.72618777e-01  1.21728338e-01 -5.66423424e-02 ... -9.57188830e-02\n",
            "     1.48970321e-01 -6.02831207e-02]]]]\n",
            "[ 0.05696588  0.09206165 -0.01546692  0.12455417  0.04764815  0.15154015\n",
            "  0.18465734  0.02489823  0.02803654 -0.01313527 -0.08533719 -0.01248471\n",
            " -0.01304089 -0.0406165   0.05051773 -0.0834532   0.04446953  0.117498\n",
            " -0.05817005 -0.1273653   0.08510329  0.04214083 -0.01168292  0.10976753\n",
            "  0.07848032 -0.05299065 -0.02410709  0.14142402  0.06154201  0.01507732\n",
            "  0.08901926 -0.02824978 -0.00749698  0.02893149 -0.06036338  0.05248588\n",
            " -0.03795034  0.02008567  0.08658316 -0.13826904  0.05766305  0.08913559\n",
            "  0.1252307   0.10037155  0.05545817  0.0622394   0.07621016 -0.05441147\n",
            "  0.02262936  0.14593767  0.04470608 -0.08097628 -0.05265811  0.01440782\n",
            "  0.00826985 -0.07736683  0.00245863  0.04172532  0.11983614  0.00131675]\n",
            "[[[[ 0.01949629 -0.06041697 -0.2921546  ... -0.26577696 -0.0750791\n",
            "     0.05676202]\n",
            "   [-0.10967763  0.02656164 -0.0823805  ...  0.04729043 -0.06990065\n",
            "    -0.03903495]\n",
            "   [ 0.04639316  0.00864717 -0.091135   ...  0.01173517  0.07871285\n",
            "     0.10814922]\n",
            "   ...\n",
            "   [ 0.22320822 -0.14094594  0.00844948 ... -0.09442218 -0.06291809\n",
            "    -0.00392197]\n",
            "   [-0.1589148  -0.11541693 -0.03577978 ...  0.01782899 -0.10909345\n",
            "     0.20187365]\n",
            "   [ 0.08303564 -0.07489439 -0.09195053 ...  0.07276155  0.04690158\n",
            "     0.10995524]]\n",
            "\n",
            "  [[-0.10803239  0.09272484 -0.22597252 ... -0.23452139 -0.28243968\n",
            "     0.27293438]\n",
            "   [-0.10886071  0.08631235 -0.1993231  ...  0.0774729  -0.00428667\n",
            "    -0.09223095]\n",
            "   [-0.01179994  0.04149269 -0.13273312 ... -0.02425553 -0.07808641\n",
            "     0.03713165]\n",
            "   ...\n",
            "   [-0.03349054  0.0923234   0.14261734 ... -0.01160494  0.13969879\n",
            "    -0.021001  ]\n",
            "   [-0.07160176  0.05831287  0.0025961  ...  0.05938799  0.09597522\n",
            "     0.01402258]\n",
            "   [-0.10947326 -0.01994853 -0.05658212 ... -0.07039446 -0.02520583\n",
            "     0.15390825]]\n",
            "\n",
            "  [[-0.04883329  0.06905585 -0.11120581 ... -0.15545018  0.00422299\n",
            "     0.03388994]\n",
            "   [ 0.12221455 -0.10998514  0.1216871  ...  0.02635223  0.19736198\n",
            "    -0.18177965]\n",
            "   [ 0.1103046  -0.00299798 -0.08194349 ... -0.00680252  0.09615536\n",
            "    -0.07532563]\n",
            "   ...\n",
            "   [ 0.09998891  0.22017406 -0.04143816 ... -0.02601195 -0.11779992\n",
            "     0.08082063]\n",
            "   [-0.06916748 -0.00222535  0.04066215 ...  0.02284748 -0.04947088\n",
            "     0.11755343]\n",
            "   [-0.06661632  0.05926657 -0.03702491 ...  0.01631513  0.15331388\n",
            "     0.09937599]]]\n",
            "\n",
            "\n",
            " [[[ 0.07998661  0.10707628 -0.10652301 ...  0.12430564 -0.16551514\n",
            "     0.02136503]\n",
            "   [-0.04308918  0.01667525 -0.03825807 ... -0.08098277 -0.12240642\n",
            "     0.20090485]\n",
            "   [ 0.02679203 -0.08516861 -0.16272305 ...  0.02177284  0.17240964\n",
            "     0.01918905]\n",
            "   ...\n",
            "   [-0.09274537  0.12450399 -0.07181688 ...  0.10852056  0.12138219\n",
            "     0.14431982]\n",
            "   [ 0.12673888 -0.06963401 -0.10702464 ...  0.06086959  0.11402799\n",
            "     0.05713689]\n",
            "   [-0.06686688 -0.12520999 -0.09544248 ...  0.09008961  0.14378132\n",
            "    -0.07299176]]\n",
            "\n",
            "  [[-0.01329962 -0.04446572 -0.13580975 ... -0.18660788 -0.03681802\n",
            "     0.07947695]\n",
            "   [-0.06784884 -0.04521649 -0.05220323 ...  0.0383912   0.03783021\n",
            "    -0.043139  ]\n",
            "   [-0.09916401 -0.10924049 -0.15798205 ...  0.10328603  0.03855358\n",
            "     0.03792573]\n",
            "   ...\n",
            "   [-0.06086019  0.07155073 -0.0504421  ...  0.06336327  0.16225666\n",
            "    -0.00295013]\n",
            "   [-0.00467415 -0.01680518 -0.14509574 ...  0.03121727  0.01389134\n",
            "    -0.11180357]\n",
            "   [-0.0620796  -0.1075437  -0.03365506 ...  0.02522503 -0.02641783\n",
            "     0.11943172]]\n",
            "\n",
            "  [[ 0.0655385   0.19919421  0.11272977 ...  0.04839226 -0.02500104\n",
            "     0.0697989 ]\n",
            "   [ 0.09560988 -0.18054266  0.01530937 ...  0.2065652  -0.09495492\n",
            "    -0.04250263]\n",
            "   [-0.09280524  0.01903614 -0.08050256 ...  0.05295214  0.02196229\n",
            "     0.16011047]\n",
            "   ...\n",
            "   [ 0.05433768  0.03363265  0.05838557 ...  0.14501482 -0.00492567\n",
            "     0.05168219]\n",
            "   [ 0.04502421  0.06165997 -0.04051824 ... -0.00518686  0.13477565\n",
            "    -0.15703866]\n",
            "   [-0.07237135  0.07944311 -0.01403755 ... -0.03435266  0.05748148\n",
            "    -0.07237026]]]\n",
            "\n",
            "\n",
            " [[[ 0.14739594 -0.04727037  0.0881945  ...  0.09273544  0.04735135\n",
            "    -0.08163701]\n",
            "   [-0.06063478 -0.3491383  -0.13053657 ... -0.07906841 -0.09585476\n",
            "    -0.00293309]\n",
            "   [ 0.06454702  0.07052109 -0.1474853  ...  0.08948112 -0.10182726\n",
            "    -0.17253305]\n",
            "   ...\n",
            "   [-0.12619546  0.01560047  0.06746937 ...  0.20449884  0.090155\n",
            "    -0.18594994]\n",
            "   [ 0.09882097  0.12947512 -0.05351214 ...  0.0996469  -0.06797969\n",
            "     0.0722613 ]\n",
            "   [ 0.17162454 -0.11591943 -0.00632954 ... -0.04126625 -0.14608544\n",
            "    -0.06687746]]\n",
            "\n",
            "  [[ 0.03036498  0.03921831  0.1579179  ... -0.05258279 -0.20870528\n",
            "     0.05551703]\n",
            "   [-0.07661968  0.01610288 -0.01344235 ... -0.05581213 -0.03987493\n",
            "     0.03670111]\n",
            "   [-0.061327   -0.06808653  0.14343077 ...  0.02712151 -0.1278348\n",
            "    -0.0985123 ]\n",
            "   ...\n",
            "   [ 0.00557847  0.14674167 -0.09110706 ... -0.1011987   0.1239817\n",
            "    -0.11631245]\n",
            "   [-0.05406377 -0.03634372 -0.1435325  ...  0.07278655 -0.02473282\n",
            "    -0.01819534]\n",
            "   [ 0.18254606 -0.03119161  0.00526612 ... -0.05945772 -0.0891015\n",
            "     0.0845383 ]]\n",
            "\n",
            "  [[-0.02627263  0.01200962 -0.04976721 ...  0.01589007 -0.02779641\n",
            "     0.06429526]\n",
            "   [ 0.02539581  0.09863269 -0.05637059 ... -0.03824772 -0.06020845\n",
            "     0.02590975]\n",
            "   [ 0.0247922   0.07806018  0.00919718 ... -0.06953561 -0.0908234\n",
            "    -0.05154112]\n",
            "   ...\n",
            "   [-0.05676027  0.07162052 -0.15203217 ... -0.16505806  0.22230154\n",
            "     0.17712511]\n",
            "   [ 0.07983006  0.05667636  0.03688714 ... -0.08280437 -0.00119229\n",
            "    -0.16899282]\n",
            "   [ 0.02363488 -0.01812506  0.0432857  ...  0.06445552 -0.13127999\n",
            "     0.14075333]]]]\n",
            "[-0.02729951 -0.00232206  0.08870092  0.14185944 -0.01697646 -0.0046893\n",
            " -0.01925724  0.00564025  0.11138529 -0.06853389 -0.04219909  0.03057414\n",
            "  0.17468189 -0.0287668   0.02406204  0.04753181 -0.04040635 -0.01284595\n",
            "  0.10615338  0.01831235 -0.03265461  0.01006413  0.13889813 -0.02647846\n",
            "  0.01227135  0.05645254  0.03062544  0.04721924 -0.00360845  0.07565071\n",
            " -0.00488763  0.07485229  0.06128519 -0.04784004 -0.10778911  0.00425423\n",
            "  0.07696079  0.02599075  0.11153524 -0.01692996  0.05644796  0.0433332\n",
            "  0.08950119  0.01295854  0.0522878   0.10716449 -0.00511685 -0.05197734\n",
            "  0.03085999 -0.02457595 -0.0152375   0.09826581  0.08728585  0.03623317\n",
            "  0.04901605 -0.0009372  -0.01273687  0.04160061 -0.04398817  0.0968102 ]\n",
            "[[[[ 0.07223675  0.02837864  0.1153767  ... -0.05087348 -0.01902871\n",
            "    -0.05028126]\n",
            "   [-0.05706849  0.08796952 -0.04323442 ...  0.07124501 -0.05538259\n",
            "    -0.10626296]\n",
            "   [-0.1653077   0.02366353 -0.06117883 ... -0.03623525  0.10496759\n",
            "    -0.12417751]\n",
            "   ...\n",
            "   [ 0.06738287  0.07485282  0.00974666 ... -0.04868022 -0.14390948\n",
            "    -0.09898482]\n",
            "   [-0.12947421  0.01752953 -0.11213323 ...  0.05173234 -0.09550177\n",
            "    -0.01166277]\n",
            "   [-0.12732062  0.0121291   0.03096639 ...  0.06639791 -0.02803699\n",
            "    -0.0932887 ]]\n",
            "\n",
            "  [[ 0.07977069  0.14254871  0.01441221 ...  0.00923546  0.09689924\n",
            "    -0.06799988]\n",
            "   [ 0.09781811 -0.09714726  0.03208226 ...  0.06087907  0.1046818\n",
            "    -0.05030508]\n",
            "   [ 0.00154413 -0.01338748  0.08391588 ...  0.04609627  0.07068881\n",
            "    -0.02058807]\n",
            "   ...\n",
            "   [ 0.07802525  0.09491805 -0.1095023  ... -0.00643114  0.04780903\n",
            "    -0.08696666]\n",
            "   [-0.05065717 -0.02387705  0.03819181 ... -0.05456546  0.06640183\n",
            "     0.11396994]\n",
            "   [ 0.03197542  0.02180601 -0.02980904 ...  0.12083033  0.12836681\n",
            "     0.03651119]]\n",
            "\n",
            "  [[ 0.08845332 -0.03825118 -0.04962709 ...  0.04126855  0.06915218\n",
            "    -0.02327719]\n",
            "   [ 0.02619687 -0.07722761  0.02012311 ... -0.07680847  0.17736687\n",
            "     0.10425835]\n",
            "   [ 0.15661602  0.02035128 -0.15623026 ...  0.1647453   0.11168084\n",
            "     0.09105355]\n",
            "   ...\n",
            "   [ 0.13216178 -0.13987516  0.08355587 ...  0.13488615  0.09084668\n",
            "     0.01213678]\n",
            "   [ 0.05383946 -0.08531676  0.05029675 ...  0.02778202 -0.01516063\n",
            "    -0.01473423]\n",
            "   [-0.04040907  0.01331928 -0.1436475  ...  0.06286614  0.16992633\n",
            "     0.00512829]]]\n",
            "\n",
            "\n",
            " [[[ 0.14764735 -0.10818252 -0.13403061 ... -0.00935971  0.01023018\n",
            "    -0.0807167 ]\n",
            "   [-0.18455566 -0.09662193 -0.0465115  ...  0.07227705  0.0761198\n",
            "     0.08585712]\n",
            "   [-0.00547942  0.00600677  0.06575866 ... -0.07900857 -0.0842835\n",
            "    -0.07448858]\n",
            "   ...\n",
            "   [-0.15235922  0.15087268 -0.04454658 ...  0.0944171   0.07780969\n",
            "     0.01010637]\n",
            "   [-0.04591744  0.1255879   0.12168055 ...  0.05097204 -0.05992121\n",
            "     0.00665094]\n",
            "   [-0.1015328   0.03396624  0.0630745  ...  0.07067619  0.07338809\n",
            "    -0.12575   ]]\n",
            "\n",
            "  [[ 0.08313052  0.00679257 -0.02021414 ...  0.09678572 -0.12754773\n",
            "    -0.16951102]\n",
            "   [ 0.10234272  0.12862055 -0.0821075  ... -0.02791398 -0.08603207\n",
            "     0.05246558]\n",
            "   [ 0.00570429 -0.15493837 -0.12134579 ... -0.13568078  0.14148824\n",
            "     0.12238459]\n",
            "   ...\n",
            "   [-0.0463214   0.16144119  0.10714798 ... -0.10280265  0.08249405\n",
            "     0.08757728]\n",
            "   [ 0.09235562 -0.05243998 -0.05979585 ... -0.10455732 -0.1185927\n",
            "    -0.04803757]\n",
            "   [-0.06642883  0.03614242 -0.08950023 ... -0.14369433 -0.03628096\n",
            "     0.07502115]]\n",
            "\n",
            "  [[ 0.06796153 -0.09476355 -0.04253734 ... -0.060933   -0.15213832\n",
            "    -0.10155452]\n",
            "   [-0.23479012 -0.10153855  0.0303826  ... -0.1132734   0.02183507\n",
            "     0.10604142]\n",
            "   [ 0.11650123  0.01548587 -0.01037654 ...  0.13754483  0.07046525\n",
            "     0.00388515]\n",
            "   ...\n",
            "   [-0.11285485 -0.0865579   0.01281511 ... -0.05350374 -0.05658798\n",
            "     0.12466978]\n",
            "   [ 0.12927845 -0.14276353 -0.01694826 ...  0.11359542 -0.07178061\n",
            "     0.06821671]\n",
            "   [ 0.07180797  0.00370803 -0.07522183 ... -0.06978407 -0.08726782\n",
            "     0.17004542]]]\n",
            "\n",
            "\n",
            " [[[-0.08449883 -0.16259694  0.06023185 ...  0.05514124 -0.14358465\n",
            "     0.00172471]\n",
            "   [-0.11473304  0.08106862  0.04380384 ... -0.06953643 -0.05324492\n",
            "     0.08739766]\n",
            "   [-0.06454253  0.13818105 -0.0654012  ...  0.06420285 -0.16138983\n",
            "     0.0514124 ]\n",
            "   ...\n",
            "   [-0.11572462 -0.00199283 -0.21281292 ...  0.02230608 -0.14549682\n",
            "     0.10348699]\n",
            "   [-0.10275899  0.08592282 -0.02328131 ...  0.07051073 -0.0110028\n",
            "    -0.00776404]\n",
            "   [-0.11846356  0.09282631 -0.08819465 ...  0.0094851  -0.03694928\n",
            "     0.04728036]]\n",
            "\n",
            "  [[-0.0577597  -0.03673469  0.00928196 ... -0.00521796 -0.11872097\n",
            "    -0.06359362]\n",
            "   [-0.04429615  0.14136466  0.00554455 ... -0.18714377 -0.06811975\n",
            "    -0.00939491]\n",
            "   [-0.14109854 -0.03325988  0.00298531 ...  0.03543526 -0.15528052\n",
            "     0.00086767]\n",
            "   ...\n",
            "   [ 0.02792776  0.05791401 -0.21990596 ... -0.14814235 -0.14582907\n",
            "     0.136557  ]\n",
            "   [-0.16780494 -0.18581137  0.00072293 ... -0.10045785 -0.08324363\n",
            "    -0.13461079]\n",
            "   [-0.08976964 -0.20099112 -0.16719064 ...  0.0387636  -0.00939593\n",
            "     0.21005973]]\n",
            "\n",
            "  [[ 0.0677597  -0.08638634 -0.05788271 ... -0.13711043  0.0195104\n",
            "    -0.05982857]\n",
            "   [-0.07975154  0.06898738 -0.07902499 ... -0.04061988 -0.05156942\n",
            "    -0.05443226]\n",
            "   [ 0.08831818  0.0160504  -0.12802467 ...  0.00215163 -0.15128914\n",
            "    -0.08055459]\n",
            "   ...\n",
            "   [-0.0116776  -0.04783402 -0.04177055 ... -0.00303645 -0.12405161\n",
            "    -0.08225797]\n",
            "   [-0.06908607 -0.0476072  -0.09019994 ... -0.02377074 -0.09322866\n",
            "    -0.07096988]\n",
            "   [ 0.01420987 -0.14329606  0.03770517 ... -0.04944003 -0.09749588\n",
            "     0.07401573]]]]\n",
            "[ 0.00338306  0.08509979  0.07508831  0.0283715   0.02971524 -0.07279439\n",
            "  0.08193997  0.03236318 -0.01491876  0.03567998 -0.06200913 -0.04528199\n",
            " -0.03535083  0.10722392  0.0462281  -0.06963398  0.04509061 -0.04476461\n",
            " -0.03159033 -0.03291306 -0.0129774  -0.025288    0.01868326 -0.02592277\n",
            " -0.00383324  0.02985225  0.1472622   0.0457963  -0.01430978  0.06563304\n",
            "  0.08653639 -0.00185804 -0.00809611 -0.0294646   0.12804611 -0.03671989\n",
            " -0.00426369  0.01868631  0.03345681  0.05366165  0.11859628  0.10846025\n",
            " -0.05910148  0.01699449  0.16116777 -0.01049468 -0.04267276  0.00616004\n",
            " -0.02648312  0.0166527  -0.06238469 -0.01786442  0.00962492 -0.00293087\n",
            " -0.03984556 -0.0657742  -0.00089748  0.0675947   0.11844148  0.06835534]\n",
            "[[[[-0.08821869  0.03322516  0.02430331 ...  0.03202968  0.01844832\n",
            "    -0.06163029]\n",
            "   [-0.04675992  0.08543015 -0.03213297 ...  0.02711483 -0.01414299\n",
            "    -0.03442351]\n",
            "   [ 0.01864438  0.08653259 -0.08642563 ...  0.00519717  0.01417551\n",
            "     0.08086515]\n",
            "   ...\n",
            "   [-0.08723183  0.05672497 -0.02263081 ... -0.01726795  0.04621982\n",
            "    -0.0703638 ]\n",
            "   [-0.04632841  0.02626016 -0.05305818 ...  0.0124962   0.07368388\n",
            "     0.10290546]\n",
            "   [-0.0854454   0.00077011  0.00048202 ... -0.08533143  0.02942266\n",
            "    -0.02317929]]\n",
            "\n",
            "  [[ 0.0188532  -0.07325764 -0.00922425 ... -0.01436546  0.09756548\n",
            "     0.01254819]\n",
            "   [-0.02781658  0.05165569 -0.0214957  ... -0.03701911 -0.07868306\n",
            "     0.04852708]\n",
            "   [ 0.04598019 -0.0284576   0.06559446 ... -0.1053932  -0.08011083\n",
            "     0.04226173]\n",
            "   ...\n",
            "   [-0.02199451  0.03106111 -0.0046244  ... -0.02044575  0.00104766\n",
            "     0.04065778]\n",
            "   [ 0.01302102  0.09908775  0.01870459 ...  0.05404112 -0.0107953\n",
            "     0.06156407]\n",
            "   [ 0.09650043  0.01556136  0.03571702 ... -0.04498377 -0.07793738\n",
            "     0.01748184]]\n",
            "\n",
            "  [[ 0.09353981  0.00726821 -0.09304206 ... -0.01705101 -0.01109936\n",
            "     0.00859483]\n",
            "   [ 0.07885712 -0.08156358  0.05401301 ... -0.07666864  0.06449523\n",
            "     0.0969994 ]\n",
            "   [-0.00193005  0.02190491 -0.06843337 ... -0.09560774  0.0281635\n",
            "    -0.06352548]\n",
            "   ...\n",
            "   [-0.01362925  0.03351151 -0.024864   ... -0.0918136  -0.06426563\n",
            "     0.04622506]\n",
            "   [ 0.06939074  0.03934679  0.10121436 ... -0.03889564  0.02360662\n",
            "     0.04944346]\n",
            "   [ 0.05808983 -0.05643965 -0.03542771 ...  0.02671059 -0.0412831\n",
            "     0.02893179]]]\n",
            "\n",
            "\n",
            " [[[ 0.06012755  0.02005298  0.0959504  ...  0.00274489  0.0260767\n",
            "    -0.00564235]\n",
            "   [ 0.06372584  0.0403645   0.09495261 ...  0.08731242  0.07938275\n",
            "     0.03931136]\n",
            "   [ 0.09993609 -0.01462708  0.08950912 ...  0.03021299 -0.10497418\n",
            "    -0.03401437]\n",
            "   ...\n",
            "   [ 0.05060733  0.05341766 -0.00955923 ...  0.07821549  0.10150193\n",
            "     0.09101372]\n",
            "   [ 0.00770407 -0.03454041  0.03057037 ...  0.04292057  0.01210819\n",
            "     0.07748323]\n",
            "   [-0.0137239  -0.10358388  0.08091205 ... -0.03779533 -0.01942853\n",
            "    -0.03632604]]\n",
            "\n",
            "  [[-0.00297722 -0.05212715  0.09343249 ... -0.04191019  0.03667454\n",
            "     0.03176916]\n",
            "   [-0.11933276  0.08796436 -0.00722417 ... -0.01380782  0.04336238\n",
            "    -0.0433362 ]\n",
            "   [ 0.02414119  0.06665781  0.02381616 ... -0.10756292 -0.10411932\n",
            "     0.00492999]\n",
            "   ...\n",
            "   [ 0.12988293  0.06817408  0.00884185 ...  0.06373986  0.15812646\n",
            "    -0.09022459]\n",
            "   [-0.0956342   0.0882844  -0.03651996 ...  0.07444242 -0.10151255\n",
            "     0.05737533]\n",
            "   [-0.01018798  0.01779921  0.07222107 ...  0.05906405  0.08811015\n",
            "     0.01179783]]\n",
            "\n",
            "  [[ 0.09258776  0.03953197 -0.03796688 ...  0.04602381  0.00692147\n",
            "     0.10367268]\n",
            "   [ 0.09889375  0.01448981  0.06326853 ... -0.09347701  0.08535362\n",
            "     0.07011104]\n",
            "   [-0.05120121  0.02442475 -0.05516785 ... -0.09903     0.0699436\n",
            "    -0.06670035]\n",
            "   ...\n",
            "   [-0.00527737 -0.00889394 -0.03477593 ...  0.09251208 -0.02144217\n",
            "     0.09622698]\n",
            "   [-0.05611234 -0.0416218   0.02380352 ...  0.0378077   0.08605967\n",
            "    -0.06800359]\n",
            "   [ 0.07620087  0.00372969  0.00203769 ...  0.09297333 -0.06174429\n",
            "     0.00028627]]]\n",
            "\n",
            "\n",
            " [[[-0.00699473  0.00367134  0.00525887 ... -0.08595384 -0.05482638\n",
            "    -0.02988636]\n",
            "   [-0.06021566  0.05330364 -0.05940294 ...  0.0969632   0.0766888\n",
            "     0.02191149]\n",
            "   [ 0.07475289  0.01224828  0.07611812 ...  0.09216187  0.05569948\n",
            "    -0.04936259]\n",
            "   ...\n",
            "   [-0.04244488 -0.02750517 -0.0292457  ... -0.09697673  0.05935348\n",
            "    -0.10168906]\n",
            "   [-0.04308468  0.06877867 -0.06078105 ... -0.0504116  -0.07799519\n",
            "     0.08901566]\n",
            "   [-0.0348283   0.03898051  0.01086406 ...  0.02221747  0.0262639\n",
            "     0.04475837]]\n",
            "\n",
            "  [[-0.06355458  0.08190166  0.04144532 ...  0.03883756 -0.05290897\n",
            "     0.05674031]\n",
            "   [ 0.05866046 -0.07214339 -0.0918121  ...  0.07412674 -0.00477235\n",
            "     0.03377654]\n",
            "   [ 0.00935662 -0.02103255 -0.06193933 ...  0.0478405  -0.03381507\n",
            "     0.01853789]\n",
            "   ...\n",
            "   [ 0.02485334 -0.00300993  0.03363211 ...  0.07259163 -0.02199011\n",
            "    -0.01264697]\n",
            "   [ 0.03988629 -0.07035148  0.0641027  ... -0.05231057 -0.00279775\n",
            "     0.02875403]\n",
            "   [-0.01252093  0.00523367 -0.08636351 ... -0.1048108   0.02970802\n",
            "     0.07706621]]\n",
            "\n",
            "  [[-0.07153545  0.0302989   0.07614654 ...  0.02719518 -0.01329467\n",
            "    -0.08685093]\n",
            "   [ 0.03727227  0.06931973 -0.03940927 ... -0.01926713  0.02959055\n",
            "    -0.08245269]\n",
            "   [ 0.06455127  0.06487671 -0.05803226 ... -0.08006188 -0.03155617\n",
            "    -0.07579145]\n",
            "   ...\n",
            "   [ 0.09522428 -0.0468763  -0.03147314 ...  0.05377106 -0.00607645\n",
            "    -0.03307688]\n",
            "   [ 0.03934448 -0.08379477  0.0635388  ...  0.05730186 -0.02582739\n",
            "    -0.04714747]\n",
            "   [-0.03902692  0.10537349  0.04262505 ... -0.08769922 -0.04576197\n",
            "     0.06129581]]]]\n",
            "[-1.50879072e-02  1.49631858e-01  6.25456199e-02  4.72624116e-02\n",
            "  1.70191135e-02  9.75633040e-03 -5.50510660e-02  5.15710795e-03\n",
            "  7.82747045e-02 -2.37363447e-02  3.63364443e-02  1.79721173e-02\n",
            " -1.69027261e-02  2.81175002e-02 -3.89101729e-02 -7.48777180e-04\n",
            "  7.15759620e-02 -1.03880782e-02 -3.73645984e-02 -1.50708314e-02\n",
            "  2.59165326e-03  6.46431223e-02 -2.09628493e-02  9.07497853e-02\n",
            " -9.88052934e-02 -3.58925462e-02 -2.95920298e-02  5.49390316e-02\n",
            " -1.85453519e-02 -1.83751117e-02  1.91186480e-02  7.62271881e-02\n",
            " -2.98994351e-02 -1.84834115e-02 -3.52036208e-02  6.20001629e-02\n",
            "  9.11735222e-02 -5.75056821e-02  2.47213282e-02  2.48519424e-02\n",
            " -3.80647629e-02 -4.14229743e-03  2.75922734e-02 -1.46659827e-02\n",
            " -1.16748447e-02  2.91344263e-02 -2.10894011e-02 -4.23934869e-02\n",
            " -2.79323515e-02 -1.75054744e-02 -3.66813131e-02 -3.21536921e-02\n",
            " -3.91301252e-02  9.48866159e-02 -3.72693203e-02  1.16790136e-04\n",
            "  3.14444937e-02  5.39078712e-02  5.43191433e-02  9.42189395e-02\n",
            "  8.49426985e-02 -3.06880567e-02  2.18175855e-02  6.50403509e-03\n",
            " -2.33882684e-02 -1.80159193e-02 -3.16858701e-02  1.22735180e-01\n",
            " -5.27024493e-02  8.80333707e-02  5.44592217e-02  5.68173900e-02\n",
            " -2.97871381e-02 -2.20322795e-02 -4.72620018e-02 -2.94069611e-02\n",
            "  2.67866254e-02 -7.04506878e-03  4.02119942e-02  5.09669669e-02\n",
            "  9.01943892e-02  2.52442155e-02  1.19113280e-02  1.39503106e-02\n",
            "  1.20791234e-01  3.18048112e-02  2.65416838e-02  8.09621587e-02\n",
            "  2.70259511e-02  4.05128486e-02  3.97414491e-02  3.59840356e-02\n",
            "  5.18392362e-02  3.73090655e-02 -5.98104522e-02 -2.96381321e-02\n",
            " -2.37284340e-02 -2.55163740e-02 -3.40642929e-02 -2.44557597e-02\n",
            "  3.01685976e-03 -1.45109007e-02  4.27281968e-02  5.17258532e-02\n",
            " -2.86846776e-02  1.73465729e-01  3.62828150e-02 -2.71830522e-02\n",
            " -2.29486208e-02 -2.98122950e-02  5.17236255e-02  2.22696383e-02\n",
            "  3.83646749e-02 -8.36392045e-02  3.71213518e-02 -3.13862078e-02\n",
            "  1.52778625e-01  1.37532920e-01 -2.43646675e-03 -2.64638364e-02]\n",
            "> 72.390\n"
          ]
        }
      ],
      "source": [
        "print_model (model)\n",
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GmFfu4r-dFdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 32, 32, 40)        1120      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 40)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 16, 16, 50)        18050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 8, 8, 50)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 8, 8, 60)          27060     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 4, 4, 60)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 4, 4, 60)          32460     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 2, 2, 60)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 2, 2, 60)          32460     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 1, 1, 60)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 1, 1, 120)         64920     \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 120)               14520     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1210      \n",
            "=================================================================\n",
            "Total params: 191,800\n",
            "Trainable params: 191,800\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpj_vgwqi3/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpj_vgwqi3/assets\n",
            "2021-11-02 14:53:30.867020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-02 14:53:30.889287: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2021-11-02 14:53:30.940920: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-11-02 14:53:31.009126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-02 14:53:31.009930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-02 14:53:31.105061: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-02 14:53:31.107467: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-02 14:53:31.107513: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-02 14:53:31.107542: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-02 14:53:31.108805: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-02 14:53:31.108900: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-02 14:53:31.113275: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-02 14:53:31.113300: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-02 14:53:31.117755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-02 14:53:31.117777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-11-02 14:53:31.117794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2021-11-02 14:53:31.217635: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2021-11-02 14:53:31.217663: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 1.254ms.\n",
            "2021-11-02 14:53:31.217668: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
            "2021-11-02 14:53:32.480984: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\n",
            "2021-11-02 14:53:32.481015: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, utils\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "  print(\"Folder \" + filename + \" does not exist.\")\n",
        "  exit()\n",
        "\n",
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "model = tf.keras.models.load_model(filename + \"/\" + filename + '.h5')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(model, filename + \"/\" + filename + \".png\", show_shapes=True, show_layer_names=True, expand_nested=True)\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255 , test_images / 255\n",
        "\n",
        "train_images = tf.cast(train_images, tf.float32)\n",
        "cifar_ds = tf.data.Dataset.from_tensor_slices((train_images)).batch(1)\n",
        "def representative_dataset():\n",
        "  for input_value in cifar_ds.take(100):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "#converter.representative_dataset = representative_dataset\n",
        "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.float32  # or tf.uint8\n",
        "converter.inference_output_type = tf.float32  # or tf.uint8\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open(filename + \"/\" + filename + \"_f32\" + '.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "INb151fxeI6B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpju81qx8i/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpju81qx8i/assets\n",
            "2021-11-02 11:55:45.721125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-02 11:55:45.721855: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2021-11-02 11:55:45.721957: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-11-02 11:55:45.722666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-02 11:55:45.723316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-02 11:55:45.723453: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-02 11:55:45.723514: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-02 11:55:45.723534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-02 11:55:45.723547: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-02 11:55:45.723593: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-02 11:55:45.723644: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-02 11:55:45.723698: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-02 11:55:45.723706: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-02 11:55:45.723719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-02 11:55:45.723724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-11-02 11:55:45.723729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2021-11-02 11:55:45.727112: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2021-11-02 11:55:45.727131: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
            "2021-11-02 11:55:45.727137: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\n",
            "2021-11-02 11:55:45.792987: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\n",
            "2021-11-02 11:55:45.793030: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\n",
            "2021-11-02 11:55:46.219813: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.float32  # or tf.uint8\n",
        "converter.inference_output_type = tf.float32  # or tf.uint8\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open(filename + \"/\" + filename + \"_i8\" + '.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pZ4KikJ-fkaU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=filename + \"/\" + filename + \"_i8\" + '.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TpXHwv2Tf3yI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Lite Predicted: [[0.         0.         0.00390625 0.0234375  0.         0.05859375\n",
            "  0.9140625  0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], x)\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print('TensorFlow Lite Predicted:', output_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "quantized_training.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3ba63467901cd6d3991f497c38810e6d1156dd2dfb6eb0edc80f01dd9606bacd"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
