{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbiM6lilQxtQ",
        "outputId": "ede20a3d-6cc7-4d96-c754-cbc1a79a6008"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-15 19:47:21.174811: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-15 19:47:21.174869: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import SeparableConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jupyter notebook to build, train, and deply CNN models for TF Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IuN7OgXSQ9i2"
      },
      "outputs": [],
      "source": [
        "filename = \"tiny_vgg_q\" # Set the name for the model output\n",
        "\n",
        "early_stop_training = True # Early stop training\n",
        "\n",
        "#___________________________\n",
        "training_batch_size = 20\n",
        "training_epochs = 100\n",
        "training_patience = 10\n",
        "\n",
        "#___________________________\n",
        "quantize_aware_training = True\n",
        "quantize_training_epochs = 100\n",
        "quantize_training_patience = 10\n",
        "\n",
        "target_exponent = 3 # Target exponent bit size for custom floating-point \n",
        "target_mantissa = 0 # Target mantissa bit size for custom floating-point\n",
        "\n",
        "max_degradation = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "google_colab = False # Set True when using on google colab\n",
        "if google_colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CNN ARCHITECTURE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def ConvPool_CNN_C():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides = 2))\n",
        "\n",
        "    model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides = 2))\n",
        "\n",
        "    model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(Conv2D(192, (1, 1), activation='relu'))\n",
        "    model.add(Conv2D(10, (1, 1)))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Activation(activation='softmax'))\n",
        "\n",
        "    # compile model\n",
        "    #opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "    opt = \"adam\"\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def shallow_CNN():\n",
        "\tmodel = Sequential()\n",
        "\t\n",
        "\tmodel.add(Conv2D(40, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Conv2D(60, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Conv2D(120, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(120, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\t#opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\topt = \"adam\"\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def shallow_dropout_CNN():\n",
        "\tmodel = Sequential()\n",
        "\t\n",
        "\tmodel.add(Conv2D(40, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Conv2D(60, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Conv2D(120, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(120, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\t#opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\topt = \"adam\"\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def shallow_SeparableCNN():\n",
        "\tmodel = Sequential()\n",
        "\t\n",
        "\tmodel.add(SeparableConv2D(40, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(SeparableConv2D(60, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(SeparableConv2D(120, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(120, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\t#opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\topt = \"adam\"\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def define_model_CNN():\n",
        "\treturn shallow_dropout_CNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quantized aware training method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Fh2Y7AaGvoUK"
      },
      "outputs": [],
      "source": [
        "import struct\n",
        "\n",
        "def bin2float(b):\n",
        "    ''' Convert binary string to a float.\n",
        "\n",
        "    Attributes:\n",
        "        :b: Binary string to transform.\n",
        "    '''\n",
        "    h = int(b, 2).to_bytes(8, byteorder=\"big\")\n",
        "    return struct.unpack('>d', h)[0]\n",
        "\n",
        "\n",
        "def float2bin(f):\n",
        "    ''' Convert float to 64-bit binary string.\n",
        "\n",
        "    Attributes:\n",
        "        :f: Float number to transform.\n",
        "    '''\n",
        "    [d] = struct.unpack(\">Q\", struct.pack(\">d\", f))\n",
        "    return f'{d:064b}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7Y8p19yiv2rs"
      },
      "outputs": [],
      "source": [
        "def quantize_float (float_number, exponent_bits, mantissa_bits):\n",
        "    exponent_sign = 1\n",
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
        "    if mantissa_bits < 0:\n",
        "      mantissa_bits = 0\n",
        "    if exponent_bits < 0:\n",
        "      exponent_bits = 0\n",
        "      \n",
        "    coefficient = float2bin(float_number)\n",
        "    sign = int (coefficient[:1], 2)\n",
        "    if 0 < mantissa_bits:\n",
        "        custom_mantissa = int (coefficient[12 : 12 + mantissa_bits], 2)\n",
        "    else:\n",
        "        custom_mantissa = 0\n",
        "    residual_mantissa = int (coefficient[12 + mantissa_bits:], 2)\n",
        "    exponent = int (coefficient[1:12], 2) - 1023\n",
        "\n",
        "    exponent_full_range = pow(2, exponent_bits - exponent_sign) - 1\n",
        "    if exponent < - exponent_full_range:\n",
        "        quantized_value = 0\n",
        "    elif exponent > exponent_full_range:\n",
        "        quantized_value = pow(-1, sign) * (1 + (1 - pow(2, - mantissa_bits))) * pow(2, exponent_full_range)\n",
        "    else:\n",
        "        if (pow (2, (52 - (mantissa_bits + 1))) - 1) < residual_mantissa:\n",
        "            custom_mantissa += 1\n",
        "            if (pow (2, mantissa_bits) - 1) < custom_mantissa:\n",
        "                custom_mantissa = 0\n",
        "                exponent += 1\n",
        "    \n",
        "        quantized_value = pow(-1, sign) * (1 + custom_mantissa * pow(2, - mantissa_bits)) * pow(2, exponent)\n",
        "    return quantized_value\n",
        "\n",
        "def quantize_model(model, exponent_bits, mantissa_bits):\n",
        "  for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.SeparableConv2D):\n",
        "      layer_weights = layer.get_weights()\n",
        "      for index in range(len(layer_weights)):\n",
        "        matrix = layer_weights[index]\n",
        "        for weight_index, weight in np.ndenumerate(matrix):\n",
        "          matrix[weight_index] = quantize_float(weight, target_exponent, target_mantissa)\n",
        "        layer_weights[index] = matrix\n",
        "      layer.set_weights(layer_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Early stop callback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vaA7sG9xenUF"
      },
      "outputs": [],
      "source": [
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, verbose=1, mode='auto', restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mHKtRDtPn0eQ"
      },
      "outputs": [],
      "source": [
        "mantissa_bits = target_mantissa\n",
        "exponent_bits = target_exponent\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = None):\n",
        "    quantize_model(self.model, exponent_bits, mantissa_bits)\n",
        "  def on_train_end(self, logs = None):\n",
        "    quantize_model(self.model, exponent_bits, mantissa_bits)\n",
        "  def on_batch_end(self, epoch, logs = None):\n",
        "    quantize_model(self.model, exponent_bits, mantissa_bits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WPVVK7cLRHlR"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(filename):\n",
        "  os.mkdir(filename)\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tf = pyplot.figure()\n",
        "\tf.set_figwidth(10)\n",
        "\tf.set_figheight(20)\n",
        "\t\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tpyplot.savefig(filename + '/' + filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "def print_model(model):\n",
        "\tfor layer in model.layers:\n",
        "\t\tif isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.SeparableConv2D):\n",
        "\t\t\tlayer_weights = layer.get_weights()\n",
        "\t\t\tprint (layer_weights)\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model_CNN()\n",
        "\t# fit model\n",
        "\thistory = model.fit(trainX, trainY, epochs=20, batch_size=64, validation_data=(testX, testY), verbose=1, callbacks=[MyCallback()])\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\t# Save the entire model to a HDF5 file.\n",
        "\tmodel.save(filename + \"/\" + filename + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-15 19:48:05.562629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2021-11-15 19:48:05.626319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 19:48:05.627972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-15 19:48:05.629872: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-15 19:48:05.632369: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-15 19:48:05.670133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-15 19:48:05.678790: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-15 19:48:05.680322: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-15 19:48:05.680826: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-15 19:48:05.681623: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-15 19:48:05.681671: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-15 19:48:05.682486: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-11-15 19:48:05.746793: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2494250000 Hz\n",
            "2021-11-15 19:48:05.747654: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56277bbbd8a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-15 19:48:05.747770: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-11-15 19:48:05.756859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-15 19:48:05.756900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \n"
          ]
        }
      ],
      "source": [
        "# entry point, run the test harness\n",
        "# load dataset\n",
        "trainX, trainY, testX, testY = load_dataset()\n",
        "\n",
        "# prepare pixel data\n",
        "trainX, testX = prep_pixels(trainX, testX)\n",
        "\n",
        "# define model\n",
        "model = define_model_CNN()\n",
        "# fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsUR8C6RRJVc",
        "outputId": "f4b2312f-ee7b-41d7-8715-6afdbcdb31b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-15 19:48:07.400983: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2500/2500 [==============================] - ETA: 0s - loss: 1.9885 - accuracy: 0.2394"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-15 19:51:18.265289: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 122880000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2500/2500 [==============================] - 197s 79ms/step - loss: 1.9885 - accuracy: 0.2394 - val_loss: 1.5909 - val_accuracy: 0.4319\n",
            "Epoch 2/100\n",
            "2500/2500 [==============================] - 198s 79ms/step - loss: 1.5507 - accuracy: 0.4299 - val_loss: 1.2742 - val_accuracy: 0.5429\n",
            "Epoch 3/100\n",
            "2500/2500 [==============================] - 199s 80ms/step - loss: 1.3899 - accuracy: 0.5005 - val_loss: 1.1332 - val_accuracy: 0.5983\n",
            "Epoch 4/100\n",
            "2500/2500 [==============================] - 187s 75ms/step - loss: 1.2879 - accuracy: 0.5430 - val_loss: 1.0461 - val_accuracy: 0.6426\n",
            "Epoch 5/100\n",
            "2500/2500 [==============================] - 181s 72ms/step - loss: 1.2087 - accuracy: 0.5730 - val_loss: 0.9902 - val_accuracy: 0.6555\n",
            "Epoch 6/100\n",
            "2500/2500 [==============================] - 181s 72ms/step - loss: 1.1529 - accuracy: 0.5938 - val_loss: 0.9445 - val_accuracy: 0.6738\n",
            "Epoch 7/100\n",
            "2500/2500 [==============================] - 177s 71ms/step - loss: 1.1132 - accuracy: 0.6093 - val_loss: 1.0100 - val_accuracy: 0.6489\n",
            "Epoch 8/100\n",
            "2500/2500 [==============================] - 178s 71ms/step - loss: 1.0836 - accuracy: 0.6212 - val_loss: 0.9105 - val_accuracy: 0.6801\n",
            "Epoch 9/100\n",
            "2500/2500 [==============================] - 182s 73ms/step - loss: 1.0537 - accuracy: 0.6331 - val_loss: 0.8839 - val_accuracy: 0.6967\n",
            "Epoch 10/100\n",
            "2500/2500 [==============================] - 188s 75ms/step - loss: 1.0220 - accuracy: 0.6433 - val_loss: 0.8709 - val_accuracy: 0.6972\n",
            "Epoch 11/100\n",
            "2500/2500 [==============================] - 179s 71ms/step - loss: 1.0116 - accuracy: 0.6475 - val_loss: 0.8753 - val_accuracy: 0.6973\n",
            "Epoch 12/100\n",
            "2500/2500 [==============================] - 183s 73ms/step - loss: 0.9970 - accuracy: 0.6517 - val_loss: 0.9177 - val_accuracy: 0.6878\n",
            "Epoch 13/100\n",
            "2500/2500 [==============================] - 178s 71ms/step - loss: 0.9774 - accuracy: 0.6607 - val_loss: 0.8571 - val_accuracy: 0.7049\n",
            "Epoch 14/100\n",
            "2500/2500 [==============================] - 178s 71ms/step - loss: 0.9744 - accuracy: 0.6630 - val_loss: 0.8413 - val_accuracy: 0.7080\n",
            "Epoch 15/100\n",
            "2500/2500 [==============================] - 174s 69ms/step - loss: 0.9568 - accuracy: 0.6688 - val_loss: 0.8398 - val_accuracy: 0.7135\n",
            "Epoch 16/100\n",
            "2500/2500 [==============================] - 178s 71ms/step - loss: 0.9423 - accuracy: 0.6744 - val_loss: 0.7741 - val_accuracy: 0.7282\n",
            "Epoch 17/100\n",
            "2500/2500 [==============================] - 177s 71ms/step - loss: 0.9380 - accuracy: 0.6729 - val_loss: 0.8268 - val_accuracy: 0.7129\n",
            "Epoch 18/100\n",
            "2500/2500 [==============================] - 171s 68ms/step - loss: 0.9279 - accuracy: 0.6812 - val_loss: 0.8197 - val_accuracy: 0.7175\n",
            "Epoch 19/100\n",
            "2500/2500 [==============================] - 176s 70ms/step - loss: 0.9296 - accuracy: 0.6800 - val_loss: 0.7787 - val_accuracy: 0.7347\n",
            "Epoch 20/100\n",
            "2500/2500 [==============================] - 172s 69ms/step - loss: 0.9130 - accuracy: 0.6847 - val_loss: 0.7965 - val_accuracy: 0.7237\n",
            "Epoch 21/100\n",
            "2500/2500 [==============================] - 165s 66ms/step - loss: 0.9078 - accuracy: 0.6846 - val_loss: 0.7750 - val_accuracy: 0.7304\n",
            "Epoch 22/100\n",
            "2500/2500 [==============================] - 164s 66ms/step - loss: 0.8996 - accuracy: 0.6902 - val_loss: 0.7492 - val_accuracy: 0.7397\n",
            "Epoch 23/100\n",
            "2500/2500 [==============================] - 162s 65ms/step - loss: 0.9013 - accuracy: 0.6884 - val_loss: 0.7565 - val_accuracy: 0.7411\n",
            "Epoch 24/100\n",
            "2500/2500 [==============================] - 162s 65ms/step - loss: 0.8853 - accuracy: 0.6962 - val_loss: 0.7589 - val_accuracy: 0.7344\n",
            "Epoch 25/100\n",
            "2500/2500 [==============================] - 164s 65ms/step - loss: 0.8798 - accuracy: 0.6978 - val_loss: 0.7939 - val_accuracy: 0.7256\n",
            "Epoch 26/100\n",
            "2500/2500 [==============================] - 160s 64ms/step - loss: 0.8772 - accuracy: 0.6950 - val_loss: 0.7481 - val_accuracy: 0.7428\n",
            "Epoch 27/100\n",
            "2500/2500 [==============================] - 163s 65ms/step - loss: 0.8745 - accuracy: 0.6984 - val_loss: 0.7264 - val_accuracy: 0.7480\n",
            "Epoch 28/100\n",
            "2500/2500 [==============================] - 167s 67ms/step - loss: 0.8761 - accuracy: 0.7013 - val_loss: 0.7365 - val_accuracy: 0.7478\n",
            "Epoch 29/100\n",
            "2500/2500 [==============================] - 162s 65ms/step - loss: 0.8688 - accuracy: 0.6998 - val_loss: 0.7242 - val_accuracy: 0.7507\n",
            "Epoch 30/100\n",
            "2500/2500 [==============================] - 166s 66ms/step - loss: 0.8663 - accuracy: 0.7034 - val_loss: 0.7441 - val_accuracy: 0.7442\n",
            "Epoch 31/100\n",
            "2500/2500 [==============================] - 172s 69ms/step - loss: 0.8552 - accuracy: 0.7059 - val_loss: 0.7267 - val_accuracy: 0.7524\n",
            "Epoch 32/100\n",
            "2500/2500 [==============================] - 195s 78ms/step - loss: 0.8571 - accuracy: 0.7052 - val_loss: 0.7889 - val_accuracy: 0.7266\n",
            "Epoch 33/100\n",
            "2500/2500 [==============================] - 172s 69ms/step - loss: 0.8587 - accuracy: 0.7051 - val_loss: 0.7525 - val_accuracy: 0.7376\n",
            "Epoch 34/100\n",
            "2500/2500 [==============================] - 172s 69ms/step - loss: 0.8602 - accuracy: 0.7026 - val_loss: 0.7252 - val_accuracy: 0.7529\n",
            "Epoch 35/100\n",
            "2500/2500 [==============================] - 167s 67ms/step - loss: 0.8475 - accuracy: 0.7104 - val_loss: 0.7031 - val_accuracy: 0.7626\n",
            "Epoch 36/100\n",
            "2500/2500 [==============================] - 170s 68ms/step - loss: 0.8497 - accuracy: 0.7082 - val_loss: 0.7510 - val_accuracy: 0.7421\n",
            "Epoch 37/100\n",
            "2500/2500 [==============================] - 175s 70ms/step - loss: 0.8445 - accuracy: 0.7109 - val_loss: 0.7201 - val_accuracy: 0.7551\n",
            "Epoch 38/100\n",
            "2500/2500 [==============================] - 172s 69ms/step - loss: 0.8452 - accuracy: 0.7110 - val_loss: 0.7936 - val_accuracy: 0.7360\n",
            "Epoch 39/100\n",
            "2500/2500 [==============================] - 170s 68ms/step - loss: 0.8367 - accuracy: 0.7130 - val_loss: 0.6910 - val_accuracy: 0.7679\n",
            "Epoch 40/100\n",
            "2500/2500 [==============================] - 173s 69ms/step - loss: 0.8352 - accuracy: 0.7112 - val_loss: 0.7158 - val_accuracy: 0.7522\n",
            "Epoch 41/100\n",
            "2500/2500 [==============================] - 165s 66ms/step - loss: 0.8371 - accuracy: 0.7133 - val_loss: 0.6978 - val_accuracy: 0.7621\n",
            "Epoch 42/100\n",
            "2500/2500 [==============================] - 176s 70ms/step - loss: 0.8365 - accuracy: 0.7142 - val_loss: 0.6832 - val_accuracy: 0.7679\n",
            "Epoch 43/100\n",
            "2500/2500 [==============================] - 166s 66ms/step - loss: 0.8345 - accuracy: 0.7142 - val_loss: 0.7653 - val_accuracy: 0.7379\n",
            "Epoch 44/100\n",
            "2500/2500 [==============================] - 171s 68ms/step - loss: 0.8303 - accuracy: 0.7154 - val_loss: 0.6951 - val_accuracy: 0.7607\n",
            "Epoch 45/100\n",
            "2500/2500 [==============================] - 110s 44ms/step - loss: 0.8311 - accuracy: 0.7136 - val_loss: 0.6814 - val_accuracy: 0.7705\n",
            "Epoch 46/100\n",
            "2500/2500 [==============================] - 155s 62ms/step - loss: 0.8259 - accuracy: 0.7182 - val_loss: 0.7223 - val_accuracy: 0.7559\n",
            "Epoch 47/100\n",
            "2500/2500 [==============================] - 153s 61ms/step - loss: 0.8296 - accuracy: 0.7148 - val_loss: 0.7554 - val_accuracy: 0.7460\n",
            "Epoch 48/100\n",
            "2500/2500 [==============================] - 168s 67ms/step - loss: 0.8214 - accuracy: 0.7171 - val_loss: 0.7041 - val_accuracy: 0.7636\n",
            "Epoch 49/100\n",
            "2500/2500 [==============================] - 172s 69ms/step - loss: 0.8256 - accuracy: 0.7189 - val_loss: 0.6932 - val_accuracy: 0.7652\n",
            "Epoch 50/100\n",
            "2500/2500 [==============================] - 184s 73ms/step - loss: 0.8217 - accuracy: 0.7180 - val_loss: 0.7014 - val_accuracy: 0.7632\n",
            "Epoch 51/100\n",
            "2500/2500 [==============================] - 183s 73ms/step - loss: 0.8243 - accuracy: 0.7172 - val_loss: 0.6793 - val_accuracy: 0.7685\n",
            "Epoch 52/100\n",
            "2500/2500 [==============================] - 181s 72ms/step - loss: 0.8230 - accuracy: 0.7178 - val_loss: 0.7254 - val_accuracy: 0.7527\n",
            "Epoch 53/100\n",
            "2500/2500 [==============================] - 187s 75ms/step - loss: 0.8138 - accuracy: 0.7209 - val_loss: 0.6880 - val_accuracy: 0.7654\n",
            "Epoch 54/100\n",
            "2500/2500 [==============================] - 194s 78ms/step - loss: 0.8141 - accuracy: 0.7210 - val_loss: 0.7331 - val_accuracy: 0.7496\n",
            "Epoch 55/100\n",
            "2500/2500 [==============================] - 193s 77ms/step - loss: 0.8153 - accuracy: 0.7208 - val_loss: 0.7845 - val_accuracy: 0.7380\n",
            "Epoch 56/100\n",
            "2500/2500 [==============================] - 196s 79ms/step - loss: 0.8197 - accuracy: 0.7225 - val_loss: 0.6986 - val_accuracy: 0.7596\n",
            "Epoch 57/100\n",
            "2500/2500 [==============================] - 198s 79ms/step - loss: 0.8197 - accuracy: 0.7219 - val_loss: 0.6972 - val_accuracy: 0.7626\n",
            "Epoch 58/100\n",
            "2500/2500 [==============================] - 177s 71ms/step - loss: 0.8128 - accuracy: 0.7193 - val_loss: 0.7886 - val_accuracy: 0.7365\n",
            "Epoch 59/100\n",
            "2500/2500 [==============================] - 168s 67ms/step - loss: 0.8055 - accuracy: 0.7239 - val_loss: 0.6791 - val_accuracy: 0.7687\n",
            "Epoch 60/100\n",
            "2500/2500 [==============================] - 162s 65ms/step - loss: 0.8096 - accuracy: 0.7219 - val_loss: 0.7033 - val_accuracy: 0.7597\n",
            "Epoch 61/100\n",
            "2500/2500 [==============================] - ETA: 0s - loss: 0.8088 - accuracy: 0.7213Restoring model weights from the end of the best epoch.\n",
            "2500/2500 [==============================] - 159s 64ms/step - loss: 0.8088 - accuracy: 0.7213 - val_loss: 0.7624 - val_accuracy: 0.7428\n",
            "Epoch 00061: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-15 22:45:22.522799: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 122880000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-quantization training > 76.850\n"
          ]
        }
      ],
      "source": [
        "if not early_stop_training:\n",
        "    history = model.fit(trainX, trainY, epochs=training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1)\n",
        "else:\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=training_patience, verbose=1, mode='auto', restore_best_weights=True)\n",
        "    history = model.fit(trainX, trainY, epochs=training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1, callbacks=[monitor])\n",
        "\n",
        "# evaluate model\n",
        "_, pre_acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('Pre-quantization training > %.3f' % (pre_acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# learning curves\n",
        "summarize_diagnostics(history)\n",
        "\n",
        "# Save the entire model to a HDF5 file.\n",
        "model.save(filename + \"/\" + filename + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_______ Post-training quantization _______\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-15 22:45:37.170182: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 122880000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original accuracy > 76.850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-15 22:45:47.170939: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 122880000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([[[[-0.25 , -0.25 , -0.125, ..., -0.5  , -0.25 ,  0.25 ],\n",
            "         [ 0.   ,  0.   , -0.5  , ..., -0.5  ,  0.25 , -0.125],\n",
            "         [ 0.25 ,  0.5  ,  0.   , ..., -0.25 ,  0.5  , -0.5  ]],\n",
            "\n",
            "        [[ 0.5  ,  0.   , -0.25 , ...,  0.5  , -0.25 ,  0.25 ],\n",
            "         [-0.5  , -0.125, -0.25 , ...,  0.125, -0.25 ,  0.   ],\n",
            "         [-0.25 ,  0.   , -0.25 , ...,  0.   , -0.5  ,  0.   ]],\n",
            "\n",
            "        [[ 0.25 , -0.25 ,  1.   , ...,  0.25 ,  0.5  ,  0.125],\n",
            "         [-1.   , -0.25 ,  0.5  , ..., -0.5  ,  0.   ,  0.   ],\n",
            "         [ 0.5  ,  0.25 ,  0.   , ...,  0.5  ,  0.125,  0.   ]]],\n",
            "\n",
            "\n",
            "       [[[-0.25 ,  0.   , -0.125, ..., -0.25 ,  0.25 ,  0.5  ],\n",
            "         [-0.25 , -0.25 ,  0.   , ..., -0.5  ,  0.   ,  0.   ],\n",
            "         [ 0.5  ,  0.   ,  0.   , ...,  0.25 ,  0.5  , -1.   ]],\n",
            "\n",
            "        [[ 0.5  , -0.25 ,  0.125, ...,  0.   , -0.125,  0.   ],\n",
            "         [-0.25 ,  0.5  , -0.125, ..., -0.5  , -0.5  ,  0.   ],\n",
            "         [ 0.125,  0.25 ,  0.   , ..., -0.5  , -0.5  , -0.5  ]],\n",
            "\n",
            "        [[ 0.25 , -0.5  , -0.25 , ...,  0.5  ,  0.25 , -0.25 ],\n",
            "         [-1.   ,  0.5  ,  0.25 , ...,  0.   ,  0.   , -0.5  ],\n",
            "         [ 0.   ,  0.5  ,  0.   , ...,  0.25 ,  0.5  ,  0.25 ]]],\n",
            "\n",
            "\n",
            "       [[[-0.5  , -0.5  ,  0.125, ...,  0.   ,  0.25 , -0.25 ],\n",
            "         [ 0.5  ,  0.25 ,  0.25 , ..., -0.25 ,  0.25 ,  0.25 ],\n",
            "         [ 0.   ,  0.5  ,  0.25 , ...,  0.5  ,  0.25 , -0.5  ]],\n",
            "\n",
            "        [[ 0.5  , -0.5  ,  0.25 , ..., -0.25 , -0.5  ,  0.   ],\n",
            "         [-0.25 , -0.25 ,  0.   , ..., -1.   , -0.25 ,  0.   ],\n",
            "         [-0.5  ,  0.   ,  0.25 , ..., -0.25 , -0.5  , -0.25 ]],\n",
            "\n",
            "        [[ 0.125,  0.   , -0.5  , ...,  0.5  ,  0.   ,  0.   ],\n",
            "         [-0.125,  0.5  , -0.5  , ...,  0.   ,  0.5  ,  0.125],\n",
            "         [ 0.125, -0.5  , -0.5  , ...,  0.25 ,  0.25 , -0.5  ]]]],\n",
            "      dtype=float32), array([-0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.5  ,  0.   ,\n",
            "        0.   ,  0.   ,  0.   ,  0.   ,  0.125, -0.5  ,  0.   ,  0.   ,\n",
            "        0.   ,  0.   ,  0.25 ,  0.   ,  0.   ,  0.   , -0.5  ,  0.   ,\n",
            "        0.   ,  0.125,  0.   , -0.5  , -0.5  ,  0.   ,  0.   ,  0.   ,\n",
            "       -0.5  , -0.5  ,  0.   ,  0.   ,  0.   , -0.25 ,  0.   ,  0.   ],\n",
            "      dtype=float32)]\n",
            "[array([[[[-0.25 ,  0.5  , -0.25 , ..., -0.5  ,  0.25 , -0.5  ],\n",
            "         [ 0.   ,  0.5  , -0.5  , ...,  0.   ,  0.   ,  0.   ],\n",
            "         [-0.5  ,  0.   ,  0.25 , ...,  0.25 ,  0.   ,  0.   ],\n",
            "         ...,\n",
            "         [-0.25 , -0.25 , -1.   , ..., -0.25 , -0.5  ,  0.   ],\n",
            "         [ 0.5  ,  0.25 ,  0.   , ..., -0.125,  0.   ,  0.   ],\n",
            "         [ 0.125,  0.125, -0.5  , ..., -0.25 ,  0.25 , -0.5  ]],\n",
            "\n",
            "        [[ 0.   , -0.125,  0.   , ..., -0.5  , -0.25 ,  0.25 ],\n",
            "         [ 0.   ,  0.   ,  0.   , ...,  0.25 , -0.25 ,  0.   ],\n",
            "         [-0.5  ,  0.   , -0.5  , ..., -0.25 ,  0.   ,  0.25 ],\n",
            "         ...,\n",
            "         [-0.25 , -1.   , -0.5  , ...,  0.25 ,  0.   , -0.25 ],\n",
            "         [-0.25 , -0.25 ,  0.25 , ..., -0.5  , -0.5  ,  0.   ],\n",
            "         [ 0.125, -0.5  ,  0.125, ...,  0.   , -0.5  ,  0.125]],\n",
            "\n",
            "        [[ 0.   ,  0.25 ,  0.   , ..., -0.5  , -0.5  ,  1.   ],\n",
            "         [ 0.   ,  0.   ,  0.25 , ...,  0.25 ,  0.   ,  0.   ],\n",
            "         [ 0.   ,  0.   ,  0.   , ..., -0.125,  0.   ,  0.   ],\n",
            "         ...,\n",
            "         [-0.25 ,  0.   , -0.5  , ...,  0.5  , -0.125,  0.   ],\n",
            "         [ 0.   ,  0.125, -0.125, ...,  0.   , -1.   , -0.125],\n",
            "         [ 0.25 , -0.125,  0.   , ...,  0.25 ,  0.   ,  0.5  ]]],\n",
            "\n",
            "\n",
            "       [[[-0.125,  0.5  , -0.25 , ...,  0.125,  0.   ,  0.5  ],\n",
            "         [-0.125,  0.25 , -0.5  , ...,  0.   ,  0.125, -0.5  ],\n",
            "         [-0.5  ,  0.   ,  0.   , ...,  0.   ,  0.25 ,  0.   ],\n",
            "         ...,\n",
            "         [-0.125, -1.   , -0.5  , ..., -0.25 , -0.5  , -1.   ],\n",
            "         [ 0.   ,  0.   ,  0.   , ..., -0.25 , -0.5  , -0.125],\n",
            "         [ 0.   ,  0.5  , -0.125, ..., -0.5  ,  0.   , -1.   ]],\n",
            "\n",
            "        [[-0.125, -0.5  ,  0.   , ..., -0.25 , -0.125, -1.   ],\n",
            "         [ 0.   ,  0.   , -0.25 , ...,  0.125,  0.   ,  0.125],\n",
            "         [-0.25 , -0.25 , -0.5  , ..., -0.25 ,  0.   ,  0.   ],\n",
            "         ...,\n",
            "         [-0.25 , -1.   ,  0.25 , ..., -0.25 , -0.125, -0.5  ],\n",
            "         [ 0.   ,  0.25 ,  0.   , ..., -0.5  , -1.   , -0.125],\n",
            "         [-0.125, -0.5  ,  0.25 , ...,  0.125, -0.125, -0.5  ]],\n",
            "\n",
            "        [[ 0.   ,  0.25 ,  0.   , ...,  0.   , -0.125,  0.   ],\n",
            "         [ 0.125, -0.25 ,  0.5  , ...,  0.   ,  0.   ,  0.125],\n",
            "         [ 0.   ,  0.25 , -0.25 , ..., -0.125, -0.25 ,  0.125],\n",
            "         ...,\n",
            "         [ 0.25 , -0.5  ,  0.   , ...,  0.   ,  0.   , -0.125],\n",
            "         [ 0.   ,  0.25 ,  0.   , ...,  0.   , -1.   ,  0.   ],\n",
            "         [ 0.   , -1.   , -0.25 , ..., -0.5  ,  0.   ,  1.   ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.   , -1.   ,  0.   , ...,  0.   ,  0.25 , -0.25 ],\n",
            "         [ 0.   , -0.125, -0.25 , ...,  0.   ,  0.   , -0.25 ],\n",
            "         [-0.5  ,  0.   , -0.125, ...,  0.   , -0.5  ,  0.   ],\n",
            "         ...,\n",
            "         [ 0.   , -0.5  ,  0.   , ..., -0.125,  0.   , -0.5  ],\n",
            "         [ 0.   ,  0.   ,  0.25 , ...,  0.25 , -1.   ,  0.   ],\n",
            "         [ 0.25 ,  0.5  ,  0.   , ..., -0.5  , -0.5  , -0.5  ]],\n",
            "\n",
            "        [[ 0.   , -1.   ,  0.25 , ...,  0.   ,  0.   , -0.25 ],\n",
            "         [-0.125, -0.25 ,  0.   , ...,  0.   ,  0.   ,  0.125],\n",
            "         [ 0.   ,  0.   ,  0.   , ...,  0.   , -0.125, -0.125],\n",
            "         ...,\n",
            "         [-1.   , -0.25 ,  0.   , ...,  0.   , -0.25 ,  0.25 ],\n",
            "         [ 0.   ,  0.125,  0.25 , ...,  0.25 , -1.   ,  0.   ],\n",
            "         [ 0.   , -1.   ,  0.125, ...,  0.125,  0.   , -0.5  ]],\n",
            "\n",
            "        [[ 0.   ,  0.125,  0.125, ...,  0.   ,  0.   ,  0.   ],\n",
            "         [-0.25 ,  0.   ,  0.   , ...,  0.   ,  0.   , -0.125],\n",
            "         [ 0.   ,  0.   ,  0.   , ...,  0.5  ,  0.   ,  0.   ],\n",
            "         ...,\n",
            "         [ 0.5  ,  0.   ,  0.   , ..., -0.25 ,  0.   ,  0.   ],\n",
            "         [ 0.125,  0.   ,  0.   , ...,  0.   , -0.5  ,  0.   ],\n",
            "         [ 0.   , -1.   ,  0.   , ..., -0.125,  0.   ,  0.5  ]]]],\n",
            "      dtype=float32), array([ 0.25 ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.25 ,\n",
            "        0.   ,  0.   ,  0.   , -0.5  , -0.25 , -0.5  , -0.25 ,  0.   ,\n",
            "        0.   , -0.5  ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
            "       -0.25 ,  0.   ,  0.   ,  0.5  ,  0.   ,  0.   ,  0.125,  0.25 ,\n",
            "        0.25 ,  0.   , -0.125, -0.25 ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
            "        0.25 ,  0.   , -0.125,  0.   ,  0.25 , -0.25 ,  0.   , -0.25 ,\n",
            "        0.   ,  0.   , -0.25 , -0.125,  0.   ,  0.   , -0.25 , -0.25 ,\n",
            "        0.125, -0.25 ,  0.   ,  0.   ], dtype=float32)]\n",
            "[array([[[[-0.5  ,  0.   , -0.5  , ..., -0.5  ,  0.125, -0.25 ],\n",
            "         [ 0.5  , -0.5  ,  0.25 , ..., -0.25 , -0.25 ,  0.125],\n",
            "         [ 0.   ,  0.   ,  0.5  , ...,  0.   , -0.5  , -0.25 ],\n",
            "         ...,\n",
            "         [-0.25 , -0.5  , -0.25 , ...,  0.   , -0.125, -0.25 ],\n",
            "         [-1.   ,  0.   ,  0.   , ..., -0.25 , -0.25 , -0.125],\n",
            "         [ 0.   ,  0.25 ,  0.25 , ..., -0.25 , -0.25 ,  0.   ]],\n",
            "\n",
            "        [[-1.   ,  0.   , -0.5  , ..., -1.   , -0.25 , -0.25 ],\n",
            "         [ 0.25 , -0.5  ,  0.25 , ..., -0.125, -0.25 ,  0.5  ],\n",
            "         [-0.25 ,  0.   ,  0.25 , ...,  0.25 , -0.5  ,  0.25 ],\n",
            "         ...,\n",
            "         [-1.   , -0.125, -0.5  , ..., -0.125,  0.5  , -1.   ],\n",
            "         [-1.   ,  0.   ,  0.   , ...,  0.   , -0.5  , -0.25 ],\n",
            "         [-0.25 , -0.5  ,  0.   , ...,  0.   , -1.   , -0.5  ]],\n",
            "\n",
            "        [[ 0.   ,  0.   , -0.25 , ...,  0.   ,  0.   , -0.25 ],\n",
            "         [ 0.5  , -0.5  ,  0.5  , ...,  0.125,  0.   ,  0.   ],\n",
            "         [-0.25 ,  0.   ,  0.   , ...,  0.25 , -0.5  ,  0.125],\n",
            "         ...,\n",
            "         [-0.5  ,  0.   , -0.125, ..., -0.5  ,  0.125,  0.25 ],\n",
            "         [-1.   ,  0.125,  0.25 , ...,  0.25 ,  0.   ,  0.   ],\n",
            "         [-0.25 ,  0.   ,  0.   , ...,  0.   , -0.25 , -0.5  ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.   ,  0.   , -0.25 , ...,  0.   ,  0.25 ,  0.25 ],\n",
            "         [ 0.125, -0.25 , -0.25 , ..., -0.125, -0.5  , -0.125],\n",
            "         [-0.25 , -0.5  , -0.5  , ...,  0.25 , -1.   ,  0.   ],\n",
            "         ...,\n",
            "         [-0.25 , -0.125, -0.5  , ..., -0.5  ,  0.   ,  0.   ],\n",
            "         [-0.5  , -0.25 ,  0.   , ..., -0.25 , -1.   , -0.25 ],\n",
            "         [ 0.   , -0.25 ,  0.25 , ..., -0.25 ,  0.25 ,  0.25 ]],\n",
            "\n",
            "        [[-0.5  ,  0.   ,  0.   , ..., -0.5  , -0.125,  0.   ],\n",
            "         [ 0.25 , -0.5  , -0.125, ...,  0.   , -0.5  ,  0.   ],\n",
            "         [-0.5  ,  0.   ,  0.   , ...,  0.   , -1.   ,  0.   ],\n",
            "         ...,\n",
            "         [-0.25 , -0.25 ,  0.125, ..., -0.25 , -0.25 ,  0.   ],\n",
            "         [ 0.125, -0.125,  0.25 , ..., -0.5  , -1.   ,  0.125],\n",
            "         [ 0.   , -0.25 , -0.25 , ..., -0.25 ,  0.   ,  0.125]],\n",
            "\n",
            "        [[-0.5  , -0.25 ,  0.125, ...,  0.25 ,  0.25 ,  0.   ],\n",
            "         [ 0.5  , -0.5  ,  0.5  , ...,  0.   , -0.25 ,  0.   ],\n",
            "         [-0.25 ,  0.   ,  0.   , ...,  0.25 ,  0.   ,  0.25 ],\n",
            "         ...,\n",
            "         [-0.125,  0.   ,  0.25 , ...,  0.125,  0.   ,  0.25 ],\n",
            "         [ 0.25 ,  0.25 ,  0.125, ..., -0.5  , -1.   ,  0.25 ],\n",
            "         [-0.125,  0.   ,  0.   , ...,  0.125, -0.25 , -0.25 ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.5  ,  0.   ,  0.   , ...,  0.5  ,  0.25 ,  0.   ],\n",
            "         [-0.5  , -1.   , -1.   , ...,  0.25 , -0.25 , -0.25 ],\n",
            "         [-0.5  ,  0.   , -0.25 , ...,  0.   , -1.   , -0.25 ],\n",
            "         ...,\n",
            "         [-0.5  , -0.125, -0.125, ...,  0.25 , -0.5  , -0.125],\n",
            "         [ 0.125,  0.125,  0.   , ...,  0.   ,  0.   ,  0.125],\n",
            "         [ 0.   , -0.5  , -0.25 , ...,  0.   , -0.25 ,  0.   ]],\n",
            "\n",
            "        [[ 0.   ,  0.125,  0.25 , ...,  0.   ,  0.5  ,  0.25 ],\n",
            "         [-0.5  , -0.5  , -1.   , ...,  0.25 , -0.25 ,  0.   ],\n",
            "         [-0.5  , -0.5  , -0.125, ...,  0.   , -0.5  ,  0.   ],\n",
            "         ...,\n",
            "         [ 0.125,  0.   ,  0.125, ...,  0.5  , -0.5  , -0.25 ],\n",
            "         [ 0.25 , -0.25 ,  0.   , ..., -0.25 , -0.5  ,  0.   ],\n",
            "         [ 0.125, -0.125, -0.5  , ...,  0.   ,  0.   ,  0.5  ]],\n",
            "\n",
            "        [[ 0.   , -0.5  ,  0.25 , ...,  0.   ,  0.   ,  0.   ],\n",
            "         [-0.25 , -0.25 , -0.25 , ...,  0.   ,  0.   ,  0.   ],\n",
            "         [-1.   ,  0.25 , -0.125, ...,  0.25 , -0.25 ,  0.   ],\n",
            "         ...,\n",
            "         [ 0.125, -0.5  ,  0.   , ..., -0.5  ,  0.5  ,  0.25 ],\n",
            "         [ 0.25 , -0.5  , -0.25 , ...,  0.125, -0.5  ,  0.   ],\n",
            "         [ 0.   , -1.   ,  0.   , ...,  0.125,  0.   ,  0.   ]]]],\n",
            "      dtype=float32), array([ 0.   , -0.25 , -0.25 ,  0.   ,  0.   ,  0.   ,  0.5  , -0.5  ,\n",
            "        0.25 ,  0.5  , -0.5  ,  0.   , -0.25 , -0.125,  0.   ,  0.25 ,\n",
            "       -0.25 ,  0.25 ,  1.   , -0.25 ,  0.   , -0.25 , -0.5  ,  0.5  ,\n",
            "        0.25 , -0.125, -0.25 ,  0.   ,  0.25 ,  1.   ,  0.   ,  0.5  ,\n",
            "        0.125,  0.   ,  0.25 ,  0.25 ,  0.25 , -0.5  , -1.   ,  0.   ,\n",
            "        0.5  , -0.25 ,  0.5  ,  0.   ,  0.5  , -0.5  , -0.25 ,  0.5  ,\n",
            "       -0.5  ,  0.25 ,  0.   ,  0.   , -0.5  , -0.5  , -0.125,  0.   ,\n",
            "        0.   , -0.125,  1.   ,  0.   ,  0.   ,  0.   ,  0.5  , -1.   ,\n",
            "        0.25 ,  0.25 ,  0.5  ,  0.   , -0.25 ,  0.   , -0.25 ,  0.   ,\n",
            "       -0.5  ,  0.   , -0.5  ,  0.5  ,  0.   , -0.5  ,  0.25 ,  0.   ,\n",
            "       -0.25 , -0.25 ,  0.25 ,  0.   ,  0.   , -0.5  ,  0.   ,  0.   ,\n",
            "        0.5  , -0.25 ,  0.5  , -0.25 , -0.25 ,  0.5  , -0.5  ,  0.   ,\n",
            "        0.25 , -0.5  ,  0.5  ,  0.25 ,  0.   ,  0.25 , -0.25 ,  0.   ,\n",
            "        0.   ,  0.5  ,  0.25 , -1.   ,  0.5  ,  0.   , -1.   ,  1.   ,\n",
            "        0.5  ,  0.   ,  0.   , -0.125,  0.125, -0.25 ,  0.5  , -0.25 ],\n",
            "      dtype=float32)]\n",
            "Post-training quantization > 13.970\n",
            "exponent = 3, mantissa = 0\n",
            "_______ Quantize aware training _______\n",
            "Starting...\n",
            "Epoch 1/100\n",
            "2500/2500 [==============================] - 199s 80ms/step - loss: 0.8158 - accuracy: 0.7190 - val_loss: 0.7382 - val_accuracy: 0.7498\n",
            "Epoch 2/100\n",
            "2500/2500 [==============================] - 206s 82ms/step - loss: 0.8794 - accuracy: 0.6981 - val_loss: 0.9852 - val_accuracy: 0.6598\n",
            "Epoch 3/100\n",
            "2500/2500 [==============================] - 208s 83ms/step - loss: 0.8793 - accuracy: 0.7003 - val_loss: 0.7467 - val_accuracy: 0.7419\n",
            "Epoch 4/100\n",
            "2500/2500 [==============================] - 213s 85ms/step - loss: 0.8733 - accuracy: 0.7038 - val_loss: 0.7902 - val_accuracy: 0.7258\n",
            "Epoch 5/100\n",
            "2500/2500 [==============================] - 214s 86ms/step - loss: 0.8811 - accuracy: 0.6978 - val_loss: 0.7701 - val_accuracy: 0.7351\n",
            "Epoch 6/100\n",
            "2500/2500 [==============================] - 216s 86ms/step - loss: 0.8773 - accuracy: 0.7006 - val_loss: 0.7083 - val_accuracy: 0.7595\n",
            "Epoch 7/100\n",
            "2500/2500 [==============================] - 213s 85ms/step - loss: 0.8847 - accuracy: 0.6986 - val_loss: 0.7168 - val_accuracy: 0.7570\n",
            "Epoch 8/100\n",
            "2500/2500 [==============================] - 204s 82ms/step - loss: 0.8807 - accuracy: 0.6982 - val_loss: 0.7885 - val_accuracy: 0.7294\n",
            "Epoch 9/100\n",
            "2500/2500 [==============================] - 195s 78ms/step - loss: 0.8817 - accuracy: 0.6983 - val_loss: 0.7870 - val_accuracy: 0.7338\n",
            "Epoch 10/100\n",
            "2500/2500 [==============================] - 199s 80ms/step - loss: 0.8814 - accuracy: 0.6993 - val_loss: 0.7097 - val_accuracy: 0.7628\n",
            "Epoch 11/100\n",
            "2500/2500 [==============================] - 203s 81ms/step - loss: 0.8826 - accuracy: 0.7006 - val_loss: 0.7578 - val_accuracy: 0.7336\n",
            "Epoch 12/100\n",
            "2500/2500 [==============================] - 255s 102ms/step - loss: 0.8929 - accuracy: 0.6944 - val_loss: 0.7025 - val_accuracy: 0.7618\n",
            "Epoch 13/100\n",
            "2500/2500 [==============================] - 222s 89ms/step - loss: 0.8867 - accuracy: 0.6959 - val_loss: 0.7340 - val_accuracy: 0.7536\n",
            "Epoch 14/100\n",
            "2500/2500 [==============================] - 212s 85ms/step - loss: 0.8880 - accuracy: 0.6958 - val_loss: 0.7471 - val_accuracy: 0.7474\n",
            "Epoch 15/100\n",
            "2500/2500 [==============================] - 215s 86ms/step - loss: 0.8818 - accuracy: 0.6959 - val_loss: 0.7501 - val_accuracy: 0.7433\n",
            "Epoch 16/100\n",
            "2500/2500 [==============================] - 223s 89ms/step - loss: 0.8789 - accuracy: 0.6997 - val_loss: 0.7407 - val_accuracy: 0.7470\n",
            "Epoch 17/100\n",
            "2500/2500 [==============================] - 222s 89ms/step - loss: 0.8957 - accuracy: 0.6927 - val_loss: 0.7900 - val_accuracy: 0.7296\n",
            "Epoch 18/100\n",
            "2500/2500 [==============================] - 202s 81ms/step - loss: 0.8793 - accuracy: 0.6981 - val_loss: 0.7703 - val_accuracy: 0.7398\n",
            "Epoch 19/100\n",
            "2500/2500 [==============================] - 201s 80ms/step - loss: 0.8864 - accuracy: 0.6968 - val_loss: 0.8003 - val_accuracy: 0.7262\n",
            "Epoch 20/100\n",
            "2500/2500 [==============================] - 201s 81ms/step - loss: 0.8964 - accuracy: 0.6916 - val_loss: 0.7415 - val_accuracy: 0.7428\n",
            "Epoch 21/100\n",
            "2500/2500 [==============================] - 201s 80ms/step - loss: 0.8923 - accuracy: 0.6915 - val_loss: 0.7419 - val_accuracy: 0.7498\n",
            "Epoch 22/100\n",
            "2500/2500 [==============================] - ETA: 0s - loss: 0.8922 - accuracy: 0.6937Restoring model weights from the end of the best epoch.\n",
            "2500/2500 [==============================] - 201s 81ms/step - loss: 0.8922 - accuracy: 0.6937 - val_loss: 0.7131 - val_accuracy: 0.7504\n",
            "Epoch 00022: early stopping\n",
            "Quantize aware training > 13.970\n",
            "Starting...\n",
            "Epoch 1/100\n",
            "1407/2500 [===============>..............] - ETA: 1:26 - loss: 0.8202 - accuracy: 0.7200"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_19545/2191330493.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmonitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantize_training_patience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantize_training_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMyCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msummarize_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print (\"_______ Post-training quantization _______\")\n",
        "model = load_model(filename + \"/\" + filename + '.h5')\n",
        "_, pre_acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('Original accuracy > %.3f' % (pre_acc * 100.0))\n",
        "\n",
        "quantize_model(model, exponent_bits, mantissa_bits)\n",
        "# evaluate model\n",
        "_, current_acc = model.evaluate(testX, testY, verbose=0)\n",
        "print_model (model)\n",
        "print('Post-training quantization > %.3f' % (current_acc * 100.0))\n",
        "\n",
        "print(\"exponent = \" + str(exponent_bits) + \", mantissa = \" + str(mantissa_bits))\n",
        "\n",
        "if quantize_aware_training:\n",
        "    print (\"_______ Quantize aware training _______\")\n",
        "    quantize_loop = True\n",
        "    while quantize_loop:\n",
        "        print (\"Starting...\")\n",
        "        model = load_model(filename + \"/\" + filename + '.h5')\n",
        "        monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=quantize_training_patience, verbose=1, mode='auto', restore_best_weights=True)\n",
        "        history = model.fit(trainX, trainY, epochs=quantize_training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1, callbacks=[MyCallback(), monitor])\n",
        "        # learning curves\n",
        "        summarize_diagnostics(history)\n",
        "        # evaluate model\n",
        "        _, test_acc = model.evaluate(testX, testY, verbose=0)\n",
        "        print('Quantize aware training > %.3f' % (current_acc * 100.0))\n",
        "        \n",
        "        if current_acc < test_acc:\n",
        "            current_acc = test_acc\n",
        "            model.save(filename + \"/\" + filename + '.h5')\n",
        "            print_model (model)\n",
        "            print('Save model > %.3f' % (current_acc * 100.0))\n",
        "            quantize_loop = current_acc < pre_acc - max_degradation\n",
        "        \n",
        "    print('Ending quantized aware training > %.3f' % (current_acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the entire model to a HDF5 file.\n",
        "model.save(filename + \"/\" + filename + '.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_______ LOAD CNN MODEL FOR EVALUATION AND CONVERSION TO TF LITE FLOATING-POINT AND FIXED-POINT _______"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCLycpCTcGdR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Predicted: [[1.1118077e-02 4.2626081e-04 6.1177625e-03 3.2010840e-03 8.2191473e-01\n",
            "  3.4573304e-03 9.0579040e-02 1.0590014e-03 4.7753200e-02 1.4373433e-02]]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "img_path = \"dog.jpg\"\n",
        "img = image.load_img(img_path, target_size=(32, 32))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x.astype('float32')\n",
        "x = x / 255.0\n",
        "\n",
        "model = load_model(filename + \"/binary.h5\")\n",
        "\n",
        "output_data = model.predict(x)\n",
        "\n",
        "print('TensorFlow Predicted:', output_data)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_model(model):\n",
        "  for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.SeparableConv2D):\n",
        "      layer_weights = layer.get_weights()\n",
        "      print (layer_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([[[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
            "\n",
            "\n",
            "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  1.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "        [[ 0.,  0.,  0., ...,  0., -1.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
            "\n",
            "\n",
            "       [[[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0., -1., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0.], dtype=float32)]\n",
            "[array([[[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         ...,\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         ...,\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         ...,\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
            "\n",
            "\n",
            "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         ...,\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0., -1.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "        [[ 0.,  0.,  0., ..., -1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         ...,\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         ...,\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
            "\n",
            "\n",
            "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
            "         ...,\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         ...,\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         ...,\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0., ...,  0., -1.,  0.]]]], dtype=float32), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0., -1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "        0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0., -1.,  0.], dtype=float32)]\n",
            "[array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.],\n",
            "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0., -1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0., -1.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "        0., -1.,  0.], dtype=float32)]\n",
            "> 10.000\n"
          ]
        }
      ],
      "source": [
        "print_model (model)\n",
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmFfu4r-dFdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 40)        1120      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 40)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 40)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 40)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 60)        21660     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 60)        240       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 60)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 60)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 120)         64920     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 120)         480       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 120)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 120)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               230520    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1210      \n",
            "=================================================================\n",
            "Total params: 320,310\n",
            "Trainable params: 319,870\n",
            "Non-trainable params: 440\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_23018/502658246.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mcifar_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrepresentative_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m       \u001b[0;31m# strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[0;32m--> 263\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    264\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, utils\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "  print(\"Folder \" + filename + \" does not exist.\")\n",
        "  exit()\n",
        "\n",
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "model = tf.keras.models.load_model(filename + \"/\" + filename + '.h5')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(model, filename + \"/\" + filename + \".png\", show_shapes=True, show_layer_names=True, expand_nested=True)\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255 , test_images / 255\n",
        "\n",
        "train_images = tf.cast(train_images, tf.float32)\n",
        "cifar_ds = tf.data.Dataset.from_tensor_slices((train_images)).batch(1)\n",
        "def representative_dataset():\n",
        "  for input_value in cifar_ds.take(100):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "#converter.representative_dataset = representative_dataset\n",
        "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.float32  # or tf.uint8\n",
        "converter.inference_output_type = tf.float32  # or tf.uint8\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open(filename + \"/\" + filename + \"_f32\" + '.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INb151fxeI6B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpaw40s58t/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpaw40s58t/assets\n",
            "2021-11-12 23:11:07.428143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-12 23:11:07.428853: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2021-11-12 23:11:07.428986: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-11-12 23:11:07.429833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-12 23:11:07.430593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-12 23:11:07.430722: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-12 23:11:07.430784: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 23:11:07.430805: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-12 23:11:07.430819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-12 23:11:07.430867: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 23:11:07.430921: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 23:11:07.430976: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-12 23:11:07.430985: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-12 23:11:07.430999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-12 23:11:07.431004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-11-12 23:11:07.431009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2021-11-12 23:11:07.435891: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2021-11-12 23:11:07.435917: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
            "2021-11-12 23:11:07.435923: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\n",
            "2021-11-12 23:11:07.536979: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\n",
            "2021-11-12 23:11:07.537020: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.float32  # or tf.uint8\n",
        "converter.inference_output_type = tf.float32  # or tf.uint8\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open(filename + \"/\" + filename + \"_i8\" + '.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ4KikJ-fkaU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=filename + \"/\" + filename + \"_i8\" + '.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpXHwv2Tf3yI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Lite Predicted: [[0.         0.         0.05078125 0.08203125 0.17578125 0.20703125\n",
            "  0.37890625 0.09765625 0.         0.00390625]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], x)\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print('TensorFlow Lite Predicted:', output_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "quantized_training.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3ba63467901cd6d3991f497c38810e6d1156dd2dfb6eb0edc80f01dd9606bacd"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
