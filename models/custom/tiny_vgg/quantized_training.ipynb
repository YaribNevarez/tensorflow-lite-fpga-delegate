{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbiM6lilQxtQ",
        "outputId": "ede20a3d-6cc7-4d96-c754-cbc1a79a6008"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-07 22:53:59.414176: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-07 22:53:59.414211: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import SeparableConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jupyter notebook to build, train, and deply CNN models for TF Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IuN7OgXSQ9i2"
      },
      "outputs": [],
      "source": [
        "filename = \"tiny_vgg\" # Set the name for the model output\n",
        "\n",
        "training_batch_size = 20\n",
        "training_epochs = 20\n",
        "\n",
        "early_stop_training = True\n",
        "quantize_aware_training = False\n",
        "\n",
        "target_exponent = 2 # Target exponent bit size for custom floating-point \n",
        "target_mantissa = 5 # Target mantissa bit size for custom floating-point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "google_colab = False # Set True when using on google colab\n",
        "if google_colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CNN ARCHITECTURE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def define_model_CNN():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(40, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(50, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(60, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(120, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(120, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\t#opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\topt = \"adam\"\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quantized aware training method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fh2Y7AaGvoUK"
      },
      "outputs": [],
      "source": [
        "import struct\n",
        "\n",
        "def bin2float(b):\n",
        "    ''' Convert binary string to a float.\n",
        "\n",
        "    Attributes:\n",
        "        :b: Binary string to transform.\n",
        "    '''\n",
        "    h = int(b, 2).to_bytes(8, byteorder=\"big\")\n",
        "    return struct.unpack('>d', h)[0]\n",
        "\n",
        "\n",
        "def float2bin(f):\n",
        "    ''' Convert float to 64-bit binary string.\n",
        "\n",
        "    Attributes:\n",
        "        :f: Float number to transform.\n",
        "    '''\n",
        "    [d] = struct.unpack(\">Q\", struct.pack(\">d\", f))\n",
        "    return f'{d:064b}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7Y8p19yiv2rs"
      },
      "outputs": [],
      "source": [
        "def quantize_float (float_number, exponent_bits, mantissa_bits):\n",
        "    exponent_sign = 1\n",
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
        "    if mantissa_bits < 0:\n",
        "      mantissa_bits = 0\n",
        "    if exponent_bits < 0:\n",
        "      exponent_bits = 0\n",
        "      \n",
        "    coefficient = float2bin(float_number)\n",
        "    sign = int (coefficient[:1], 2)\n",
        "    if 0 < mantissa_bits:\n",
        "        custom_mantissa = int (coefficient[12 : 12 + mantissa_bits], 2)\n",
        "    else:\n",
        "        custom_mantissa = 0\n",
        "    residual_mantissa = int (coefficient[12 + mantissa_bits:], 2)\n",
        "    exponent = int (coefficient[1:12], 2) - 1023\n",
        "\n",
        "    exponent_full_range = pow(2, exponent_bits - exponent_sign) - 1\n",
        "    if exponent < - exponent_full_range:\n",
        "        quantized_value = 0\n",
        "    elif exponent > exponent_full_range:\n",
        "        quantized_value = pow(-1, sign) * (1 + (1 - pow(2, - mantissa_bits))) * pow(2, exponent_full_range)\n",
        "    else:\n",
        "        if (pow (2, (52 - (mantissa_bits + 1))) - 1) < residual_mantissa:\n",
        "            custom_mantissa += 1\n",
        "            if (pow (2, mantissa_bits) - 1) < custom_mantissa:\n",
        "                custom_mantissa = 0\n",
        "                exponent += 1\n",
        "    \n",
        "        quantized_value = pow(-1, sign) * (1 + custom_mantissa * pow(2, - mantissa_bits)) * pow(2, exponent)\n",
        "    return quantized_value\n",
        "\n",
        "def quantize_model(model, exponent_bits, mantissa_bits):\n",
        "  for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "      layer_weight = layer.get_weights()\n",
        "      if len(layer_weight) == 2:\n",
        "        filter_matrix = layer_weight[0]\n",
        "        bias_matrix = layer_weight[1]\n",
        "        if filter_matrix.ndim == 4:\n",
        "          for id_i, i in enumerate(filter_matrix):\n",
        "            for id_j, j in enumerate(i):\n",
        "              for id_k, k in enumerate(j):\n",
        "                for id_l ,l in enumerate(k):\n",
        "                  filter_matrix[id_i][id_j][id_k][id_l] = quantize_float (l, exponent_bits, mantissa_bits)\n",
        "                  bias_matrix[id_l] = quantize_float (bias_matrix[id_l], exponent_bits, mantissa_bits)\n",
        "        layer_weight[0] = filter_matrix\n",
        "        layer_weight[1] = bias_matrix\n",
        "        layer.set_weights(layer_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Early stop callback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vaA7sG9xenUF"
      },
      "outputs": [],
      "source": [
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto', restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mHKtRDtPn0eQ"
      },
      "outputs": [],
      "source": [
        "mantissa_bits = target_mantissa\n",
        "exponent_bits = target_exponent\n",
        "epoch_count = 0\n",
        "quantize = False\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    global epoch_count\n",
        "    global quantize\n",
        "    global mantissa_bits\n",
        "    epoch_count += 1\n",
        "    quantize = 1 < epoch_count\n",
        "    if quantize:\n",
        "      quantize_model(self.model, exponent_bits, mantissa_bits)\n",
        "      #mantissa_bits -= 1\n",
        "  def on_train_end(self, logs={}):\n",
        "    quantize_model(self.model, exponent_bits, mantissa_bits)\n",
        "  def on_batch_end(self, epoch, logs=None):\n",
        "    if quantize:\n",
        "      quantize_model(self.model, exponent_bits, mantissa_bits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WPVVK7cLRHlR"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(filename):\n",
        "  os.mkdir(filename)\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tpyplot.savefig(filename + '/' + filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model_CNN()\n",
        "\t# fit model\n",
        "\thistory = model.fit(trainX, trainY, epochs=20, batch_size=64, validation_data=(testX, testY), verbose=1, callbacks=[MyCallback()])\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\t# Save the entire model to a HDF5 file.\n",
        "\tmodel.save(filename + \"/\" + filename + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsUR8C6RRJVc",
        "outputId": "f4b2312f-ee7b-41d7-8715-6afdbcdb31b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-07 22:54:36.868347: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2021-11-07 22:54:36.927841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-07 22:54:36.930054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-07 22:54:36.932355: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-07 22:54:36.936438: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-07 22:54:36.995822: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-07 22:54:37.014973: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-07 22:54:37.016720: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-07 22:54:37.017119: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-07 22:54:37.020159: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-07 22:54:37.020175: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-07 22:54:37.032138: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-11-07 22:54:37.109765: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2494430000 Hz\n",
            "2021-11-07 22:54:37.111819: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c68c0964c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-07 22:54:37.111840: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-11-07 22:54:37.115969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-07 22:54:37.115983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \n",
            "2021-11-07 22:54:38.911537: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2500/2500 [==============================] - 71s 29ms/step - loss: 1.3375 - accuracy: 0.5175 - val_loss: 1.0508 - val_accuracy: 0.6240\n",
            "Epoch 2/20\n",
            "2500/2500 [==============================] - 76s 31ms/step - loss: 0.9322 - accuracy: 0.6730 - val_loss: 0.9010 - val_accuracy: 0.6860\n",
            "Epoch 3/20\n",
            "2500/2500 [==============================] - 74s 30ms/step - loss: 0.7663 - accuracy: 0.7328 - val_loss: 0.8822 - val_accuracy: 0.6926\n",
            "Epoch 4/20\n",
            "2500/2500 [==============================] - 81s 33ms/step - loss: 0.6608 - accuracy: 0.7681 - val_loss: 0.8303 - val_accuracy: 0.7120\n",
            "Epoch 5/20\n",
            "2500/2500 [==============================] - 87s 35ms/step - loss: 0.5622 - accuracy: 0.8009 - val_loss: 0.8512 - val_accuracy: 0.7159\n",
            "Epoch 6/20\n",
            "2500/2500 [==============================] - 99s 40ms/step - loss: 0.4876 - accuracy: 0.8264 - val_loss: 0.8467 - val_accuracy: 0.7311\n",
            "Epoch 7/20\n",
            "2500/2500 [==============================] - 94s 38ms/step - loss: 0.4218 - accuracy: 0.8499 - val_loss: 0.9151 - val_accuracy: 0.7325\n",
            "Epoch 8/20\n",
            "2500/2500 [==============================] - 97s 39ms/step - loss: 0.3650 - accuracy: 0.8695 - val_loss: 1.0122 - val_accuracy: 0.7036\n",
            "Epoch 9/20\n",
            "2500/2500 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.8851Restoring model weights from the end of the best epoch.\n",
            "2500/2500 [==============================] - 93s 37ms/step - loss: 0.3224 - accuracy: 0.8851 - val_loss: 1.0413 - val_accuracy: 0.7164\n",
            "Epoch 00009: early stopping\n",
            "> 71.200\n"
          ]
        }
      ],
      "source": [
        "# entry point, run the test harness\n",
        "# load dataset\n",
        "trainX, trainY, testX, testY = load_dataset()\n",
        "\n",
        "# prepare pixel data\n",
        "trainX, testX = prep_pixels(trainX, testX)\n",
        "\n",
        "# define model\n",
        "model = define_model_CNN()\n",
        "# fit model\n",
        "\n",
        "if not early_stop_training and not quantize_aware_training:\n",
        "    history = model.fit(trainX, trainY, epochs=training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1)\n",
        "if not early_stop_training and quantize_aware_training:\n",
        "    history = model.fit(trainX, trainY, epochs=training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1, callbacks=[MyCallback()])\n",
        "if early_stop_training and not quantize_aware_training:\n",
        "    history = model.fit(trainX, trainY, epochs=training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1, callbacks=[monitor])    \n",
        "elif early_stop_training and quantize_aware_training:\n",
        "    history = model.fit(trainX, trainY, epochs=training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1, callbacks=[MyCallback(), monitor])\n",
        "else:\n",
        "    print (\"Impossible Error!\")\n",
        "\n",
        "# evaluate model\n",
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))\n",
        "# learning curves\n",
        "summarize_diagnostics(history)\n",
        "# Save the entire model to a HDF5 file.\n",
        "model.save(filename + \"/\" + filename + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GCLycpCTcGdR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Predicted: [[1.69982624e-04 1.73500703e-05 1.17512144e-01 1.51710873e-02\n",
            "  4.22756851e-01 4.02325779e-01 1.32874027e-02 2.86353547e-02\n",
            "  3.30227595e-05 9.09151422e-05]]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "img_path = \"dog.jpg\"\n",
        "img = image.load_img(img_path, target_size=(32, 32))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x.astype('float32')\n",
        "x = x / 255.0\n",
        "\n",
        "model = load_model(filename + \"/\" + filename + '.h5')\n",
        "\n",
        "output_data = model.predict(x)\n",
        "\n",
        "print('TensorFlow Predicted:', output_data)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_model(model):\n",
        "  for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "      layer_weight = layer.get_weights()\n",
        "      if len(layer_weight) == 2:\n",
        "        filter_matrix = layer_weight[0]\n",
        "        bias_matrix = layer_weight[1]\n",
        "        print (filter_matrix)\n",
        "        print (bias_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[[-0.4031566   0.109771   -0.27435508 ... -0.37304878  0.17078745\n",
            "     0.5479573 ]\n",
            "   [ 0.26943073  0.05030951  0.46407261 ...  0.35941005 -0.4416826\n",
            "     0.1516608 ]\n",
            "   [ 0.24178095 -0.05832038 -0.30581546 ...  0.28685135  0.00541239\n",
            "    -0.34124184]]\n",
            "\n",
            "  [[-0.01122501  0.03647713  0.10055883 ...  0.31357613 -0.18109512\n",
            "    -0.05785538]\n",
            "   [-0.28776133 -0.17298912  0.2753972  ...  0.17396557  0.34265742\n",
            "    -0.35993668]\n",
            "   [-0.4259857  -0.24887443  0.39335462 ...  0.12809113 -0.49303973\n",
            "    -0.35041133]]\n",
            "\n",
            "  [[-0.07353748 -0.2385735  -0.30710146 ...  0.15356806  0.15827888\n",
            "     0.09295273]\n",
            "   [-0.05178424 -0.30034685  0.42279163 ... -0.34581825  0.18833531\n",
            "     0.35938504]\n",
            "   [-0.07231412  0.20812413  0.0871422  ...  0.17354047  0.40602916\n",
            "    -0.20495133]]]\n",
            "\n",
            "\n",
            " [[[-0.41996092 -0.12073469 -0.39845118 ... -0.5126185   0.30745792\n",
            "     0.22978128]\n",
            "   [ 0.26310346 -0.1173304  -0.48781013 ...  0.02980684 -0.16281873\n",
            "    -0.3484796 ]\n",
            "   [-0.43079346 -0.00685366 -0.56052077 ...  0.21333349  0.25052166\n",
            "     0.23625124]]\n",
            "\n",
            "  [[-0.47994456 -0.44197184  0.3557709  ... -0.23807251 -0.59172994\n",
            "     0.2322987 ]\n",
            "   [-0.14192183  0.3604541   0.08242305 ... -0.5627704  -0.28350386\n",
            "    -0.28109774]\n",
            "   [-0.25109392 -0.45754284  0.4180994  ... -0.54192424 -0.34261838\n",
            "    -0.02994633]]\n",
            "\n",
            "  [[ 0.24052589  0.3217877  -0.16708183 ...  0.2743455   0.12168126\n",
            "    -0.13460451]\n",
            "   [ 0.24980086 -0.421297    0.41535962 ...  0.23088792  0.06907035\n",
            "    -0.31644198]\n",
            "   [-0.16752754 -0.39955133  0.2689637  ...  0.01248143 -0.22312602\n",
            "     0.37633455]]]\n",
            "\n",
            "\n",
            " [[[ 0.29881707 -0.20722315  0.00474253 ... -0.08429182  0.08544085\n",
            "     0.45184332]\n",
            "   [-0.11239947  0.21555598  0.06155895 ...  0.14629868  0.0612598\n",
            "     0.35306212]\n",
            "   [ 0.16072582  0.4009071   0.04927114 ...  0.12133592  0.4527871\n",
            "    -0.43534097]]\n",
            "\n",
            "  [[ 0.18259872  0.4718847  -0.2647012  ... -0.15776488  0.19996934\n",
            "     0.16539636]\n",
            "   [ 0.12337121  0.12661377 -0.4900543  ...  0.3397608  -0.43222192\n",
            "    -0.30892295]\n",
            "   [ 0.379777    0.05517334 -0.01248629 ...  0.10707812  0.35266623\n",
            "    -0.24383809]]\n",
            "\n",
            "  [[ 0.11434744  0.3106869   0.33104843 ... -0.26860404 -0.13010612\n",
            "    -0.08135128]\n",
            "   [ 0.39101207  0.04215803 -0.32794008 ... -0.10118616  0.32523823\n",
            "    -0.21121505]\n",
            "   [ 0.38310248  0.42800888 -0.3491826  ...  0.14587986 -0.27821735\n",
            "    -0.28188497]]]]\n",
            "[-0.04347     0.02480457  0.038072    0.09172624 -0.0438505  -0.05246571\n",
            "  0.06012945 -0.20460144 -0.04815171 -0.04832394  0.00091223 -0.07136269\n",
            "  0.05370704  0.04120212  0.1051265  -0.04017555  0.044571   -0.13646682\n",
            " -0.01975193 -0.06008663 -0.00214739  0.01640443 -0.04827483 -0.05236425\n",
            " -0.02816027 -0.00931061 -0.2131151  -0.07945478  0.05676261 -0.07971877\n",
            "  0.0128809   0.08288572 -0.02837878 -0.24209851  0.08792655  0.02626054\n",
            "  0.02815934 -0.07553322 -0.00122712  0.05620762]\n",
            "[[[[ 0.03653305 -0.06132758 -0.28868708 ...  0.11028768 -0.14437865\n",
            "     0.08386181]\n",
            "   [ 0.05403435 -0.04306281  0.04771444 ...  0.06216516 -0.26235664\n",
            "    -0.07817026]\n",
            "   [-0.11262681 -0.06136678  0.00401358 ... -0.03693852 -0.04897229\n",
            "    -0.12404653]\n",
            "   ...\n",
            "   [ 0.13725378  0.05197834  0.15367977 ... -0.03199646  0.05973771\n",
            "     0.06845912]\n",
            "   [ 0.02503594 -0.01200208 -0.09790874 ...  0.11978663 -0.0014071\n",
            "    -0.13059106]\n",
            "   [-0.0718437  -0.14517556  0.1068021  ...  0.16832489 -0.32256356\n",
            "    -0.14415464]]\n",
            "\n",
            "  [[-0.19270362 -0.20454378 -0.01143623 ...  0.02202559 -0.23573275\n",
            "    -0.04526427]\n",
            "   [ 0.0755981  -0.07521508  0.00774649 ... -0.11536104 -0.2957533\n",
            "    -0.1236778 ]\n",
            "   [ 0.00962896  0.11298365 -0.02516726 ... -0.08014874  0.15737085\n",
            "    -0.09249706]\n",
            "   ...\n",
            "   [ 0.00424259 -0.06475565  0.12674755 ... -0.18059233  0.07734232\n",
            "    -0.1279225 ]\n",
            "   [ 0.04731326  0.00040815 -0.20395483 ... -0.0915459   0.05433455\n",
            "    -0.05094333]\n",
            "   [ 0.09339482  0.14986682  0.13663638 ... -0.05850122 -0.15241359\n",
            "     0.10028302]]\n",
            "\n",
            "  [[-0.16172294 -0.18059528  0.11604657 ...  0.18226522 -0.2199543\n",
            "    -0.03873629]\n",
            "   [ 0.06998536 -0.21780409  0.09997571 ...  0.04562072 -0.08388927\n",
            "     0.04538975]\n",
            "   [ 0.13002306 -0.11495987 -0.18576357 ... -0.19649395  0.1002907\n",
            "    -0.0904469 ]\n",
            "   ...\n",
            "   [ 0.01466092 -0.13213785 -0.09858474 ...  0.00770485  0.06486759\n",
            "     0.04722977]\n",
            "   [-0.05244921 -0.1521663  -0.31180826 ... -0.04225135  0.09914027\n",
            "     0.06505471]\n",
            "   [-0.03289734  0.02963457 -0.10341686 ...  0.08087312  0.10308681\n",
            "    -0.04630182]]]\n",
            "\n",
            "\n",
            " [[[-0.1015857   0.01420189 -0.19957875 ... -0.18830945  0.05430396\n",
            "     0.0678082 ]\n",
            "   [ 0.08184164  0.04443142 -0.01377281 ... -0.00316529 -0.07383865\n",
            "    -0.151896  ]\n",
            "   [-0.12785289 -0.09782275 -0.12676425 ... -0.10088528 -0.04356256\n",
            "     0.07423275]\n",
            "   ...\n",
            "   [ 0.12738684  0.24805292  0.0117884  ... -0.14079799 -0.00633251\n",
            "     0.00790988]\n",
            "   [ 0.11893558 -0.15998037 -0.35471454 ... -0.00935721 -0.1227105\n",
            "    -0.10023619]\n",
            "   [ 0.13162255 -0.10581278 -0.21482193 ...  0.05916361 -0.26497784\n",
            "    -0.1439975 ]]\n",
            "\n",
            "  [[-0.08349107 -0.12028445 -0.06184954 ...  0.21087363 -0.05466933\n",
            "     0.06374807]\n",
            "   [ 0.0574503  -0.02893881  0.06400026 ...  0.1780593  -0.10838845\n",
            "    -0.02467351]\n",
            "   [-0.14970657  0.02064923  0.03813606 ... -0.12603544 -0.1543726\n",
            "    -0.06631599]\n",
            "   ...\n",
            "   [-0.08272222 -0.10322905 -0.1066773  ... -0.10543178  0.05507436\n",
            "    -0.0657186 ]\n",
            "   [ 0.0656782   0.20677438 -0.11840484 ... -0.23387535  0.03993633\n",
            "    -0.05930647]\n",
            "   [ 0.01941439  0.03399847 -0.17646001 ... -0.04095135  0.02406592\n",
            "     0.00940913]]\n",
            "\n",
            "  [[-0.11299497 -0.16657735 -0.15590583 ...  0.19603826  0.03418384\n",
            "    -0.0268904 ]\n",
            "   [ 0.10513843 -0.14554802 -0.16559432 ...  0.14523359  0.08240604\n",
            "    -0.21900524]\n",
            "   [-0.13248555 -0.01558205 -0.09772568 ... -0.07353148 -0.02177439\n",
            "    -0.14695849]\n",
            "   ...\n",
            "   [-0.3488369  -0.01365883 -0.09688299 ... -0.10805378 -0.03517985\n",
            "    -0.07265731]\n",
            "   [-0.12837425  0.02663383 -0.10949887 ... -0.16159892  0.01348699\n",
            "     0.01469082]\n",
            "   [-0.02575809  0.22591174 -0.10870533 ... -0.1344459   0.18000868\n",
            "     0.09191778]]]\n",
            "\n",
            "\n",
            " [[[ 0.01137739  0.03067941 -0.1842825  ...  0.10636815 -0.06875268\n",
            "    -0.12820232]\n",
            "   [ 0.02863796  0.02000013 -0.24048883 ...  0.23599061 -0.11959401\n",
            "    -0.16181459]\n",
            "   [-0.15715295 -0.14045323  0.12027342 ... -0.11765312 -0.0741445\n",
            "    -0.17458786]\n",
            "   ...\n",
            "   [ 0.13679561 -0.01470161 -0.28479773 ... -0.01458369 -0.00808372\n",
            "    -0.11723387]\n",
            "   [ 0.01420196 -0.06878971 -0.19567966 ... -0.14038876 -0.02303983\n",
            "    -0.05610214]\n",
            "   [-0.0088839  -0.09965249 -0.15697782 ... -0.13245216 -0.18009363\n",
            "    -0.00124384]]\n",
            "\n",
            "  [[-0.04311115 -0.08856594 -0.1071793  ...  0.18794976 -0.1416635\n",
            "    -0.0919584 ]\n",
            "   [ 0.03426069 -0.17315972 -0.32251856 ... -0.04423701 -0.10698641\n",
            "    -0.13500364]\n",
            "   [-0.16868322 -0.04845648  0.2025995  ... -0.15706857  0.10488158\n",
            "    -0.07752001]\n",
            "   ...\n",
            "   [ 0.04039962  0.11808247 -0.18982846 ... -0.11340436 -0.09408198\n",
            "    -0.14023174]\n",
            "   [ 0.07996914  0.09664688 -0.10209286 ... -0.13583235 -0.13302884\n",
            "    -0.02713436]\n",
            "   [ 0.01731379  0.15856203 -0.12459119 ... -0.22289838  0.07605565\n",
            "     0.034918  ]]\n",
            "\n",
            "  [[-0.04267977 -0.02083578  0.02800762 ...  0.04667817  0.02688597\n",
            "     0.0710241 ]\n",
            "   [ 0.04797152 -0.03913005  0.02731646 ... -0.17252831 -0.09067979\n",
            "     0.07017226]\n",
            "   [-0.08629107 -0.05947653  0.06578707 ... -0.08793513 -0.16234806\n",
            "     0.04853953]\n",
            "   ...\n",
            "   [-0.04976892 -0.15619655  0.09338038 ...  0.18599011 -0.03550766\n",
            "     0.0323022 ]\n",
            "   [ 0.02699293 -0.03313003  0.02733392 ... -0.06918565 -0.06545106\n",
            "    -0.11641493]\n",
            "   [-0.0479942   0.07240956 -0.22279912 ...  0.00902994 -0.14454107\n",
            "    -0.00965926]]]]\n",
            "[ 0.14077727 -0.09741691  0.07619268 -0.05101187 -0.06403248 -0.03192643\n",
            " -0.03967997 -0.15276618 -0.07995927  0.03085773 -0.07960241 -0.09005363\n",
            "  0.05876796  0.007844   -0.06024688  0.09663612 -0.10178556 -0.13187736\n",
            "  0.08460009  0.06446321 -0.02003922 -0.06418137  0.01222294 -0.01338157\n",
            " -0.21975395  0.07572462 -0.0116742   0.10494574  0.03268027 -0.05857337\n",
            " -0.00225817  0.15299061 -0.04032327  0.05508226 -0.03019823  0.09965958\n",
            "  0.08453202 -0.06675772  0.03349146 -0.01143614  0.01701636  0.0808588\n",
            "  0.21896312  0.01892641 -0.07142082  0.01317722  0.02736373  0.08250114\n",
            "  0.08057132 -0.03420363]\n",
            "[[[[-1.09741390e-01  1.72907129e-01  5.86819276e-02 ... -9.14447904e-02\n",
            "     1.93792775e-01  1.45531386e-01]\n",
            "   [ 3.97044793e-02 -2.49631971e-01  7.60150999e-02 ... -3.14532578e-01\n",
            "     1.75355852e-01  1.65150672e-01]\n",
            "   [ 7.90128931e-02  1.05540395e-01 -4.24806327e-02 ... -1.13121867e-02\n",
            "     1.18637748e-01  9.04762000e-02]\n",
            "   ...\n",
            "   [ 6.53779730e-02 -1.66374207e-01 -1.25708356e-02 ... -4.52072620e-02\n",
            "    -8.87795463e-02 -9.84426215e-03]\n",
            "   [-2.10970372e-01  1.41090453e-01  2.19567895e-01 ... -2.11788371e-01\n",
            "     7.90278539e-02 -3.76149118e-02]\n",
            "   [ 5.81507236e-02  7.22303707e-03 -7.74678290e-02 ...  4.63930108e-02\n",
            "     9.65311155e-02 -8.68228823e-02]]\n",
            "\n",
            "  [[ 1.97792239e-02  5.96509166e-02  1.27541766e-01 ... -6.44350946e-02\n",
            "     4.87642810e-02 -3.15281332e-01]\n",
            "   [-2.23503977e-01 -1.50321752e-01 -4.44025453e-03 ... -1.60999876e-02\n",
            "     1.15158282e-01 -8.02368224e-02]\n",
            "   [ 2.65442967e-01 -1.02176599e-01  6.03845865e-02 ...  4.03585956e-02\n",
            "     9.30245444e-02 -1.77375957e-01]\n",
            "   ...\n",
            "   [ 1.54674590e-01  2.57470608e-01 -1.21599250e-01 ...  9.77433473e-02\n",
            "    -1.57663912e-01 -1.42762035e-01]\n",
            "   [-2.86816925e-01  6.83059692e-02 -2.00288475e-01 ... -1.54578481e-02\n",
            "     2.75908634e-02 -2.66673882e-02]\n",
            "   [-1.22088818e-02 -5.95428050e-03  9.96834971e-03 ...  9.22847763e-02\n",
            "     3.73130739e-02 -2.10728012e-02]]\n",
            "\n",
            "  [[-7.42241144e-02 -5.12145758e-02  2.10147172e-01 ... -3.21056135e-02\n",
            "     7.69938901e-02  3.97166200e-02]\n",
            "   [-9.05607641e-02  8.41413960e-02  1.14551030e-01 ... -1.62005156e-01\n",
            "     4.20868024e-02 -6.52418053e-03]\n",
            "   [ 1.41190603e-01 -1.40822440e-01  3.76485176e-02 ... -1.13036618e-01\n",
            "     1.51272461e-01 -1.18624546e-01]\n",
            "   ...\n",
            "   [ 1.85427785e-01  1.06217474e-01  9.12776515e-02 ...  1.45249337e-01\n",
            "    -7.65635148e-02  9.69196670e-03]\n",
            "   [-1.60009801e-01  2.48287693e-01 -3.96406412e-01 ...  5.79388216e-02\n",
            "     1.55085176e-01 -8.61796141e-02]\n",
            "   [-6.52475879e-02 -1.20210826e-01  4.54653315e-02 ... -5.37602082e-02\n",
            "     3.63118127e-02  1.15473263e-01]]]\n",
            "\n",
            "\n",
            " [[[-1.82327554e-01  1.05081595e-01 -7.51126856e-02 ... -1.89304993e-01\n",
            "     6.14045411e-02  8.31285790e-02]\n",
            "   [ 9.86158997e-02 -7.30057154e-03 -6.19091131e-02 ... -5.29331416e-02\n",
            "     3.03271525e-02 -2.17787866e-02]\n",
            "   [-1.06106386e-01  7.74946585e-02  9.59271193e-02 ...  1.30438104e-01\n",
            "     6.48143515e-02 -1.13623187e-01]\n",
            "   ...\n",
            "   [ 6.14059716e-02 -6.20022789e-02 -9.97288823e-02 ...  3.00320517e-03\n",
            "    -6.38505295e-02  9.74003300e-02]\n",
            "   [-2.20331609e-01  1.93602949e-01 -6.39419332e-02 ... -1.08300202e-01\n",
            "     8.99933949e-02 -2.13085935e-01]\n",
            "   [-3.98031585e-02  1.02762356e-01 -6.53124154e-02 ...  2.07753316e-03\n",
            "    -9.05269608e-02 -1.11289747e-01]]\n",
            "\n",
            "  [[-2.13038966e-01 -1.45699397e-01 -9.24430713e-02 ... -3.38013843e-02\n",
            "     7.80089274e-02 -1.41346499e-01]\n",
            "   [-8.30040649e-02 -6.37889095e-03 -1.78078532e-01 ... -4.57811765e-02\n",
            "    -5.07002091e-03 -8.81031826e-02]\n",
            "   [-5.41972648e-03 -2.40427554e-01 -3.37184891e-02 ... -1.47253275e-03\n",
            "    -2.58319862e-02 -1.46825001e-01]\n",
            "   ...\n",
            "   [ 9.18242633e-02  2.62126207e-01 -1.13030352e-01 ... -4.53832708e-02\n",
            "    -1.21244574e-02 -2.33175293e-01]\n",
            "   [-2.58609831e-01  6.58665597e-02  2.42255554e-02 ... -1.98670387e-01\n",
            "     1.67980030e-01 -1.25945970e-01]\n",
            "   [-5.41241691e-02  1.08480148e-01  1.85103845e-02 ...  1.10590532e-02\n",
            "    -6.01624437e-02 -5.34139536e-02]]\n",
            "\n",
            "  [[-1.37937292e-01 -2.64994919e-01  8.19422081e-02 ... -2.37903908e-01\n",
            "     3.30716342e-01 -3.14051919e-02]\n",
            "   [-9.06631723e-02  2.27386151e-02  6.76308386e-03 ... -2.27571040e-01\n",
            "     1.71159297e-01 -4.64565977e-02]\n",
            "   [ 3.46860439e-02  5.02190106e-02  7.21249357e-02 ...  1.08238861e-01\n",
            "     1.51089221e-01 -8.56081024e-02]\n",
            "   ...\n",
            "   [ 1.24761626e-01  1.14771679e-01 -3.54888923e-02 ...  1.60600860e-02\n",
            "    -4.22958471e-02 -1.54573023e-01]\n",
            "   [-1.00422218e-01  1.41801879e-01 -1.74768075e-01 ...  3.04172169e-02\n",
            "     3.52867633e-01  7.33330250e-02]\n",
            "   [-4.29895055e-03 -5.38594881e-03  7.27203488e-02 ...  7.17170611e-02\n",
            "     1.03877522e-02 -1.25249490e-01]]]\n",
            "\n",
            "\n",
            " [[[ 8.79629552e-02 -1.53149620e-01 -8.67232084e-02 ... -1.94687262e-01\n",
            "    -1.96308881e-01 -1.65615886e-01]\n",
            "   [-5.10046370e-02  5.29126488e-02  1.75318912e-01 ... -9.11344774e-03\n",
            "    -2.76691988e-02  1.70173515e-02]\n",
            "   [-1.34502277e-01  9.55083445e-02  7.77133331e-02 ...  1.91454086e-02\n",
            "     5.01684397e-02 -9.08469930e-02]\n",
            "   ...\n",
            "   [-7.97494780e-03 -1.36050284e-01  1.98060577e-03 ...  5.26839495e-02\n",
            "    -9.99579802e-02  2.11112633e-01]\n",
            "   [-1.61735013e-01  2.47725114e-01 -2.34602720e-01 ... -3.44721600e-02\n",
            "     8.92794803e-02 -1.00861624e-01]\n",
            "   [-7.26322010e-02 -1.56710744e-02 -3.75373615e-03 ...  5.63447438e-02\n",
            "     2.08955500e-02  4.21146862e-03]]\n",
            "\n",
            "  [[-1.07548267e-01 -2.68314391e-01  1.46064296e-01 ...  8.71419720e-03\n",
            "    -1.90417558e-01  1.05115540e-01]\n",
            "   [-1.84230730e-01  3.15516591e-02  2.03300342e-02 ...  6.02892414e-02\n",
            "    -7.02336505e-02 -1.63945973e-01]\n",
            "   [-3.15229207e-01 -7.38691241e-02  1.43812224e-01 ... -4.29096743e-02\n",
            "     3.24519388e-02  2.72789374e-02]\n",
            "   ...\n",
            "   [ 5.18007949e-02  4.32562120e-02 -1.53954744e-01 ... -2.17667580e-01\n",
            "    -2.15078099e-03 -4.46458682e-02]\n",
            "   [-1.16932437e-01 -1.61869556e-01 -8.66668150e-02 ... -8.46613720e-02\n",
            "     2.86519855e-01 -1.17548957e-01]\n",
            "   [ 2.75486223e-02 -7.42219621e-03 -2.47551128e-02 ...  8.11268687e-02\n",
            "     8.64957124e-02 -7.42085651e-02]]\n",
            "\n",
            "  [[ 2.36307338e-01 -9.64187784e-05  6.10849820e-02 ... -2.44640205e-02\n",
            "     1.20552793e-01  1.88056212e-02]\n",
            "   [-2.55793750e-01 -2.52445936e-02 -4.12616320e-02 ... -2.80245721e-01\n",
            "     5.66422381e-03  4.41587418e-02]\n",
            "   [-1.95480615e-01 -3.41797099e-02  6.14904948e-02 ... -3.65001738e-01\n",
            "     1.71114177e-01 -1.36961490e-01]\n",
            "   ...\n",
            "   [-3.18735018e-02  7.64718233e-03  1.74138203e-01 ... -1.20566659e-01\n",
            "    -9.60063934e-02 -9.50317830e-02]\n",
            "   [-1.30342111e-01 -2.52603125e-02 -3.12130779e-01 ... -9.56391245e-02\n",
            "    -4.48647998e-02 -9.57176276e-03]\n",
            "   [ 1.26644829e-02 -8.44609588e-02 -5.93780205e-02 ... -3.11231855e-02\n",
            "     8.42176452e-02 -1.26002776e-02]]]]\n",
            "[ 0.12968382 -0.0492514   0.13313654  0.02474486  0.06163791 -0.2065791\n",
            "  0.00826642 -0.1714388  -0.06758954 -0.19532053 -0.0251325  -0.03686188\n",
            " -0.2220093  -0.19746356  0.11904216 -0.05768159 -0.04776043 -0.06764655\n",
            "  0.07643074 -0.02076027  0.05769402  0.13787794 -0.05397676 -0.09419612\n",
            " -0.04796717  0.04112679  0.02240807  0.00908488 -0.21516275  0.11163066\n",
            "  0.11183868 -0.23800525  0.08608642 -0.13547704 -0.1390121   0.01986832\n",
            "  0.08719298 -0.07940087 -0.12818703 -0.08223026  0.02823819 -0.06954504\n",
            "  0.01654259 -0.09933147 -0.13178039  0.04823555 -0.02605128 -0.0697743\n",
            "  0.05891875  0.1013218   0.0079752  -0.12132872 -0.00909822  0.2293249\n",
            " -0.0837443   0.01771426  0.00892196  0.11740553  0.19401039  0.0248174 ]\n",
            "[[[[ 2.19099559e-02  1.64829921e-02  1.87480338e-02 ... -1.82849333e-01\n",
            "    -2.62656897e-01 -1.28701001e-01]\n",
            "   [ 2.44830595e-03  3.07675228e-02  6.47544265e-02 ... -9.86337140e-02\n",
            "    -5.51674748e-03  1.61581784e-01]\n",
            "   [ 4.02238453e-03 -9.42820162e-02  5.06535955e-02 ... -1.98950171e-01\n",
            "     1.02301605e-01  1.17929071e-01]\n",
            "   ...\n",
            "   [ 1.55567871e-02  5.91007099e-02  9.68530551e-02 ... -1.19510531e-01\n",
            "    -1.87001321e-02 -2.84791719e-02]\n",
            "   [ 7.41074011e-02  2.34266028e-01 -1.54262319e-01 ...  8.28224942e-02\n",
            "    -1.79328606e-01  9.93857309e-02]\n",
            "   [ 6.74142316e-02  6.13479689e-02 -4.78094928e-02 ...  4.59490120e-02\n",
            "     1.50881484e-01 -2.00684503e-01]]\n",
            "\n",
            "  [[-6.20073825e-02 -4.17489782e-02 -5.86479064e-03 ...  1.40092894e-01\n",
            "     2.85142730e-03  1.75469760e-02]\n",
            "   [ 1.00922883e-01  8.79687518e-02 -1.64215550e-01 ... -5.50451279e-02\n",
            "    -2.03096151e-01 -2.05340102e-01]\n",
            "   [-5.36817312e-03 -1.29069135e-01  1.85330346e-01 ... -3.80564518e-02\n",
            "    -1.14070736e-01  1.46750046e-03]\n",
            "   ...\n",
            "   [-2.16785204e-02  1.56129807e-01  1.48307294e-01 ... -1.55262783e-01\n",
            "    -1.01039581e-01  2.16758735e-02]\n",
            "   [-1.01124302e-01  2.23232269e-01 -1.13013789e-01 ...  9.72663164e-02\n",
            "     6.55223941e-03 -1.76586285e-02]\n",
            "   [-2.08347544e-01  4.73986976e-02  1.54766059e-02 ...  1.30555645e-01\n",
            "     1.57674566e-01 -9.51353610e-02]]\n",
            "\n",
            "  [[ 1.46419927e-01 -1.08869918e-01  6.77045137e-02 ...  2.92563196e-02\n",
            "     1.58488438e-01 -4.30779308e-02]\n",
            "   [-8.82782042e-03  1.32418841e-01 -8.72484073e-02 ...  1.12571032e-03\n",
            "     4.82646525e-02 -6.93486109e-02]\n",
            "   [ 7.85579383e-02 -1.13363639e-01  6.18277751e-02 ... -2.39926744e-02\n",
            "    -5.98820634e-02 -1.05729818e-01]\n",
            "   ...\n",
            "   [-1.54744938e-01  5.30966409e-02 -1.38541743e-01 ...  1.22281939e-01\n",
            "     7.77596757e-02 -1.05959922e-01]\n",
            "   [ 5.19256406e-02  5.49480645e-03  6.16258942e-02 ...  8.11752006e-02\n",
            "    -2.09259734e-01 -2.76060384e-02]\n",
            "   [ 6.85554296e-02  4.15959693e-02 -1.00082070e-01 ...  1.73208520e-01\n",
            "     6.13278449e-02 -1.49711579e-01]]]\n",
            "\n",
            "\n",
            " [[[-1.47634998e-01 -6.69914037e-02 -1.20697394e-02 ... -9.46786478e-02\n",
            "    -5.73992170e-02 -1.38234347e-01]\n",
            "   [-1.58484583e-03 -3.06866411e-02  5.09790964e-02 ... -1.43528357e-01\n",
            "    -9.65218619e-02 -7.91495889e-02]\n",
            "   [-4.13169377e-02  7.83970430e-02 -2.14341539e-03 ...  1.11656122e-01\n",
            "    -1.71311647e-01 -2.49977820e-02]\n",
            "   ...\n",
            "   [-2.76108249e-03 -4.16307300e-02 -2.56861486e-02 ... -3.40344980e-02\n",
            "    -2.09950265e-02 -1.94120929e-01]\n",
            "   [ 3.99013348e-02 -2.64613479e-02 -4.57015820e-02 ... -5.31082302e-02\n",
            "    -2.37264648e-01  1.39101759e-01]\n",
            "   [-1.16427802e-02  2.90627405e-02  1.38278231e-01 ...  8.87152031e-02\n",
            "    -1.15096219e-01 -2.83817053e-01]]\n",
            "\n",
            "  [[-1.97563022e-01  2.47066393e-02 -2.18109205e-01 ... -3.87955131e-03\n",
            "    -1.02984317e-01 -5.11127263e-02]\n",
            "   [ 1.70419827e-01 -1.35354713e-01 -9.36095715e-02 ... -9.10547748e-02\n",
            "     1.87222450e-03  5.15625589e-02]\n",
            "   [ 2.55229941e-04  3.69955540e-01 -4.26641591e-02 ...  9.17041954e-03\n",
            "    -6.26035258e-02  3.29275429e-02]\n",
            "   ...\n",
            "   [-7.79470876e-02  5.74797876e-02 -7.03152269e-02 ... -1.14263743e-01\n",
            "    -1.33239359e-01 -4.76309136e-02]\n",
            "   [-1.96027696e-01 -6.36771768e-02 -3.33415791e-02 ... -9.21137929e-02\n",
            "     2.21716851e-01  1.26205236e-01]\n",
            "   [-1.88863263e-01 -9.64199156e-02 -4.37583588e-02 ... -1.57432109e-01\n",
            "     8.86568800e-02 -4.86855879e-02]]\n",
            "\n",
            "  [[ 1.26418527e-02 -9.32288170e-02 -1.82185024e-01 ...  4.53540757e-02\n",
            "    -2.07068548e-02  3.43192089e-03]\n",
            "   [ 3.08458079e-02 -1.52233057e-02  1.24213938e-02 ...  3.21970508e-02\n",
            "     1.45229384e-01  2.24793285e-01]\n",
            "   [ 4.71649412e-03 -8.20581988e-02  6.30489513e-02 ...  1.07140929e-01\n",
            "    -4.40316498e-02 -1.98002219e-01]\n",
            "   ...\n",
            "   [-6.97143450e-02 -3.61466229e-01 -4.59025167e-02 ... -5.51140457e-02\n",
            "     5.49653172e-02 -1.01034746e-01]\n",
            "   [-1.47480592e-01 -2.37586364e-01 -2.17069266e-03 ... -3.96928005e-02\n",
            "    -7.40741864e-02  2.47477051e-02]\n",
            "   [-9.53910202e-02  1.20579846e-01 -2.80000269e-02 ... -1.41508922e-01\n",
            "    -3.41588736e-01  3.08444593e-02]]]\n",
            "\n",
            "\n",
            " [[[-4.54622246e-02 -1.34692013e-01 -1.71964839e-01 ... -8.57108533e-02\n",
            "    -1.38499275e-01 -1.18419930e-01]\n",
            "   [ 6.17542677e-02 -1.46246993e-03  2.83465743e-01 ...  1.83856323e-01\n",
            "    -4.49458957e-02  9.63853374e-02]\n",
            "   [ 2.00221166e-02  2.08430260e-01 -1.70880914e-01 ...  1.40612021e-01\n",
            "    -1.58141494e-01  1.89765003e-02]\n",
            "   ...\n",
            "   [ 1.12799369e-02  1.29064143e-01  1.14721484e-01 ...  5.46281412e-02\n",
            "    -3.52750644e-02 -7.49244913e-02]\n",
            "   [-5.96624985e-02 -3.46257269e-01  1.23177856e-01 ... -1.23695493e-01\n",
            "     1.94271743e-01  1.99398279e-01]\n",
            "   [-2.03631427e-02  8.54110569e-02 -1.79121289e-02 ...  3.63179483e-02\n",
            "    -8.33684579e-03 -1.67373821e-01]]\n",
            "\n",
            "  [[ 7.29295388e-02  1.29454732e-01 -2.44354419e-02 ... -9.04898122e-02\n",
            "    -2.68488564e-02  1.26749039e-01]\n",
            "   [ 9.87761766e-02  5.07574789e-02 -4.26788256e-02 ... -9.37142745e-02\n",
            "     1.61815330e-01  6.46903887e-02]\n",
            "   [-1.48318216e-01  1.27987832e-01  6.45695478e-02 ... -1.00197889e-01\n",
            "     4.25466988e-03 -1.13567017e-01]\n",
            "   ...\n",
            "   [-1.86268061e-01  5.82537986e-03  8.09673443e-02 ...  1.18097430e-02\n",
            "     9.08680186e-02 -1.68325692e-01]\n",
            "   [ 9.15835984e-03  1.70729961e-02 -1.05748899e-01 ...  1.41956434e-01\n",
            "     1.60991978e-02  1.87942132e-01]\n",
            "   [ 5.66659980e-02 -1.34950578e-01 -4.84611653e-02 ...  3.69128287e-02\n",
            "    -2.74102271e-01  1.23821804e-02]]\n",
            "\n",
            "  [[-1.18325530e-02  2.16410875e-01  1.30408853e-02 ... -4.95398380e-02\n",
            "     1.79087579e-01 -1.62803773e-02]\n",
            "   [-1.95387065e-01 -1.13181390e-01 -1.42327443e-01 ...  1.58682704e-01\n",
            "     1.35614097e-01 -1.91313341e-01]\n",
            "   [ 7.07590505e-02 -1.23678081e-01  4.02542278e-02 ... -1.50616303e-01\n",
            "     9.65555832e-02 -1.33884951e-01]\n",
            "   ...\n",
            "   [-1.85574517e-01  4.17243652e-02 -1.02509312e-01 ... -2.41973698e-02\n",
            "     1.65544450e-01 -7.74459466e-02]\n",
            "   [-4.36265655e-02 -1.31302044e-01  1.67063355e-01 ... -1.66062251e-01\n",
            "    -7.28981895e-03 -1.70729786e-01]\n",
            "   [ 5.62673211e-02  3.05155795e-02  3.04377545e-02 ...  9.31054056e-02\n",
            "    -1.63900629e-01  4.10916805e-02]]]]\n",
            "[-0.01002774  0.21151091  0.2127518   0.06359511  0.288989    0.22234792\n",
            "  0.00802322  0.0737776   0.06135698  0.04401423 -0.02601117  0.05306249\n",
            "  0.15063033  0.08264596 -0.00110886  0.21711735  0.0781609   0.10340932\n",
            "  0.03088163  0.21891609  0.0852771   0.09723344  0.04873255  0.04500313\n",
            "  0.1514455   0.2035884   0.1142362   0.22468589  0.00378471  0.04596418\n",
            "  0.05884159  0.00757183 -0.00545653  0.15975633  0.04292085  0.19831254\n",
            "  0.26762775  0.11144581  0.27982005  0.14485772 -0.11875471  0.1823942\n",
            " -0.06966545  0.01938692  0.02726861 -0.06616192  0.10174322  0.10924543\n",
            "  0.02643447  0.0983272   0.20050219  0.31866807  0.26657426  0.24743389\n",
            "  0.04366611  0.17947274  0.09154459  0.25690392 -0.09315757 -0.08053289\n",
            "  0.00681235  0.03976084 -0.04192552  0.17306633 -0.01633862  0.02394378\n",
            "  0.31744534  0.06847163 -0.06417789  0.17054354  0.15203913  0.29185113\n",
            "  0.07236636  0.22141975  0.07961486  0.08426709  0.1229246   0.14611286\n",
            " -0.06202727  0.21817112  0.21409723  0.0139175   0.04555594  0.03745639\n",
            "  0.18833028  0.09148829  0.06020819 -0.10044686  0.11738618  0.00582217\n",
            "  0.07450165 -0.04497394  0.0610517   0.07006551  0.03606163  0.05720939\n",
            "  0.16310453  0.12390324  0.085026   -0.03218018 -0.04970918  0.10931295\n",
            " -0.0482645   0.04668062  0.1769655   0.07494359  0.24610235  0.0719291\n",
            "  0.17443791 -0.05524569  0.01153962 -0.01762249  0.05144924  0.25155273\n",
            " -0.00347358  0.12299316 -0.02004736  0.04068734  0.04689898  0.09976762]\n",
            "> 71.200\n"
          ]
        }
      ],
      "source": [
        "print_model (model)\n",
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GmFfu4r-dFdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 40)        1120      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 40)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 50)        18050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 50)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 60)          27060     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 60)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 120)         64920     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               230520    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1210      \n",
            "=================================================================\n",
            "Total params: 342,880\n",
            "Trainable params: 342,880\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, utils\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "  print(\"Folder \" + filename + \" does not exist.\")\n",
        "  exit()\n",
        "\n",
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "model = tf.keras.models.load_model(filename + \"/\" + filename + '.h5')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(model, filename + \"/\" + filename + \".png\", show_shapes=True, show_layer_names=True, expand_nested=True)\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255 , test_images / 255\n",
        "\n",
        "train_images = tf.cast(train_images, tf.float32)\n",
        "cifar_ds = tf.data.Dataset.from_tensor_slices((train_images)).batch(1)\n",
        "def representative_dataset():\n",
        "  for input_value in cifar_ds.take(100):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "#converter.representative_dataset = representative_dataset\n",
        "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.float32  # or tf.uint8\n",
        "converter.inference_output_type = tf.float32  # or tf.uint8\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open(filename + \"/\" + filename + \"_f32\" + '.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INb151fxeI6B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp5eivkfnf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp5eivkfnf/assets\n",
            "2021-11-05 04:34:29.072093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-05 04:34:29.072780: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2021-11-05 04:34:29.072900: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-11-05 04:34:29.073691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-05 04:34:29.074365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-05 04:34:29.074473: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-05 04:34:29.074541: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-05 04:34:29.074567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-05 04:34:29.074584: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-05 04:34:29.074632: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-05 04:34:29.074705: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-05 04:34:29.074760: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-05 04:34:29.074767: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-05 04:34:29.074779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-05 04:34:29.074784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-11-05 04:34:29.074789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2021-11-05 04:34:29.076157: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2021-11-05 04:34:29.076179: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
            "2021-11-05 04:34:29.076184: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
            "2021-11-05 04:34:29.142050: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\n",
            "2021-11-05 04:34:29.142095: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\n",
            "2021-11-05 04:34:29.497839: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.float32  # or tf.uint8\n",
        "converter.inference_output_type = tf.float32  # or tf.uint8\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open(filename + \"/\" + filename + \"_i8\" + '.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ4KikJ-fkaU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=filename + \"/\" + filename + \"_i8\" + '.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpXHwv2Tf3yI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Lite Predicted: [[0.         0.         0.00390625 0.00390625 0.03125    0.046875\n",
            "  0.91015625 0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], x)\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print('TensorFlow Lite Predicted:', output_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "quantized_training.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3ba63467901cd6d3991f497c38810e6d1156dd2dfb6eb0edc80f01dd9606bacd"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
