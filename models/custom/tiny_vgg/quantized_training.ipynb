{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbiM6lilQxtQ",
        "outputId": "ede20a3d-6cc7-4d96-c754-cbc1a79a6008"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import SeparableConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jupyter notebook to build, train, and deply CNN models for TF Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IuN7OgXSQ9i2"
      },
      "outputs": [],
      "source": [
        "filename = \"tiny_vgg_q\" # Set the name for the model output\n",
        "\n",
        "early_stop_training = True # Early stop training\n",
        "\n",
        "#___________________________\n",
        "training_batch_size = 20\n",
        "training_epochs = 100\n",
        "training_patience = 10\n",
        "\n",
        "#___________________________\n",
        "quantize_aware_training = True\n",
        "quantize_training_epochs = 20\n",
        "quantize_training_patience = 5\n",
        "\n",
        "target_exponent = 5 # Target exponent bit size for custom floating-point \n",
        "target_mantissa = 2 # Target mantissa bit size for custom floating-point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "google_colab = False # Set True when using on google colab\n",
        "if google_colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CNN ARCHITECTURE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def define_model_CNN():\n",
        "\tmodel = Sequential()\n",
        "\t\n",
        "\tmodel.add(Conv2D(40, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Conv2D(60, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Conv2D(120, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(120, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\t#opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\topt = \"adam\"\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quantized aware training method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fh2Y7AaGvoUK"
      },
      "outputs": [],
      "source": [
        "import struct\n",
        "\n",
        "def bin2float(b):\n",
        "    ''' Convert binary string to a float.\n",
        "\n",
        "    Attributes:\n",
        "        :b: Binary string to transform.\n",
        "    '''\n",
        "    h = int(b, 2).to_bytes(8, byteorder=\"big\")\n",
        "    return struct.unpack('>d', h)[0]\n",
        "\n",
        "\n",
        "def float2bin(f):\n",
        "    ''' Convert float to 64-bit binary string.\n",
        "\n",
        "    Attributes:\n",
        "        :f: Float number to transform.\n",
        "    '''\n",
        "    [d] = struct.unpack(\">Q\", struct.pack(\">d\", f))\n",
        "    return f'{d:064b}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7Y8p19yiv2rs"
      },
      "outputs": [],
      "source": [
        "def quantize_float (float_number, exponent_bits, mantissa_bits):\n",
        "    exponent_sign = 1\n",
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
        "    if mantissa_bits < 0:\n",
        "      mantissa_bits = 0\n",
        "    if exponent_bits < 0:\n",
        "      exponent_bits = 0\n",
        "      \n",
        "    coefficient = float2bin(float_number)\n",
        "    sign = int (coefficient[:1], 2)\n",
        "    if 0 < mantissa_bits:\n",
        "        custom_mantissa = int (coefficient[12 : 12 + mantissa_bits], 2)\n",
        "    else:\n",
        "        custom_mantissa = 0\n",
        "    residual_mantissa = int (coefficient[12 + mantissa_bits:], 2)\n",
        "    exponent = int (coefficient[1:12], 2) - 1023\n",
        "\n",
        "    exponent_full_range = pow(2, exponent_bits - exponent_sign) - 1\n",
        "    if exponent < - exponent_full_range:\n",
        "        quantized_value = 0\n",
        "    elif exponent > exponent_full_range:\n",
        "        quantized_value = pow(-1, sign) * (1 + (1 - pow(2, - mantissa_bits))) * pow(2, exponent_full_range)\n",
        "    else:\n",
        "        if (pow (2, (52 - (mantissa_bits + 1))) - 1) < residual_mantissa:\n",
        "            custom_mantissa += 1\n",
        "            if (pow (2, mantissa_bits) - 1) < custom_mantissa:\n",
        "                custom_mantissa = 0\n",
        "                exponent += 1\n",
        "    \n",
        "        quantized_value = pow(-1, sign) * (1 + custom_mantissa * pow(2, - mantissa_bits)) * pow(2, exponent)\n",
        "    return quantized_value\n",
        "\n",
        "def quantize_model(model, exponent_bits, mantissa_bits):\n",
        "  for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "      layer_weight = layer.get_weights()\n",
        "      if len(layer_weight) == 2:\n",
        "        filter_matrix = layer_weight[0]\n",
        "        bias_matrix = layer_weight[1]\n",
        "        if filter_matrix.ndim == 4:\n",
        "          for id_i, i in enumerate(filter_matrix):\n",
        "            for id_j, j in enumerate(i):\n",
        "              for id_k, k in enumerate(j):\n",
        "                for id_l ,l in enumerate(k):\n",
        "                  filter_matrix[id_i][id_j][id_k][id_l] = quantize_float (l, exponent_bits, mantissa_bits)\n",
        "                  bias_matrix[id_l] = quantize_float (bias_matrix[id_l], exponent_bits, mantissa_bits)\n",
        "        layer_weight[0] = filter_matrix\n",
        "        layer_weight[1] = bias_matrix\n",
        "        layer.set_weights(layer_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Early stop callback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vaA7sG9xenUF"
      },
      "outputs": [],
      "source": [
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, verbose=1, mode='auto', restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mHKtRDtPn0eQ"
      },
      "outputs": [],
      "source": [
        "mantissa_bits = target_mantissa\n",
        "exponent_bits = target_exponent\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    quantize_model(self.model, exponent_bits, mantissa_bits)\n",
        "  def on_train_end(self, logs={}):\n",
        "    quantize_model(self.model, exponent_bits, mantissa_bits)\n",
        "  def on_batch_end(self, epoch, logs=None):\n",
        "    quantize_model(self.model, exponent_bits, mantissa_bits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WPVVK7cLRHlR"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(filename):\n",
        "  os.mkdir(filename)\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tf = pyplot.figure()\n",
        "\tf.set_figwidth(10)\n",
        "\tf.set_figheight(20)\n",
        "\t\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tpyplot.savefig(filename + '/' + filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model_CNN()\n",
        "\t# fit model\n",
        "\thistory = model.fit(trainX, trainY, epochs=20, batch_size=64, validation_data=(testX, testY), verbose=1, callbacks=[MyCallback()])\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\t# Save the entire model to a HDF5 file.\n",
        "\tmodel.save(filename + \"/\" + filename + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'define_model_CNN' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_22199/875371568.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_model_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'define_model_CNN' is not defined"
          ]
        }
      ],
      "source": [
        "# entry point, run the test harness\n",
        "# load dataset\n",
        "trainX, trainY, testX, testY = load_dataset()\n",
        "\n",
        "# prepare pixel data\n",
        "trainX, testX = prep_pixels(trainX, testX)\n",
        "\n",
        "# define model\n",
        "model = define_model_CNN()\n",
        "# fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsUR8C6RRJVc",
        "outputId": "f4b2312f-ee7b-41d7-8715-6afdbcdb31b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-10 18:28:28.120107: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2500/2500 [==============================] - ETA: 0s - loss: 1.7149 - accuracy: 0.4018"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-10 18:33:26.449827: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 122880000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2500/2500 [==============================] - 310s 124ms/step - loss: 1.7149 - accuracy: 0.4018 - val_loss: 1.3638 - val_accuracy: 0.5107\n",
            "Epoch 2/20\n",
            "2500/2500 [==============================] - 304s 122ms/step - loss: 1.3168 - accuracy: 0.5381 - val_loss: 1.4838 - val_accuracy: 0.5675\n",
            "Epoch 3/20\n",
            "2500/2500 [==============================] - 314s 126ms/step - loss: 1.1729 - accuracy: 0.5953 - val_loss: 0.9918 - val_accuracy: 0.6675\n",
            "Epoch 4/20\n",
            "2500/2500 [==============================] - 319s 128ms/step - loss: 1.0756 - accuracy: 0.6306 - val_loss: 1.1389 - val_accuracy: 0.6426\n",
            "Epoch 5/20\n",
            "2500/2500 [==============================] - 293s 117ms/step - loss: 0.9988 - accuracy: 0.6615 - val_loss: 0.8540 - val_accuracy: 0.7163\n",
            "Epoch 6/20\n",
            "2500/2500 [==============================] - 295s 118ms/step - loss: 0.9320 - accuracy: 0.6828 - val_loss: 0.9444 - val_accuracy: 0.7124\n",
            "Epoch 7/20\n",
            "2500/2500 [==============================] - 292s 117ms/step - loss: 0.8756 - accuracy: 0.7023 - val_loss: 0.8734 - val_accuracy: 0.7225\n",
            "Epoch 8/20\n",
            "2500/2500 [==============================] - 290s 116ms/step - loss: 0.8325 - accuracy: 0.7159 - val_loss: 0.7403 - val_accuracy: 0.7448\n",
            "Epoch 9/20\n",
            "2500/2500 [==============================] - 332s 133ms/step - loss: 0.7883 - accuracy: 0.7314 - val_loss: 0.6862 - val_accuracy: 0.7741\n",
            "Epoch 10/20\n",
            "2500/2500 [==============================] - 322s 129ms/step - loss: 0.7450 - accuracy: 0.7481 - val_loss: 0.8837 - val_accuracy: 0.7317\n",
            "Epoch 11/20\n",
            "2500/2500 [==============================] - 330s 132ms/step - loss: 0.7107 - accuracy: 0.7587 - val_loss: 0.7276 - val_accuracy: 0.7582\n",
            "Epoch 12/20\n",
            "2500/2500 [==============================] - 332s 133ms/step - loss: 0.6690 - accuracy: 0.7735 - val_loss: 0.8366 - val_accuracy: 0.7328\n",
            "Epoch 13/20\n",
            "2500/2500 [==============================] - 349s 140ms/step - loss: 0.6425 - accuracy: 0.7812 - val_loss: 0.8958 - val_accuracy: 0.7387\n",
            "Epoch 14/20\n",
            "2500/2500 [==============================] - 355s 142ms/step - loss: 0.6224 - accuracy: 0.7866 - val_loss: 0.6218 - val_accuracy: 0.7991\n",
            "Epoch 15/20\n",
            "2500/2500 [==============================] - 267s 107ms/step - loss: 0.5914 - accuracy: 0.7991 - val_loss: 0.6660 - val_accuracy: 0.7818\n",
            "Epoch 16/20\n",
            "2500/2500 [==============================] - 250s 100ms/step - loss: 0.5727 - accuracy: 0.8051 - val_loss: 0.6512 - val_accuracy: 0.7907\n",
            "Epoch 17/20\n",
            "2500/2500 [==============================] - 272s 109ms/step - loss: 0.5471 - accuracy: 0.8134 - val_loss: 0.6445 - val_accuracy: 0.7939\n",
            "Epoch 18/20\n",
            "2500/2500 [==============================] - 271s 109ms/step - loss: 0.5302 - accuracy: 0.8174 - val_loss: 0.6069 - val_accuracy: 0.7963\n",
            "Epoch 19/20\n",
            "2500/2500 [==============================] - 304s 122ms/step - loss: 0.5167 - accuracy: 0.8224 - val_loss: 0.5996 - val_accuracy: 0.8038\n",
            "Epoch 20/20\n",
            "2500/2500 [==============================] - 339s 136ms/step - loss: 0.5020 - accuracy: 0.8283 - val_loss: 0.5868 - val_accuracy: 0.8073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-10 20:10:52.910363: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 122880000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> 80.730\n"
          ]
        }
      ],
      "source": [
        "if not early_stop_training:\n",
        "    history = model.fit(trainX, trainY, epochs=training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1)\n",
        "else:\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=training_patience, verbose=1, mode='auto', restore_best_weights=True)\n",
        "    history = model.fit(trainX, trainY, epochs=training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1, callbacks=[monitor])\n",
        "\n",
        "# evaluate model\n",
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('Pre-quantization training > %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# learning curves\n",
        "summarize_diagnostics(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_______ Post-training quantization _______\n",
            "Post-training quantization > 80.090\n"
          ]
        }
      ],
      "source": [
        "if not quantize_aware_training:\n",
        "    print (\"_______ Post-training quantization _______\")\n",
        "    quantize_model(model, exponent_bits, mantissa_bits)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "    print('Post-training quantization > %.3f' % (acc * 100.0))\n",
        "else:\n",
        "    print (\"_______ Quantize aware training _______\")\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=quantize_training_patience, verbose=1, mode='auto', restore_best_weights=True)\n",
        "    history = model.fit(trainX, trainY, epochs=quantize_training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1, callbacks=[MyCallback(), monitor])\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "    print('Quantize aware training > %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the entire model to a HDF5 file.\n",
        "model.save(filename + \"/\" + filename + '.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_______ LOAD CNN MODEL FOR EVALUATION AND CONVERSION TO TF LITE FLOATING-POINT AND FIXED-POINT _______"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GCLycpCTcGdR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-11 01:16:18.929698: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2021-11-11 01:16:18.966076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-11 01:16:18.967451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-11 01:16:18.967618: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-11 01:16:18.968269: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-11 01:16:19.011153: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-11 01:16:19.018068: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-11 01:16:19.042868: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-11 01:16:19.043142: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-11 01:16:19.079815: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-11 01:16:19.079850: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-11 01:16:19.082174: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-11-11 01:16:19.146665: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2494200000 Hz\n",
            "2021-11-11 01:16:19.148015: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558d14be26c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-11 01:16:19.148036: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-11-11 01:16:19.150851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-11 01:16:19.150866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Predicted: [[1.5144495e-05 3.9155074e-07 2.9066799e-03 4.8440439e-03 8.9457666e-04\n",
            "  9.8720443e-01 2.0172596e-03 2.1131528e-03 2.4682145e-06 1.7672298e-06]]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "img_path = \"dog.jpg\"\n",
        "img = image.load_img(img_path, target_size=(32, 32))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x.astype('float32')\n",
        "x = x / 255.0\n",
        "\n",
        "model = load_model(filename + \"/\" + filename + '.h5')\n",
        "\n",
        "output_data = model.predict(x)\n",
        "\n",
        "print('TensorFlow Predicted:', output_data)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_model(model):\n",
        "  for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "      layer_weight = layer.get_weights()\n",
        "      if len(layer_weight) == 2:\n",
        "        filter_matrix = layer_weight[0]\n",
        "        bias_matrix = layer_weight[1]\n",
        "        print (filter_matrix)\n",
        "        print (bias_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[[ 5.0000000e-01 -3.7500000e-01  7.5000000e-01 ... -2.1875000e-01\n",
            "     5.0000000e-01  1.0937500e-01]\n",
            "   [ 5.0000000e-01  2.1875000e-01  4.3750000e-01 ... -3.1250000e-02\n",
            "     4.3750000e-01 -2.5000000e-01]\n",
            "   [ 7.8125000e-02 -3.1250000e-01  3.1250000e-01 ...  2.1875000e-01\n",
            "     3.7500000e-01 -1.0937500e-01]]\n",
            "\n",
            "  [[ 1.5625000e-01  1.2500000e-01 -1.8750000e-01 ... -1.8750000e-01\n",
            "     2.5000000e-01 -2.1875000e-01]\n",
            "   [-2.1875000e-01  6.2500000e-01  3.1250000e-01 ... -4.3750000e-01\n",
            "     3.1250000e-01  2.1875000e-01]\n",
            "   [-3.1250000e-01 -5.0000000e-01 -2.5000000e-01 ...  6.2500000e-01\n",
            "     1.5625000e-01  5.0000000e-01]]\n",
            "\n",
            "  [[ 6.2500000e-01 -4.3750000e-01 -3.7500000e-01 ... -5.0000000e-01\n",
            "    -1.0937500e-01 -6.2500000e-01]\n",
            "   [ 6.2500000e-01  4.3750000e-01 -1.5625000e-01 ... -7.8125000e-02\n",
            "    -2.5000000e-01  4.3750000e-01]\n",
            "   [ 3.7500000e-01  1.2500000e-01  2.5000000e-01 ...  5.0000000e-01\n",
            "    -1.5625000e-01  3.1250000e-01]]]\n",
            "\n",
            "\n",
            " [[[ 2.1875000e-01 -4.3750000e-01 -5.0000000e-01 ...  2.5000000e-01\n",
            "    -5.0000000e-01 -3.7500000e-01]\n",
            "   [-3.1250000e-01  3.1250000e-01 -1.2500000e-01 ...  1.8310547e-04\n",
            "    -1.5625000e-01 -6.2500000e-01]\n",
            "   [ 2.5000000e-01 -3.7500000e-01 -1.8750000e-01 ... -3.7500000e-01\n",
            "    -1.8750000e-01 -4.3750000e-01]]\n",
            "\n",
            "  [[-6.2500000e-01 -5.0000000e-01 -5.0000000e-01 ...  4.3750000e-01\n",
            "     5.0000000e-01  5.0000000e-01]\n",
            "   [-1.5625000e-01 -6.2500000e-02 -4.3750000e-01 ... -3.7500000e-01\n",
            "    -3.1250000e-01  3.1250000e-01]\n",
            "   [-2.1875000e-01 -4.3750000e-01  1.2500000e-01 ...  3.1250000e-02\n",
            "     3.7500000e-01 -1.0937500e-01]]\n",
            "\n",
            "  [[-3.1250000e-02 -7.5000000e-01  1.8750000e-01 ...  1.8750000e-01\n",
            "     7.8125000e-02  5.4687500e-02]\n",
            "   [-5.0000000e-01  3.7500000e-01  2.5000000e-01 ... -1.9531250e-02\n",
            "     3.7500000e-01  6.2500000e-01]\n",
            "   [ 3.1250000e-01 -2.5000000e-01  3.1250000e-01 ...  3.9062500e-02\n",
            "    -1.7089844e-03 -1.0937500e-01]]]\n",
            "\n",
            "\n",
            " [[[-2.5000000e-01  3.7500000e-01  2.5000000e-01 ...  3.7500000e-01\n",
            "    -3.1250000e-01 -1.8750000e-01]\n",
            "   [-3.7500000e-01  1.5625000e-01 -3.1250000e-01 ... -4.6875000e-02\n",
            "    -5.4687500e-02 -6.2500000e-02]\n",
            "   [ 3.1250000e-01  5.4687500e-02 -3.1250000e-01 ... -2.5000000e-01\n",
            "    -1.0937500e-01 -2.5000000e-01]]\n",
            "\n",
            "  [[-4.3750000e-01  3.1250000e-01 -1.5625000e-01 ...  5.0000000e-01\n",
            "    -4.3750000e-01  9.3750000e-02]\n",
            "   [-1.8750000e-01  2.5000000e-01  7.5000000e-01 ... -5.0000000e-01\n",
            "    -6.2500000e-01 -3.7500000e-01]\n",
            "   [-2.5000000e-01  3.1250000e-01  7.8125000e-02 ... -3.1250000e-01\n",
            "     7.8125000e-02 -4.3750000e-01]]\n",
            "\n",
            "  [[ 1.8750000e-01  3.7500000e-01 -1.9531250e-02 ... -9.3750000e-02\n",
            "     2.1875000e-01  4.3750000e-01]\n",
            "   [-1.8750000e-01 -6.2500000e-02  2.5000000e-01 ...  2.7343750e-02\n",
            "    -2.1875000e-01 -6.2500000e-02]\n",
            "   [-5.4687500e-02  3.7500000e-01 -3.7500000e-01 ...  1.5625000e-01\n",
            "    -3.1250000e-01  4.3750000e-01]]]]\n",
            "[ 0.125       0.09375     0.15625     0.3125      0.03125    -0.125\n",
            "  0.0625      0.0625     -0.078125   -0.125       0.125       0.0625\n",
            "  0.046875    0.0390625   0.046875    0.09375     0.0234375   0.09375\n",
            " -0.125       0.0390625   0.109375    0.15625     0.0546875   0.09375\n",
            "  0.03125     0.25       -0.125       0.03125     0.09375     0.15625\n",
            "  0.25       -0.00341797  0.1875     -0.00146484  0.0625      0.03125\n",
            "  0.0625     -0.1875      0.09375    -0.3125      0.21875    -0.046875\n",
            "  0.109375   -0.625       0.1875     -0.01171875  0.09375     0.21875\n",
            "  0.0546875   0.25       -0.25        0.125       0.03125     0.078125\n",
            "  0.078125    0.125      -0.0078125   0.0234375   0.109375    0.078125\n",
            "  0.125       0.0234375   0.21875     0.25      ]\n",
            "[[[[-6.2500000e-01  1.2207031e-03  1.0937500e-01 ... -3.1250000e-01\n",
            "     7.8125000e-03 -1.0937500e-01]\n",
            "   [ 1.8750000e-01  4.3750000e-01 -4.3750000e-01 ...  1.5625000e-01\n",
            "     2.5000000e-01  3.4179688e-03]\n",
            "   [-4.3750000e-01  1.0937500e-01  1.0937500e-01 ... -7.8125000e-03\n",
            "     2.5000000e-01 -7.8125000e-02]\n",
            "   ...\n",
            "   [-3.7500000e-01  5.4687500e-02  6.2500000e-02 ... -4.6875000e-02\n",
            "     3.1250000e-01 -4.3750000e-01]\n",
            "   [-4.3750000e-01 -9.3750000e-02  1.0937500e-01 ... -6.2500000e-01\n",
            "    -1.5625000e-01  3.9062500e-02]\n",
            "   [-1.5625000e-01  6.2500000e-01 -5.0000000e-01 ... -1.8750000e-01\n",
            "     1.8750000e-01 -3.1250000e-01]]\n",
            "\n",
            "  [[-5.0000000e-01 -3.9062500e-03  2.1875000e-01 ... -2.1875000e-01\n",
            "    -1.8750000e-01 -1.0937500e-01]\n",
            "   [ 5.4687500e-02  1.5625000e-01 -1.5625000e-01 ... -9.3750000e-02\n",
            "     1.8750000e-01  1.5625000e-01]\n",
            "   [-3.1250000e-01  1.2500000e-01  3.1250000e-01 ... -1.5625000e-01\n",
            "    -9.3750000e-02 -2.7343750e-02]\n",
            "   ...\n",
            "   [-1.5625000e-01 -1.2500000e-01  1.0937500e-01 ...  3.9062500e-02\n",
            "     2.5000000e-01 -2.5000000e-01]\n",
            "   [-4.3750000e-01 -1.8750000e-01  2.7343750e-02 ...  3.1250000e-02\n",
            "     1.0937500e-01 -1.5625000e-01]\n",
            "   [-9.3750000e-02  3.1250000e-01  1.5625000e-01 ... -5.0000000e-01\n",
            "    -5.0000000e-01  1.5625000e-02]]\n",
            "\n",
            "  [[-3.1250000e-01  7.8125000e-02 -2.1875000e-01 ... -1.2500000e-01\n",
            "     3.1250000e-01  3.9062500e-02]\n",
            "   [ 3.9062500e-02 -5.0000000e-01 -6.2500000e-01 ... -1.5625000e-01\n",
            "     2.1875000e-01  2.5000000e-01]\n",
            "   [-4.3750000e-01  5.4687500e-02 -1.2500000e-01 ...  1.5625000e-01\n",
            "    -1.8750000e-01  1.5625000e-01]\n",
            "   ...\n",
            "   [-6.2500000e-02 -2.5000000e-01 -6.2500000e-02 ... -9.3750000e-02\n",
            "     7.8125000e-03  2.4414062e-03]\n",
            "   [-6.2500000e-01  5.4687500e-02 -1.0937500e-01 ...  2.7343750e-02\n",
            "     1.5625000e-01  6.2500000e-02]\n",
            "   [-3.7500000e-01 -9.3750000e-02  3.1250000e-01 ... -3.7500000e-01\n",
            "    -6.2500000e-01  3.1250000e-01]]]\n",
            "\n",
            "\n",
            " [[[-1.0937500e-01 -3.1250000e-01  1.8750000e-01 ...  7.8125000e-02\n",
            "     9.3750000e-02 -4.3750000e-01]\n",
            "   [-1.5625000e-01  1.9531250e-03 -1.2500000e-01 ... -4.6875000e-02\n",
            "     2.1875000e-01  1.5625000e-01]\n",
            "   [ 3.9062500e-02 -2.5000000e-01  1.8750000e-01 ... -1.5625000e-01\n",
            "    -1.0937500e-01 -2.5000000e-01]\n",
            "   ...\n",
            "   [-1.2500000e-01 -2.5000000e-01  1.0937500e-01 ...  7.8125000e-02\n",
            "     1.2500000e-01 -2.5000000e-01]\n",
            "   [ 6.2500000e-02 -9.3750000e-02  9.3750000e-02 ...  2.1875000e-01\n",
            "    -7.8125000e-02 -3.1250000e-01]\n",
            "   [ 3.1250000e-02 -2.1875000e-01  2.1875000e-01 ...  3.9062500e-02\n",
            "    -1.8750000e-01  1.4648438e-03]]\n",
            "\n",
            "  [[ 4.3750000e-01  1.5625000e-01  1.8750000e-01 ... -4.6875000e-02\n",
            "     2.3437500e-02 -7.8125000e-02]\n",
            "   [-1.5625000e-02 -1.5625000e-01 -1.5625000e-01 ... -9.3750000e-02\n",
            "    -1.5625000e-01 -2.3437500e-02]\n",
            "   [ 2.3437500e-02 -1.2500000e-01  1.2500000e-01 ...  1.5625000e-01\n",
            "     3.7500000e-01 -3.9062500e-03]\n",
            "   ...\n",
            "   [-1.2500000e-01 -2.5000000e-01  3.1250000e-02 ...  1.5625000e-01\n",
            "     3.9062500e-03 -1.0937500e-01]\n",
            "   [-3.1250000e-01  6.2500000e-02 -1.5625000e-01 ...  1.0937500e-01\n",
            "    -2.1875000e-01 -1.5625000e-01]\n",
            "   [ 2.3437500e-02  2.3437500e-02  6.2500000e-02 ... -8.7500000e-01\n",
            "    -5.0000000e-01 -2.1875000e-01]]\n",
            "\n",
            "  [[ 2.1875000e-01  4.8828125e-03  1.5625000e-02 ... -1.5625000e-01\n",
            "     1.5625000e-01  6.2500000e-01]\n",
            "   [-1.8750000e-01 -3.1250000e-01 -3.1250000e-01 ...  3.1250000e-01\n",
            "    -7.8125000e-02 -2.5000000e-01]\n",
            "   [ 1.5625000e-01  2.5000000e-01 -1.0937500e-01 ...  1.2500000e-01\n",
            "     1.2500000e-01  1.5625000e-01]\n",
            "   ...\n",
            "   [-3.7500000e-01 -1.5625000e-01  6.2500000e-02 ...  1.2500000e-01\n",
            "    -1.8750000e-01  3.7500000e-01]\n",
            "   [ 3.6621094e-04 -1.2500000e-01  7.8125000e-02 ...  2.3437500e-02\n",
            "     1.8750000e-01  1.8750000e-01]\n",
            "   [-3.9062500e-02 -1.9531250e-02  4.3750000e-01 ... -6.2500000e-01\n",
            "    -1.8750000e-01 -2.1875000e-01]]]\n",
            "\n",
            "\n",
            " [[[ 4.3750000e-01  3.1250000e-01 -1.0937500e-01 ...  1.5625000e-01\n",
            "    -1.3671875e-02 -9.3750000e-02]\n",
            "   [-4.6875000e-02 -7.8125000e-02  1.5625000e-01 ... -3.9062500e-02\n",
            "    -7.8125000e-02  1.0937500e-01]\n",
            "   [ 3.7500000e-01 -9.3750000e-02  4.6875000e-02 ... -3.1250000e-02\n",
            "     2.5000000e-01  9.7656250e-03]\n",
            "   ...\n",
            "   [ 6.2500000e-02 -2.5000000e-01 -1.8750000e-01 ...  3.7500000e-01\n",
            "     3.9062500e-02 -3.1250000e-02]\n",
            "   [ 6.2500000e-01  2.1875000e-01 -5.0000000e-01 ...  1.8750000e-01\n",
            "    -1.2500000e-01 -3.9062500e-03]\n",
            "   [ 1.0937500e-01 -4.3750000e-01  3.1250000e-01 ...  1.2500000e-01\n",
            "    -3.1250000e-01 -9.3750000e-02]]\n",
            "\n",
            "  [[ 1.5625000e-01  3.7500000e-01 -2.5000000e-01 ... -2.5000000e-01\n",
            "    -1.2500000e-01  2.1875000e-01]\n",
            "   [-7.8125000e-02 -5.4687500e-02 -2.1875000e-01 ... -5.4687500e-02\n",
            "    -3.9062500e-02 -3.7500000e-01]\n",
            "   [ 4.3750000e-01  6.2500000e-02 -3.1250000e-01 ...  2.3437500e-02\n",
            "     1.2500000e-01 -1.5625000e-02]\n",
            "   ...\n",
            "   [ 1.5625000e-01  7.8125000e-03 -3.7500000e-01 ...  2.1875000e-01\n",
            "    -1.8750000e-01  2.5000000e-01]\n",
            "   [ 2.5000000e-01  1.2500000e-01 -5.0000000e-01 ...  2.3437500e-02\n",
            "     2.7343750e-02  1.9531250e-02]\n",
            "   [-1.8750000e-01 -1.0937500e-01 -1.0937500e-01 ... -6.2500000e-02\n",
            "    -6.2500000e-02 -1.5625000e-01]]\n",
            "\n",
            "  [[ 3.1250000e-01  1.2500000e-01 -2.7343750e-02 ... -2.5000000e-01\n",
            "     1.5625000e-01  4.3750000e-01]\n",
            "   [-2.1875000e-01  4.6875000e-02 -2.5000000e-01 ... -1.2500000e-01\n",
            "    -3.7500000e-01 -2.1875000e-01]\n",
            "   [ 1.9531250e-02 -2.1875000e-01 -3.1250000e-01 ... -1.0937500e-01\n",
            "    -2.7343750e-02  5.4687500e-02]\n",
            "   ...\n",
            "   [-3.9062500e-02 -1.8750000e-01 -3.7500000e-01 ... -6.2500000e-02\n",
            "    -2.3437500e-02  7.5000000e-01]\n",
            "   [ 4.3750000e-01 -6.2500000e-02 -2.1875000e-01 ... -1.2500000e-01\n",
            "     2.1875000e-01  3.1250000e-01]\n",
            "   [-7.8125000e-02  1.2500000e-01  1.5625000e-01 ... -4.3750000e-01\n",
            "    -4.6875000e-02 -1.0937500e-01]]]]\n",
            "[-0.5        -0.3125     -0.625      -0.375      -0.625      -0.625\n",
            " -0.5        -0.25       -0.5        -0.1875     -0.4375     -0.21875\n",
            "  0.0625     -0.1875     -0.3125     -0.21875    -0.375       0.21875\n",
            " -0.5        -0.3125     -0.375      -0.046875   -0.3125     -0.4375\n",
            " -0.375      -0.4375     -0.00976562 -0.25       -0.25       -0.25\n",
            " -0.4375     -0.25       -0.0390625  -0.125      -0.109375   -0.15625\n",
            " -0.4375     -0.375      -0.4375     -0.5        -0.5        -0.0625\n",
            " -0.15625    -0.375       0.15625    -0.15625    -0.4375     -0.5\n",
            "  0.1875      0.1875     -0.25       -0.125      -0.0625     -0.3125\n",
            " -0.3125      0.375      -0.5        -0.5        -0.375      -0.5\n",
            " -0.375      -0.3125     -0.09375    -0.375      -0.25       -0.00683594\n",
            "  0.00341797 -0.625      -0.00195312 -0.21875    -0.3125     -0.21875\n",
            " -0.375      -0.15625     0.25       -0.375      -0.015625   -0.1875\n",
            "  0.0390625  -0.21875    -0.09375    -0.15625    -0.15625    -0.375\n",
            "  0.1875     -0.4375     -0.4375     -0.046875   -0.125      -0.1875\n",
            " -0.1875     -0.1875     -0.875      -0.15625    -0.3125     -0.046875\n",
            " -0.75        0.00585938 -0.5        -0.1875     -0.625      -0.1875\n",
            " -0.21875     0.01367188 -0.375      -0.125      -0.3125     -0.3125\n",
            " -0.0625     -0.21875    -0.125      -0.5         0.03125    -0.109375\n",
            " -0.25       -0.21875    -0.109375   -0.109375   -0.0625     -0.375\n",
            " -0.02734375 -0.5        -0.078125   -0.1875     -0.03125    -0.4375\n",
            " -0.078125   -0.375     ]\n",
            "[[[[ 1.1718750e-02 -2.5000000e-01  1.8750000e-01 ... -4.3750000e-01\n",
            "    -3.9062500e-02 -2.3437500e-02]\n",
            "   [ 3.1250000e-02 -1.5258789e-04  5.0000000e-01 ...  2.1875000e-01\n",
            "    -1.2500000e-01  1.0937500e-01]\n",
            "   [-4.3750000e-01  3.7500000e-01 -1.5625000e-01 ...  7.8125000e-02\n",
            "     2.1875000e-01  5.4687500e-02]\n",
            "   ...\n",
            "   [ 1.8750000e-01 -1.5625000e-01  1.8750000e-01 ... -3.1250000e-01\n",
            "     2.5000000e-01  7.8125000e-02]\n",
            "   [-6.2500000e-02  3.1250000e-01  2.1875000e-01 ... -1.5625000e-01\n",
            "    -7.8125000e-02 -1.9531250e-02]\n",
            "   [-3.1250000e-01  2.5000000e-01  1.2500000e-01 ... -7.8125000e-02\n",
            "    -9.3750000e-02 -1.8750000e-01]]\n",
            "\n",
            "  [[-3.1250000e-02 -7.8125000e-02  1.5625000e-02 ... -2.5000000e-01\n",
            "    -3.9062500e-02  1.8750000e-01]\n",
            "   [ 1.5625000e-01  1.2500000e-01  1.3671875e-02 ...  1.5625000e-01\n",
            "     3.1250000e-01 -7.8125000e-02]\n",
            "   [-1.8750000e-01 -3.9062500e-02  2.5000000e-01 ...  3.1250000e-02\n",
            "    -5.0000000e-01  1.2500000e-01]\n",
            "   ...\n",
            "   [-1.8750000e-01 -2.5000000e-01  7.8125000e-02 ... -4.3750000e-01\n",
            "     3.1250000e-01  1.2500000e-01]\n",
            "   [-2.3437500e-02  9.3750000e-02  7.8125000e-02 ... -1.8750000e-01\n",
            "     1.5625000e-01  1.8750000e-01]\n",
            "   [-1.2500000e-01  5.8593750e-03  2.1875000e-01 ...  9.7656250e-03\n",
            "     1.8750000e-01  1.0937500e-01]]\n",
            "\n",
            "  [[ 3.1250000e-02 -2.5000000e-01  3.1250000e-01 ... -6.2500000e-01\n",
            "    -5.0000000e-01  3.1250000e-01]\n",
            "   [-2.7343750e-02  3.7500000e-01 -2.5000000e-01 ... -4.6875000e-02\n",
            "     9.3750000e-02  4.6875000e-02]\n",
            "   [-1.2500000e-01 -9.3750000e-02  3.1250000e-02 ... -1.2500000e-01\n",
            "    -2.5000000e-01  6.2500000e-02]\n",
            "   ...\n",
            "   [-1.2500000e-01 -4.3750000e-01 -2.1875000e-01 ...  4.6875000e-02\n",
            "     3.1250000e-01 -3.7500000e-01]\n",
            "   [-7.8125000e-02 -7.8125000e-02 -3.1250000e-02 ... -1.2500000e-01\n",
            "     1.5625000e-01 -2.1875000e-01]\n",
            "   [-6.2500000e-02 -1.2500000e-01 -1.2500000e-01 ... -1.8750000e-01\n",
            "     1.8750000e-01  2.3437500e-02]]]\n",
            "\n",
            "\n",
            " [[[-1.0937500e-01 -5.0000000e-01  2.1875000e-01 ... -9.3750000e-02\n",
            "    -4.3750000e-01 -4.3750000e-01]\n",
            "   [ 2.1875000e-01  2.3437500e-02  2.1875000e-01 ... -4.3750000e-01\n",
            "    -2.1875000e-01  2.3437500e-02]\n",
            "   [-2.1875000e-01 -2.1875000e-01  3.7500000e-01 ... -3.7500000e-01\n",
            "    -2.3437500e-02  1.0937500e-01]\n",
            "   ...\n",
            "   [-5.0000000e-01 -3.1250000e-01  1.2500000e-01 ...  3.1250000e-01\n",
            "    -3.1250000e-01  2.3437500e-02]\n",
            "   [-1.0937500e-01  1.5625000e-01  6.2500000e-02 ...  3.9062500e-02\n",
            "    -2.5000000e-01 -1.8750000e-01]\n",
            "   [-1.0937500e-01  1.8750000e-01  1.8750000e-01 ...  1.0937500e-01\n",
            "    -6.2500000e-02 -4.3750000e-01]]\n",
            "\n",
            "  [[-3.1250000e-01 -2.5000000e-01 -2.1875000e-01 ...  6.8359375e-03\n",
            "    -5.0000000e-01 -1.5625000e-01]\n",
            "   [ 3.1250000e-01  1.0937500e-01 -3.1250000e-01 ... -9.3750000e-02\n",
            "    -1.2500000e-01 -4.6875000e-02]\n",
            "   [-3.7500000e-01  3.7500000e-01  2.5000000e-01 ...  1.5625000e-01\n",
            "    -1.5625000e-01  3.1250000e-01]\n",
            "   ...\n",
            "   [-2.5000000e-01 -1.5625000e-01 -1.0937500e-01 ... -2.1875000e-01\n",
            "     9.3750000e-02 -5.0000000e-01]\n",
            "   [ 9.3750000e-02  6.2500000e-02  2.3437500e-02 ... -5.8593750e-03\n",
            "     4.3750000e-01 -1.5625000e-01]\n",
            "   [ 1.0937500e-01  2.1875000e-01 -3.1250000e-01 ... -3.1250000e-02\n",
            "     2.5000000e-01 -1.9531250e-02]]\n",
            "\n",
            "  [[-9.3750000e-02 -3.1250000e-01 -1.8750000e-01 ... -2.1875000e-01\n",
            "    -4.3750000e-01 -2.1875000e-01]\n",
            "   [-3.7500000e-01  2.7343750e-02 -1.8750000e-01 ... -1.8750000e-01\n",
            "    -1.8750000e-01 -3.1250000e-01]\n",
            "   [-3.7500000e-01 -1.8750000e-01 -4.6875000e-02 ...  3.1250000e-02\n",
            "     5.4687500e-02  2.1875000e-01]\n",
            "   ...\n",
            "   [-1.5625000e-01  1.0937500e-01 -1.0937500e-01 ...  2.1875000e-01\n",
            "     7.8125000e-02 -4.3750000e-01]\n",
            "   [-3.9062500e-02 -3.1250000e-02 -3.1250000e-01 ...  1.5625000e-01\n",
            "     7.8125000e-02 -1.8750000e-01]\n",
            "   [ 1.5625000e-01 -1.2500000e-01 -3.1250000e-01 ...  3.7500000e-01\n",
            "     6.8359375e-03 -1.5625000e-01]]]\n",
            "\n",
            "\n",
            " [[[-5.0000000e-01 -5.0000000e-01 -2.5000000e-01 ... -1.5625000e-01\n",
            "    -1.5625000e-01 -3.1250000e-02]\n",
            "   [-9.3750000e-02  1.5625000e-01 -6.1035156e-04 ... -2.5000000e-01\n",
            "    -2.7343750e-02  9.7656250e-03]\n",
            "   [ 5.8593750e-03 -2.5000000e-01 -6.2500000e-02 ... -3.7500000e-01\n",
            "    -5.4687500e-02  1.2500000e-01]\n",
            "   ...\n",
            "   [-2.1875000e-01  1.5625000e-01  6.2500000e-02 ... -3.9062500e-02\n",
            "    -1.8750000e-01 -6.2500000e-02]\n",
            "   [ 5.0000000e-01  4.8828125e-03 -3.9062500e-02 ... -1.8750000e-01\n",
            "    -4.3750000e-01 -1.5625000e-01]\n",
            "   [ 3.9062500e-02 -7.8125000e-02  2.1875000e-01 ... -1.2500000e-01\n",
            "    -1.2500000e-01 -2.5000000e-01]]\n",
            "\n",
            "  [[-1.8750000e-01 -3.7500000e-01 -1.5625000e-01 ...  1.5625000e-01\n",
            "    -1.5625000e-01  1.8750000e-01]\n",
            "   [-2.1875000e-01 -2.1875000e-01 -3.7500000e-01 ... -2.1875000e-01\n",
            "    -3.1250000e-01 -9.3750000e-02]\n",
            "   [-3.1250000e-01  6.2500000e-02 -9.3750000e-02 ... -5.4687500e-02\n",
            "    -7.8125000e-02 -1.5625000e-01]\n",
            "   ...\n",
            "   [-2.1875000e-01 -3.1250000e-01 -1.5625000e-01 ...  2.1875000e-01\n",
            "    -1.8750000e-01 -3.7500000e-01]\n",
            "   [-7.8125000e-02 -4.6875000e-02  1.3671875e-02 ... -1.0937500e-01\n",
            "     1.1718750e-02 -1.0937500e-01]\n",
            "   [ 1.8750000e-01 -1.9531250e-02 -1.5625000e-01 ... -2.1875000e-01\n",
            "     3.7500000e-01  2.7343750e-02]]\n",
            "\n",
            "  [[ 1.9531250e-02 -3.1250000e-01 -3.1250000e-01 ...  1.2500000e-01\n",
            "     2.4414062e-03 -3.9062500e-02]\n",
            "   [-1.8750000e-01 -7.8125000e-02  2.5000000e-01 ... -3.9062500e-02\n",
            "     2.1875000e-01 -3.1250000e-02]\n",
            "   [ 1.0937500e-01 -3.1250000e-01 -1.2500000e-01 ... -2.1875000e-01\n",
            "    -1.8750000e-01 -1.2500000e-01]\n",
            "   ...\n",
            "   [-1.8750000e-01  1.0937500e-01 -2.5000000e-01 ... -3.7500000e-01\n",
            "    -1.8750000e-01 -6.2500000e-01]\n",
            "   [ 4.6875000e-02  3.1250000e-01 -5.0000000e-01 ... -2.7343750e-02\n",
            "     1.3671875e-02 -2.5000000e-01]\n",
            "   [ 1.0937500e-01  5.4687500e-02 -2.3437500e-02 ...  3.9062500e-02\n",
            "     3.9062500e-02 -1.8750000e-01]]]]\n",
            "[-0.21875     0.09375    -0.4375     -0.375       0.625      -0.3125\n",
            "  0.109375   -0.15625    -0.3125     -0.109375   -0.078125   -0.15625\n",
            " -0.375      -0.5        -0.5         0.21875    -0.4375      0.21875\n",
            " -0.15625    -0.25        0.0625     -0.078125   -0.15625    -0.4375\n",
            " -0.75       -0.5         0.4375      0.1875     -0.4375     -0.875\n",
            " -0.5        -0.078125   -0.5        -0.25       -0.3125     -0.0546875\n",
            " -0.5        -0.5         0.25       -0.125      -0.15625    -0.078125\n",
            " -0.375      -0.875      -0.1875      0.375      -0.00976562 -0.375\n",
            " -0.75       -0.25       -0.375       0.25        0.09375    -0.3125\n",
            " -0.5         0.01171875 -0.4375      0.3125     -0.09375    -0.375\n",
            " -0.25        0.3125     -0.375      -0.03125     0.375      -0.3125\n",
            " -0.03125    -0.21875    -0.125      -0.25       -0.4375     -0.3125\n",
            " -0.25        0.375       0.125      -0.3125     -0.625      -0.3125\n",
            " -0.09375    -0.375      -0.109375   -0.375       0.375      -0.3125\n",
            " -0.1875     -0.109375   -0.5        -0.5         0.09375    -0.125\n",
            " -0.21875    -0.25        0.15625    -0.078125   -0.5        -0.625\n",
            " -0.25       -0.1875     -0.109375    0.25       -0.4375      0.1875\n",
            " -0.5        -0.5        -0.1875     -0.4375      0.02734375 -0.5\n",
            " -0.109375   -0.078125    0.01953125 -0.0625     -0.625      -0.3125\n",
            " -0.0625      0.0625     -0.078125   -0.5        -0.625      -0.25\n",
            " -0.25       -0.09375    -0.3125     -0.625       0.1875      0.21875\n",
            " -0.4375     -0.4375     -0.375      -0.4375     -0.4375      0.0625\n",
            " -0.15625     0.125       0.03125    -0.5        -0.1875     -0.21875\n",
            " -0.3125      0.15625    -0.3125      0.03125     0.1875      0.0546875\n",
            " -0.15625    -0.3125     -0.3125     -0.375      -0.4375     -0.15625\n",
            "  0.15625     0.21875    -0.1875     -0.01953125  0.375      -0.3125\n",
            " -0.1875     -0.625      -0.25        0.21875     0.01171875 -0.21875\n",
            "  0.75       -0.21875    -0.5        -0.109375   -0.109375   -0.0234375\n",
            " -0.1875      0.21875    -0.375      -0.25       -0.375      -0.4375\n",
            "  0.21875    -0.5         0.375      -0.1875     -0.25       -0.21875\n",
            " -0.25       -0.01171875 -0.5        -0.5        -0.625       0.1875\n",
            " -0.21875     0.625      -0.0625     -0.375      -0.625      -0.875\n",
            " -0.75        0.25       -0.3125     -0.75       -0.5        -0.125\n",
            "  0.078125   -0.4375     -0.1875      0.21875     0.21875    -0.00341797\n",
            " -0.25       -0.109375   -0.03125    -0.375      -0.25       -0.3125\n",
            " -0.625      -0.1875      0.3125     -0.5         0.00488281 -0.15625\n",
            " -0.375      -0.01367188  0.09375     0.15625    -0.375      -0.25\n",
            " -0.078125   -0.5        -0.5        -0.375      -0.375      -0.21875\n",
            " -0.25       -0.375      -0.3125     -0.625      -0.125       0.09375\n",
            " -0.3125      0.25       -0.0546875  -0.5        -0.125      -0.3125\n",
            " -0.375       0.125      -0.01953125 -0.09375     0.625       0.078125\n",
            "  0.375      -0.875      -0.25       -0.5        -0.4375     -0.4375\n",
            " -0.3125     -0.0546875  -0.3125     -0.75      ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-11 01:18:52.367867: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 122880000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> 80.090\n"
          ]
        }
      ],
      "source": [
        "print_model (model)\n",
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GmFfu4r-dFdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 2,475,402\n",
            "Trainable params: 2,474,506\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-10 20:12:23.873494: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1228800000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/yarib/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /home/yarib/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-10 20:13:42.265662: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmps7xca_qf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-10 20:13:50.813863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-10 20:13:50.823142: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2021-11-10 20:13:50.830882: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-11-10 20:13:50.984778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-10 20:13:50.987750: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f81d689a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-10 20:13:50.987796: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 860M, Compute Capability 5.0\n",
            "2021-11-10 20:13:50.990208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-10 20:13:50.991279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-10 20:13:51.024801: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:51.026621: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:51.026681: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-10 20:13:51.026723: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-10 20:13:51.027691: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:51.027833: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:51.029725: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:51.029747: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-10 20:13:51.029789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-10 20:13:51.029801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-11-10 20:13:51.029818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2021-11-10 20:13:51.053874: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2021-11-10 20:13:51.053907: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.677ms.\n",
            "2021-11-10 20:13:51.053914: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-10 20:13:51.464548: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\n",
            "2021-11-10 20:13:51.464597: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\n",
            "2021-11-10 20:13:51.526225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-10 20:13:51.527096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-10 20:13:51.527269: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:51.527389: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:51.527432: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-10 20:13:51.527460: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-10 20:13:51.527541: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:51.527630: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:51.527716: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:51.527729: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-10 20:13:51.527747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-10 20:13:51.527754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-11-10 20:13:51.527762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, utils\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "  print(\"Folder \" + filename + \" does not exist.\")\n",
        "  exit()\n",
        "\n",
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "model = tf.keras.models.load_model(filename + \"/\" + filename + '.h5')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(model, filename + \"/\" + filename + \".png\", show_shapes=True, show_layer_names=True, expand_nested=True)\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255 , test_images / 255\n",
        "\n",
        "train_images = tf.cast(train_images, tf.float32)\n",
        "cifar_ds = tf.data.Dataset.from_tensor_slices((train_images)).batch(1)\n",
        "def representative_dataset():\n",
        "  for input_value in cifar_ds.take(100):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "#converter.representative_dataset = representative_dataset\n",
        "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.float32  # or tf.uint8\n",
        "converter.inference_output_type = tf.float32  # or tf.uint8\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open(filename + \"/\" + filename + \"_f32\" + '.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "INb151fxeI6B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp7b_9ubnk/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp7b_9ubnk/assets\n",
            "2021-11-10 20:13:58.661770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-10 20:13:58.662467: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2021-11-10 20:13:58.664582: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-11-10 20:13:58.665490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-10 20:13:58.666174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-10 20:13:58.666277: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:58.666343: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:58.666372: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-10 20:13:58.666385: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-10 20:13:58.666429: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:58.666477: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:58.666528: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-10 20:13:58.666535: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-10 20:13:58.666547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-10 20:13:58.666552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-11-10 20:13:58.666557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2021-11-10 20:13:58.669355: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2021-11-10 20:13:58.669376: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
            "2021-11-10 20:13:58.669383: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\n",
            "2021-11-10 20:13:58.875273: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\n",
            "2021-11-10 20:13:58.875324: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.float32  # or tf.uint8\n",
        "converter.inference_output_type = tf.float32  # or tf.uint8\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open(filename + \"/\" + filename + \"_i8\" + '.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pZ4KikJ-fkaU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=filename + \"/\" + filename + \"_i8\" + '.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TpXHwv2Tf3yI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Lite Predicted: [[0.         0.         0.         0.00390625 0.         0.99609375\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], x)\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print('TensorFlow Lite Predicted:', output_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "quantized_training.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3ba63467901cd6d3991f497c38810e6d1156dd2dfb6eb0edc80f01dd9606bacd"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
