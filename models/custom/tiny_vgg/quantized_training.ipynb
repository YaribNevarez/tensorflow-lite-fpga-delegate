{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbiM6lilQxtQ",
        "outputId": "ede20a3d-6cc7-4d96-c754-cbc1a79a6008"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-12 17:58:22.528416: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-12 17:58:22.528450: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import SeparableConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jupyter notebook to build, train, and deply CNN models for TF Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IuN7OgXSQ9i2"
      },
      "outputs": [],
      "source": [
        "filename = \"tiny_vgg_q\" # Set the name for the model output\n",
        "\n",
        "early_stop_training = True # Early stop training\n",
        "\n",
        "#___________________________\n",
        "training_batch_size = 20\n",
        "training_epochs = 100\n",
        "training_patience = 10\n",
        "\n",
        "#___________________________\n",
        "quantize_aware_training = True\n",
        "quantize_training_epochs = 100\n",
        "quantize_training_patience = 10\n",
        "\n",
        "target_exponent = 5 # Target exponent bit size for custom floating-point \n",
        "target_mantissa = 2 # Target mantissa bit size for custom floating-point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "google_colab = False # Set True when using on google colab\n",
        "if google_colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CNN ARCHITECTURE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def ConvPool_CNN_C():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides = 2))\n",
        "\n",
        "    model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides = 2))\n",
        "\n",
        "    model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(Conv2D(192, (1, 1), activation='relu'))\n",
        "    model.add(Conv2D(10, (1, 1)))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Activation(activation='softmax'))\n",
        "\n",
        "    # compile model\n",
        "    #opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "    opt = \"adam\"\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def shallow_CNN():\n",
        "\tmodel = Sequential()\n",
        "\t\n",
        "\tmodel.add(Conv2D(40, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Conv2D(60, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Conv2D(120, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(120, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\t#opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\topt = \"adam\"\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def shallow_SeparableCNN():\n",
        "\tmodel = Sequential()\n",
        "\t\n",
        "\tmodel.add(SeparableConv2D(40, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(SeparableConv2D(60, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(SeparableConv2D(120, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(120, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\t#opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\topt = \"adam\"\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def define_model_CNN():\n",
        "\treturn shallow_SeparableCNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quantized aware training method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Fh2Y7AaGvoUK"
      },
      "outputs": [],
      "source": [
        "import struct\n",
        "\n",
        "def bin2float(b):\n",
        "    ''' Convert binary string to a float.\n",
        "\n",
        "    Attributes:\n",
        "        :b: Binary string to transform.\n",
        "    '''\n",
        "    h = int(b, 2).to_bytes(8, byteorder=\"big\")\n",
        "    return struct.unpack('>d', h)[0]\n",
        "\n",
        "\n",
        "def float2bin(f):\n",
        "    ''' Convert float to 64-bit binary string.\n",
        "\n",
        "    Attributes:\n",
        "        :f: Float number to transform.\n",
        "    '''\n",
        "    [d] = struct.unpack(\">Q\", struct.pack(\">d\", f))\n",
        "    return f'{d:064b}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7Y8p19yiv2rs"
      },
      "outputs": [],
      "source": [
        "def quantize_float (float_number, exponent_bits, mantissa_bits):\n",
        "    exponent_sign = 1\n",
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
        "    if mantissa_bits < 0:\n",
        "      mantissa_bits = 0\n",
        "    if exponent_bits < 0:\n",
        "      exponent_bits = 0\n",
        "      \n",
        "    coefficient = float2bin(float_number)\n",
        "    sign = int (coefficient[:1], 2)\n",
        "    if 0 < mantissa_bits:\n",
        "        custom_mantissa = int (coefficient[12 : 12 + mantissa_bits], 2)\n",
        "    else:\n",
        "        custom_mantissa = 0\n",
        "    residual_mantissa = int (coefficient[12 + mantissa_bits:], 2)\n",
        "    exponent = int (coefficient[1:12], 2) - 1023\n",
        "\n",
        "    exponent_full_range = pow(2, exponent_bits - exponent_sign) - 1\n",
        "    if exponent < - exponent_full_range:\n",
        "        quantized_value = 0\n",
        "    elif exponent > exponent_full_range:\n",
        "        quantized_value = pow(-1, sign) * (1 + (1 - pow(2, - mantissa_bits))) * pow(2, exponent_full_range)\n",
        "    else:\n",
        "        if (pow (2, (52 - (mantissa_bits + 1))) - 1) < residual_mantissa:\n",
        "            custom_mantissa += 1\n",
        "            if (pow (2, mantissa_bits) - 1) < custom_mantissa:\n",
        "                custom_mantissa = 0\n",
        "                exponent += 1\n",
        "    \n",
        "        quantized_value = pow(-1, sign) * (1 + custom_mantissa * pow(2, - mantissa_bits)) * pow(2, exponent)\n",
        "    return quantized_value\n",
        "\n",
        "def quantize_model(model, exponent_bits, mantissa_bits):\n",
        "  for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.SeparableConv2D):\n",
        "      layer_weights = layer.get_weights()\n",
        "      for index in range(len(layer_weights)):\n",
        "        matrix = layer_weights[index]\n",
        "        for weight_index, weight in np.ndenumerate(matrix):\n",
        "          matrix[weight_index] = quantize_float(weight, target_exponent, target_mantissa)\n",
        "        print (matrix)\n",
        "        layer_weights[index] = matrix\n",
        "      layer.set_weights(layer_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Early stop callback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vaA7sG9xenUF"
      },
      "outputs": [],
      "source": [
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, verbose=1, mode='auto', restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mHKtRDtPn0eQ"
      },
      "outputs": [],
      "source": [
        "mantissa_bits = target_mantissa\n",
        "exponent_bits = target_exponent\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    quantize_model(self.model, exponent_bits, mantissa_bits)\n",
        "  def on_train_end(self, logs={}):\n",
        "    quantize_model(self.model, exponent_bits, mantissa_bits)\n",
        "  def on_batch_end(self, epoch, logs=None):\n",
        "    quantize_model(self.model, exponent_bits, mantissa_bits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WPVVK7cLRHlR"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(filename):\n",
        "  os.mkdir(filename)\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tf = pyplot.figure()\n",
        "\tf.set_figwidth(10)\n",
        "\tf.set_figheight(20)\n",
        "\t\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tpyplot.savefig(filename + '/' + filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model_CNN()\n",
        "\t# fit model\n",
        "\thistory = model.fit(trainX, trainY, epochs=20, batch_size=64, validation_data=(testX, testY), verbose=1, callbacks=[MyCallback()])\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\t# Save the entire model to a HDF5 file.\n",
        "\tmodel.save(filename + \"/\" + filename + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-12 17:59:30.359699: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2021-11-12 17:59:30.392250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-12 17:59:30.392988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-12 17:59:30.394062: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-12 17:59:30.394756: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 17:59:30.429277: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-12 17:59:30.436450: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-12 17:59:30.436986: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 17:59:30.437099: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 17:59:30.437777: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-12 17:59:30.437793: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-12 17:59:30.439443: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-11-12 17:59:30.488600: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2494220000 Hz\n",
            "2021-11-12 17:59:30.489997: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55903275d300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-12 17:59:30.490019: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-11-12 17:59:30.492794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-12 17:59:30.492806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \n"
          ]
        }
      ],
      "source": [
        "# entry point, run the test harness\n",
        "# load dataset\n",
        "trainX, trainY, testX, testY = load_dataset()\n",
        "\n",
        "# prepare pixel data\n",
        "trainX, testX = prep_pixels(trainX, testX)\n",
        "\n",
        "# define model\n",
        "model = define_model_CNN()\n",
        "# fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsUR8C6RRJVc",
        "outputId": "f4b2312f-ee7b-41d7-8715-6afdbcdb31b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-11 23:52:43.526102: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2499/2500 [============================>.] - ETA: 0s - loss: 1.9148 - accuracy: 0.2996"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-11 23:54:16.827275: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 122880000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2500/2500 [==============================] - 91s 37ms/step - loss: 1.9146 - accuracy: 0.2997 - val_loss: 1.5472 - val_accuracy: 0.4517\n",
            "Epoch 2/100\n",
            "2500/2500 [==============================] - 100s 40ms/step - loss: 1.6204 - accuracy: 0.4108 - val_loss: 1.6164 - val_accuracy: 0.4568\n",
            "Epoch 3/100\n",
            "2500/2500 [==============================] - 122s 49ms/step - loss: 1.5067 - accuracy: 0.4536 - val_loss: 1.2715 - val_accuracy: 0.5387\n",
            "Epoch 4/100\n",
            "2500/2500 [==============================] - 109s 44ms/step - loss: 1.4299 - accuracy: 0.4893 - val_loss: 1.5074 - val_accuracy: 0.4782\n",
            "Epoch 5/100\n",
            "2500/2500 [==============================] - 92s 37ms/step - loss: 1.3600 - accuracy: 0.5189 - val_loss: 1.1278 - val_accuracy: 0.6037\n",
            "Epoch 6/100\n",
            "2500/2500 [==============================] - 95s 38ms/step - loss: 1.3154 - accuracy: 0.5365 - val_loss: 1.1010 - val_accuracy: 0.6184\n",
            "Epoch 7/100\n",
            "2500/2500 [==============================] - 95s 38ms/step - loss: 1.2581 - accuracy: 0.5577 - val_loss: 1.1912 - val_accuracy: 0.6018\n",
            "Epoch 8/100\n",
            "2500/2500 [==============================] - 111s 45ms/step - loss: 1.2200 - accuracy: 0.5740 - val_loss: 1.3424 - val_accuracy: 0.5573\n",
            "Epoch 9/100\n",
            "2500/2500 [==============================] - 106s 42ms/step - loss: 1.1795 - accuracy: 0.5886 - val_loss: 1.0016 - val_accuracy: 0.6527\n",
            "Epoch 10/100\n",
            "2500/2500 [==============================] - 106s 43ms/step - loss: 1.1562 - accuracy: 0.5984 - val_loss: 1.1323 - val_accuracy: 0.6184\n",
            "Epoch 11/100\n",
            "2500/2500 [==============================] - 143s 57ms/step - loss: 1.1217 - accuracy: 0.6068 - val_loss: 1.0259 - val_accuracy: 0.6534\n",
            "Epoch 12/100\n",
            "2500/2500 [==============================] - 134s 53ms/step - loss: 1.0986 - accuracy: 0.6169 - val_loss: 1.0564 - val_accuracy: 0.6320\n",
            "Epoch 13/100\n",
            "2500/2500 [==============================] - 105s 42ms/step - loss: 1.0733 - accuracy: 0.6241 - val_loss: 1.1119 - val_accuracy: 0.6358\n",
            "Epoch 14/100\n",
            "2500/2500 [==============================] - 94s 37ms/step - loss: 1.0586 - accuracy: 0.6319 - val_loss: 0.9125 - val_accuracy: 0.6892\n",
            "Epoch 15/100\n",
            "2500/2500 [==============================] - 129s 51ms/step - loss: 1.0443 - accuracy: 0.6375 - val_loss: 1.0635 - val_accuracy: 0.6490\n",
            "Epoch 16/100\n",
            "2500/2500 [==============================] - 143s 57ms/step - loss: 1.0278 - accuracy: 0.6412 - val_loss: 0.9294 - val_accuracy: 0.6837\n",
            "Epoch 17/100\n",
            "2500/2500 [==============================] - 147s 59ms/step - loss: 1.0193 - accuracy: 0.6458 - val_loss: 0.9861 - val_accuracy: 0.6599\n",
            "Epoch 18/100\n",
            "2500/2500 [==============================] - 127s 51ms/step - loss: 0.9987 - accuracy: 0.6529 - val_loss: 0.9516 - val_accuracy: 0.6739\n",
            "Epoch 19/100\n",
            "2500/2500 [==============================] - 107s 43ms/step - loss: 0.9918 - accuracy: 0.6545 - val_loss: 0.8441 - val_accuracy: 0.7073\n",
            "Epoch 20/100\n",
            "2500/2500 [==============================] - 140s 56ms/step - loss: 0.9844 - accuracy: 0.6587 - val_loss: 0.8919 - val_accuracy: 0.6945\n",
            "Epoch 21/100\n",
            "2500/2500 [==============================] - 136s 55ms/step - loss: 0.9792 - accuracy: 0.6607 - val_loss: 1.0370 - val_accuracy: 0.6627\n",
            "Epoch 22/100\n",
            "2500/2500 [==============================] - 122s 49ms/step - loss: 0.9659 - accuracy: 0.6613 - val_loss: 0.9778 - val_accuracy: 0.6637\n",
            "Epoch 23/100\n",
            "2500/2500 [==============================] - 121s 49ms/step - loss: 0.9612 - accuracy: 0.6658 - val_loss: 0.7980 - val_accuracy: 0.7257\n",
            "Epoch 24/100\n",
            "2500/2500 [==============================] - 145s 58ms/step - loss: 0.9509 - accuracy: 0.6686 - val_loss: 1.0984 - val_accuracy: 0.6442\n",
            "Epoch 25/100\n",
            "2500/2500 [==============================] - 146s 59ms/step - loss: 0.9508 - accuracy: 0.6689 - val_loss: 0.8111 - val_accuracy: 0.7221\n",
            "Epoch 26/100\n",
            "2500/2500 [==============================] - 144s 58ms/step - loss: 0.9448 - accuracy: 0.6713 - val_loss: 0.8375 - val_accuracy: 0.7150\n",
            "Epoch 27/100\n",
            "2500/2500 [==============================] - 128s 51ms/step - loss: 0.9370 - accuracy: 0.6744 - val_loss: 1.0931 - val_accuracy: 0.6445\n",
            "Epoch 28/100\n",
            "2500/2500 [==============================] - 157s 63ms/step - loss: 0.9358 - accuracy: 0.6762 - val_loss: 0.8869 - val_accuracy: 0.6976\n",
            "Epoch 29/100\n",
            "2500/2500 [==============================] - 167s 67ms/step - loss: 0.9237 - accuracy: 0.6767 - val_loss: 0.9582 - val_accuracy: 0.6737\n",
            "Epoch 30/100\n",
            "2500/2500 [==============================] - 138s 55ms/step - loss: 0.9287 - accuracy: 0.6781 - val_loss: 0.9666 - val_accuracy: 0.6757\n",
            "Epoch 31/100\n",
            "2500/2500 [==============================] - 178s 71ms/step - loss: 0.9220 - accuracy: 0.6806 - val_loss: 0.8224 - val_accuracy: 0.7158\n",
            "Epoch 32/100\n",
            "2500/2500 [==============================] - 161s 64ms/step - loss: 0.9132 - accuracy: 0.6816 - val_loss: 0.7492 - val_accuracy: 0.7412\n",
            "Epoch 33/100\n",
            "2500/2500 [==============================] - 166s 66ms/step - loss: 0.9119 - accuracy: 0.6823 - val_loss: 0.8412 - val_accuracy: 0.7079\n",
            "Epoch 34/100\n",
            "2500/2500 [==============================] - 151s 60ms/step - loss: 0.9064 - accuracy: 0.6865 - val_loss: 0.9447 - val_accuracy: 0.6849\n",
            "Epoch 35/100\n",
            "2500/2500 [==============================] - 115s 46ms/step - loss: 0.9052 - accuracy: 0.6823 - val_loss: 0.8371 - val_accuracy: 0.7160\n",
            "Epoch 36/100\n",
            "2500/2500 [==============================] - 108s 43ms/step - loss: 0.9037 - accuracy: 0.6856 - val_loss: 0.9633 - val_accuracy: 0.6746\n",
            "Epoch 37/100\n",
            "2500/2500 [==============================] - 108s 43ms/step - loss: 0.8994 - accuracy: 0.6869 - val_loss: 0.8875 - val_accuracy: 0.7031\n",
            "Epoch 38/100\n",
            "2500/2500 [==============================] - 125s 50ms/step - loss: 0.8948 - accuracy: 0.6886 - val_loss: 1.0037 - val_accuracy: 0.6749\n",
            "Epoch 39/100\n",
            "2500/2500 [==============================] - 127s 51ms/step - loss: 0.8885 - accuracy: 0.6906 - val_loss: 0.9111 - val_accuracy: 0.6892\n",
            "Epoch 40/100\n",
            "2500/2500 [==============================] - 135s 54ms/step - loss: 0.8956 - accuracy: 0.6881 - val_loss: 0.8787 - val_accuracy: 0.6994\n",
            "Epoch 41/100\n",
            "2500/2500 [==============================] - 157s 63ms/step - loss: 0.8895 - accuracy: 0.6924 - val_loss: 0.7699 - val_accuracy: 0.7402\n",
            "Epoch 42/100\n",
            "2500/2500 [==============================] - ETA: 0s - loss: 0.8813 - accuracy: 0.6938Restoring model weights from the end of the best epoch.\n",
            "2500/2500 [==============================] - 170s 68ms/step - loss: 0.8813 - accuracy: 0.6938 - val_loss: 1.2577 - val_accuracy: 0.6206\n",
            "Epoch 00042: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-12 01:22:51.662514: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 122880000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-quantization training > 74.120\n"
          ]
        }
      ],
      "source": [
        "if not early_stop_training:\n",
        "    history = model.fit(trainX, trainY, epochs=training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1)\n",
        "else:\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=training_patience, verbose=1, mode='auto', restore_best_weights=True)\n",
        "    history = model.fit(trainX, trainY, epochs=training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1, callbacks=[monitor])\n",
        "\n",
        "# evaluate model\n",
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('Pre-quantization training > %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_5323/491810080.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummarize_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "# learning curves\n",
        "summarize_diagnostics(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_______ Quantize aware training _______\n"
          ]
        }
      ],
      "source": [
        "if not quantize_aware_training:\n",
        "    print (\"_______ Post-training quantization _______\")\n",
        "    quantize_model(model, exponent_bits, mantissa_bits)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "    print('Post-training quantization > %.3f' % (acc * 100.0))\n",
        "else:\n",
        "    print (\"_______ Quantize aware training _______\")\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=quantize_training_patience, verbose=1, mode='auto', restore_best_weights=True)\n",
        "    history = model.fit(trainX, trainY, epochs=quantize_training_epochs, batch_size=training_batch_size, validation_data=(testX, testY), verbose=1, callbacks=[MyCallback(), monitor])\n",
        "    # learning curves\n",
        "    summarize_diagnostics(history)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "    print('Quantize aware training > %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the entire model to a HDF5 file.\n",
        "model.save(filename + \"/\" + filename + '.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_______ LOAD CNN MODEL FOR EVALUATION AND CONVERSION TO TF LITE FLOATING-POINT AND FIXED-POINT _______"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GCLycpCTcGdR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Predicted: [[0.00974922 0.01915544 0.0849871  0.0703998  0.09942796 0.1459774\n",
            "  0.5163244  0.02028543 0.0208753  0.01281799]]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "img_path = \"dog.jpg\"\n",
        "img = image.load_img(img_path, target_size=(32, 32))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x.astype('float32')\n",
        "x = x / 255.0\n",
        "\n",
        "model = load_model(filename + \"/\" + filename + '.h5')\n",
        "\n",
        "output_data = model.predict(x)\n",
        "\n",
        "print('TensorFlow Predicted:', output_data)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_model(model):\n",
        "  for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.SeparableConv2D):\n",
        "      layer_weights = layer.get_weights()\n",
        "      for index in range(len(layer_weights)):\n",
        "        matrix = layer_weights[index]\n",
        "        for weight_index, weight in np.ndenumerate(matrix):\n",
        "          matrix[weight_index] = quantize_float(weight, target_exponent, target_mantissa)\n",
        "        print (matrix)\n",
        "        layer_weights[index] = matrix\n",
        "      layer.set_weights(layer_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[[-1.     ]\n",
            "   [-0.1875 ]\n",
            "   [-0.21875]]\n",
            "\n",
            "  [[ 0.3125 ]\n",
            "   [-0.1875 ]\n",
            "   [-0.375  ]]\n",
            "\n",
            "  [[ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.375  ]]]\n",
            "\n",
            "\n",
            " [[[ 0.875  ]\n",
            "   [-0.375  ]\n",
            "   [-0.625  ]]\n",
            "\n",
            "  [[-0.625  ]\n",
            "   [ 0.875  ]\n",
            "   [ 0.     ]]\n",
            "\n",
            "  [[ 0.5    ]\n",
            "   [ 0.     ]\n",
            "   [ 0.875  ]]]\n",
            "\n",
            "\n",
            " [[[ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.625  ]]\n",
            "\n",
            "  [[ 0.5    ]\n",
            "   [ 0.875  ]\n",
            "   [-0.3125 ]]\n",
            "\n",
            "  [[-0.3125 ]\n",
            "   [-0.625  ]\n",
            "   [-0.1875 ]]]]\n",
            "[[[[ 0.      -0.875    0.625    0.125    1.25     0.      -0.25\n",
            "    -0.5     -0.25    -0.21875  0.3125   0.3125   1.75     0.875\n",
            "    -1.      -0.1875  -0.125    0.      -1.5     -0.15625  1.75\n",
            "    -1.       0.      -1.25     0.375   -0.375    1.      -0.4375\n",
            "     0.      -0.125    0.3125  -0.625    0.3125   0.       0.\n",
            "     1.      -0.25     1.25     0.15625  0.     ]\n",
            "   [ 0.375    0.1875  -0.625   -0.625   -0.1875   0.       0.4375\n",
            "     0.4375   0.75     0.      -0.21875 -0.75     0.      -0.25\n",
            "     0.125    0.75     0.75    -1.       0.3125  -0.1875   0.\n",
            "     0.15625  0.       0.3125  -0.75     0.75    -0.21875  0.\n",
            "    -0.625    0.875   -1.       0.      -0.625   -1.25    -0.5\n",
            "    -0.3125   0.875   -0.21875 -0.75    -0.1875 ]\n",
            "   [-0.75     0.1875  -0.625    0.5     -0.25     0.       0.4375\n",
            "     0.5      0.875    0.      -1.25    -1.       0.      -0.3125\n",
            "     0.15625  0.3125  -1.      -0.3125   0.375    0.       0.\n",
            "    -0.625    0.       0.125    0.21875 -0.3125  -0.21875  0.875\n",
            "     0.5      0.5      0.5      0.4375   0.      -0.4375   0.625\n",
            "    -0.3125  -0.5      0.      -0.875   -0.125  ]]]]\n",
            "[ 0.3125   0.625    0.       0.       0.       0.       0.3125   0.\n",
            " -0.25    -0.15625  0.       0.       0.       0.       0.4375   0.21875\n",
            "  0.       0.15625  0.      -0.3125   0.       0.      -0.15625  0.\n",
            "  0.875    0.       0.4375   0.       0.       0.       0.       0.625\n",
            "  0.15625  0.125    0.       0.       0.      -0.15625  0.      -0.25   ]\n",
            "[[[[-0.375  ]\n",
            "   [-0.125  ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.5    ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.15625]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.1875 ]\n",
            "   [-0.625  ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.75   ]\n",
            "   [-0.5    ]\n",
            "   [ 0.     ]\n",
            "   [ 0.21875]\n",
            "   [ 0.125  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.875  ]\n",
            "   [ 0.21875]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.15625]\n",
            "   [ 0.5    ]\n",
            "   [ 0.     ]\n",
            "   [ 0.375  ]\n",
            "   [-0.375  ]\n",
            "   [ 0.     ]\n",
            "   [-0.125  ]\n",
            "   [-0.375  ]]\n",
            "\n",
            "  [[-0.4375 ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.375  ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.15625]\n",
            "   [ 0.     ]\n",
            "   [-0.15625]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.125  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.75   ]\n",
            "   [ 0.     ]\n",
            "   [-0.5    ]\n",
            "   [ 0.     ]\n",
            "   [ 0.1875 ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.15625]\n",
            "   [ 0.     ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.21875]\n",
            "   [ 0.375  ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [-0.21875]\n",
            "   [-0.375  ]\n",
            "   [ 0.375  ]\n",
            "   [-0.5    ]\n",
            "   [-0.15625]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.375  ]\n",
            "   [ 0.     ]]\n",
            "\n",
            "  [[ 0.     ]\n",
            "   [ 0.5    ]\n",
            "   [-0.21875]\n",
            "   [-0.25   ]\n",
            "   [-0.1875 ]\n",
            "   [ 0.     ]\n",
            "   [-0.1875 ]\n",
            "   [-0.15625]\n",
            "   [ 0.21875]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.25   ]\n",
            "   [ 0.21875]\n",
            "   [ 0.25   ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.625  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.125  ]\n",
            "   [ 0.15625]\n",
            "   [ 0.     ]\n",
            "   [ 0.15625]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.875  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.875  ]\n",
            "   [ 0.     ]\n",
            "   [-0.1875 ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.5    ]\n",
            "   [ 0.     ]]]\n",
            "\n",
            "\n",
            " [[[ 1.     ]\n",
            "   [-0.15625]\n",
            "   [ 0.15625]\n",
            "   [-0.75   ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.25   ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.     ]\n",
            "   [-1.     ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.875  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.625  ]\n",
            "   [-0.375  ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.15625]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.5    ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.1875 ]\n",
            "   [-0.375  ]\n",
            "   [-0.875  ]\n",
            "   [ 0.625  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.875  ]\n",
            "   [-1.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.125  ]]\n",
            "\n",
            "  [[-0.1875 ]\n",
            "   [ 0.5    ]\n",
            "   [-0.5    ]\n",
            "   [-0.15625]\n",
            "   [ 0.     ]\n",
            "   [-0.21875]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.     ]\n",
            "   [-0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [-0.375  ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.21875]\n",
            "   [-0.5    ]\n",
            "   [ 1.     ]\n",
            "   [-0.875  ]\n",
            "   [ 0.1875 ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.1875 ]\n",
            "   [-0.25   ]\n",
            "   [-0.15625]\n",
            "   [-0.75   ]\n",
            "   [-0.5    ]\n",
            "   [-1.     ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.125  ]\n",
            "   [ 0.     ]]\n",
            "\n",
            "  [[-0.125  ]\n",
            "   [ 1.     ]\n",
            "   [-0.75   ]\n",
            "   [ 0.     ]\n",
            "   [-0.625  ]\n",
            "   [ 0.     ]\n",
            "   [-0.75   ]\n",
            "   [ 0.21875]\n",
            "   [ 0.625  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.     ]\n",
            "   [-0.875  ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.21875]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.21875]\n",
            "   [-0.15625]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.125  ]\n",
            "   [-0.25   ]\n",
            "   [ 0.     ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.875  ]\n",
            "   [-0.5    ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [-1.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.25   ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.1875 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.625  ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [-0.3125 ]\n",
            "   [ 1.25   ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 1.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.375  ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [-0.3125 ]\n",
            "   [-0.4375 ]\n",
            "   [-0.15625]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [-0.3125 ]\n",
            "   [-0.625  ]\n",
            "   [ 0.375  ]\n",
            "   [-0.4375 ]\n",
            "   [-0.625  ]\n",
            "   [-0.25   ]\n",
            "   [-0.21875]\n",
            "   [-0.5    ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-1.     ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.5    ]]\n",
            "\n",
            "  [[ 0.5    ]\n",
            "   [-0.15625]\n",
            "   [-0.3125 ]\n",
            "   [-0.5    ]\n",
            "   [ 0.625  ]\n",
            "   [-0.5    ]\n",
            "   [-0.25   ]\n",
            "   [ 0.75   ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.75   ]\n",
            "   [ 0.125  ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.125  ]\n",
            "   [ 0.875  ]\n",
            "   [ 0.25   ]\n",
            "   [-0.15625]\n",
            "   [ 0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.75   ]\n",
            "   [-0.375  ]\n",
            "   [ 0.5    ]\n",
            "   [-0.75   ]\n",
            "   [-0.5    ]\n",
            "   [-0.625  ]\n",
            "   [ 0.     ]\n",
            "   [-0.5    ]\n",
            "   [-0.15625]\n",
            "   [-0.75   ]\n",
            "   [-0.75   ]\n",
            "   [ 0.     ]\n",
            "   [-0.375  ]\n",
            "   [ 0.     ]\n",
            "   [-0.625  ]\n",
            "   [-0.5    ]\n",
            "   [-0.1875 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.625  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.625  ]]\n",
            "\n",
            "  [[ 0.15625]\n",
            "   [-0.3125 ]\n",
            "   [-0.25   ]\n",
            "   [ 0.     ]\n",
            "   [ 0.5    ]\n",
            "   [-0.4375 ]\n",
            "   [-0.375  ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.625  ]\n",
            "   [-0.125  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.625  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.21875]\n",
            "   [ 0.5    ]\n",
            "   [-0.375  ]\n",
            "   [ 0.25   ]\n",
            "   [-0.125  ]\n",
            "   [-0.625  ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.5    ]\n",
            "   [-0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.21875]\n",
            "   [-0.15625]\n",
            "   [ 0.     ]\n",
            "   [ 0.15625]\n",
            "   [-0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.125  ]\n",
            "   [-0.15625]\n",
            "   [ 0.     ]\n",
            "   [ 0.625  ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.4375 ]]]]\n",
            "[[[[ 0.375    0.      -0.875   ...  0.4375  -1.       0.     ]\n",
            "   [-0.4375   0.       0.      ...  0.5      0.       0.5    ]\n",
            "   [ 0.5     -0.75     0.25    ...  0.      -0.25     0.5    ]\n",
            "   ...\n",
            "   [ 0.      -0.625    0.21875 ...  0.5      0.15625 -0.4375 ]\n",
            "   [ 0.3125  -0.75    -0.375   ... -0.625   -0.25     0.     ]\n",
            "   [ 0.3125  -0.625    0.625   ...  0.625   -0.375    0.     ]]]]\n",
            "[-1.25     1.25    -1.25     1.5      0.375   -0.875   -0.875   -1.\n",
            " -0.4375   0.3125  -1.       1.25    -1.5     -1.5      0.75    -1.75\n",
            " -0.875    1.       1.      -0.4375  -0.3125   0.      -0.3125   0.\n",
            " -1.      -1.       0.       3.      -1.25    -0.375   -0.4375   1.25\n",
            " -1.25    -1.      -1.25    -0.75     1.25    -0.75    -0.75    -1.75\n",
            "  1.       0.75     0.       0.25    -0.3125  -0.875   -1.25    -1.25\n",
            " -0.4375  -0.75    -0.75     1.      -0.21875 -1.5      0.25     0.21875\n",
            " -2.      -0.875   -0.625    0.625  ]\n",
            "[[[[ 0.125  ]\n",
            "   [ 0.     ]\n",
            "   [-0.1875 ]\n",
            "   [-0.125  ]\n",
            "   [-0.625  ]\n",
            "   [ 0.     ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.15625]\n",
            "   [-0.25   ]\n",
            "   [ 0.15625]\n",
            "   [ 0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.25   ]\n",
            "   [-0.5    ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.21875]\n",
            "   [-0.21875]\n",
            "   [-0.5    ]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.75   ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.     ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.15625]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [-0.1875 ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.15625]\n",
            "   [ 0.     ]\n",
            "   [ 0.15625]\n",
            "   [ 0.15625]\n",
            "   [ 0.     ]\n",
            "   [ 0.125  ]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.125  ]\n",
            "   [ 0.     ]\n",
            "   [-0.15625]\n",
            "   [ 0.     ]\n",
            "   [-0.375  ]\n",
            "   [ 0.     ]\n",
            "   [-0.125  ]\n",
            "   [ 0.15625]\n",
            "   [ 0.     ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [-0.375  ]\n",
            "   [ 0.21875]\n",
            "   [ 0.     ]\n",
            "   [-0.21875]\n",
            "   [-0.625  ]]\n",
            "\n",
            "  [[ 0.15625]\n",
            "   [ 0.375  ]\n",
            "   [-0.1875 ]\n",
            "   [-0.625  ]\n",
            "   [-0.625  ]\n",
            "   [-0.3125 ]\n",
            "   [-0.375  ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.125  ]\n",
            "   [-0.625  ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.25   ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.     ]\n",
            "   [-0.625  ]\n",
            "   [ 0.5    ]\n",
            "   [-0.15625]\n",
            "   [-0.25   ]\n",
            "   [ 0.21875]\n",
            "   [-0.125  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.375  ]\n",
            "   [ 0.     ]\n",
            "   [-0.75   ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.1875 ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.25   ]\n",
            "   [ 0.21875]\n",
            "   [ 0.     ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.15625]\n",
            "   [ 0.625  ]\n",
            "   [-0.21875]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.25   ]\n",
            "   [-0.3125 ]\n",
            "   [-0.25   ]\n",
            "   [ 0.     ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.625  ]\n",
            "   [-0.625  ]\n",
            "   [-0.5    ]\n",
            "   [ 0.     ]\n",
            "   [-0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.15625]\n",
            "   [ 0.     ]\n",
            "   [-0.5    ]]\n",
            "\n",
            "  [[ 0.     ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.21875]\n",
            "   [-0.625  ]\n",
            "   [-0.4375 ]\n",
            "   [-0.625  ]\n",
            "   [-0.25   ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.     ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [-0.375  ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.25   ]\n",
            "   [-0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [-0.5    ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.1875 ]\n",
            "   [ 0.15625]\n",
            "   [-0.1875 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.25   ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.     ]\n",
            "   [ 0.21875]\n",
            "   [-0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.125  ]\n",
            "   [-0.21875]\n",
            "   [ 0.     ]\n",
            "   [ 0.15625]\n",
            "   [-0.5    ]\n",
            "   [ 0.1875 ]\n",
            "   [-0.875  ]\n",
            "   [-0.3125 ]\n",
            "   [-0.25   ]\n",
            "   [-0.15625]\n",
            "   [ 0.25   ]\n",
            "   [-0.5    ]\n",
            "   [ 0.     ]\n",
            "   [-0.4375 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.375  ]\n",
            "   [ 0.     ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.21875]\n",
            "   [-0.125  ]\n",
            "   [-0.3125 ]\n",
            "   [-0.25   ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.625  ]\n",
            "   [ 0.5    ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.5    ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.15625]\n",
            "   [ 0.75   ]\n",
            "   [ 1.25   ]\n",
            "   [ 0.     ]\n",
            "   [-0.75   ]\n",
            "   [-0.25   ]\n",
            "   [ 0.625  ]\n",
            "   [-0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.25   ]\n",
            "   [ 0.625  ]\n",
            "   [-0.625  ]\n",
            "   [ 0.75   ]\n",
            "   [ 1.     ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.5    ]\n",
            "   [-0.25   ]\n",
            "   [ 0.75   ]\n",
            "   [-0.625  ]\n",
            "   [ 0.375  ]\n",
            "   [-0.375  ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.1875 ]\n",
            "   [-0.625  ]\n",
            "   [ 0.     ]\n",
            "   [-0.15625]\n",
            "   [ 0.25   ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.25   ]\n",
            "   [-0.1875 ]\n",
            "   [-0.75   ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [-0.375  ]\n",
            "   [ 0.875  ]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.625  ]\n",
            "   [-0.625  ]\n",
            "   [-0.3125 ]]\n",
            "\n",
            "  [[ 0.625  ]\n",
            "   [ 0.875  ]\n",
            "   [-0.625  ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [-0.375  ]\n",
            "   [-0.3125 ]\n",
            "   [-0.5    ]\n",
            "   [ 0.5    ]\n",
            "   [-0.75   ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.625  ]\n",
            "   [-1.     ]\n",
            "   [ 0.625  ]\n",
            "   [-0.625  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.     ]\n",
            "   [-0.5    ]\n",
            "   [-1.25   ]\n",
            "   [ 0.75   ]\n",
            "   [-0.875  ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.21875]\n",
            "   [ 0.5    ]\n",
            "   [-0.75   ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.     ]\n",
            "   [ 0.625  ]\n",
            "   [-0.625  ]\n",
            "   [-0.5    ]\n",
            "   [ 0.625  ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.625  ]\n",
            "   [-0.625  ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.5    ]\n",
            "   [-0.375  ]\n",
            "   [ 0.625  ]\n",
            "   [ 0.625  ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.5    ]\n",
            "   [-0.625  ]\n",
            "   [-1.     ]\n",
            "   [-0.75   ]\n",
            "   [ 0.625  ]\n",
            "   [-0.25   ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.5    ]\n",
            "   [ 0.625  ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.625  ]\n",
            "   [ 0.     ]]\n",
            "\n",
            "  [[ 0.375  ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.3125 ]\n",
            "   [-0.375  ]\n",
            "   [ 0.     ]\n",
            "   [-0.875  ]\n",
            "   [-0.25   ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.875  ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.375  ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.     ]\n",
            "   [-0.625  ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.875  ]\n",
            "   [-0.125  ]\n",
            "   [-0.1875 ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.1875 ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.3125 ]\n",
            "   [-0.1875 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.15625]\n",
            "   [ 0.4375 ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.625  ]\n",
            "   [ 0.75   ]\n",
            "   [-0.875  ]\n",
            "   [-0.875  ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.375  ]\n",
            "   [ 0.5    ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [-0.5    ]\n",
            "   [-0.5    ]\n",
            "   [ 0.625  ]\n",
            "   [-0.625  ]\n",
            "   [-0.3125 ]\n",
            "   [-0.125  ]\n",
            "   [-0.625  ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.21875]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]]]\n",
            "\n",
            "\n",
            " [[[ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [-0.5    ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [-0.375  ]\n",
            "   [-0.375  ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.25   ]\n",
            "   [-0.21875]\n",
            "   [ 0.     ]\n",
            "   [ 0.21875]\n",
            "   [ 0.15625]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.5    ]\n",
            "   [-0.75   ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.1875 ]\n",
            "   [-0.375  ]\n",
            "   [ 0.     ]\n",
            "   [ 0.5    ]\n",
            "   [-0.5    ]\n",
            "   [ 0.21875]\n",
            "   [ 0.     ]\n",
            "   [ 0.375  ]\n",
            "   [-0.15625]\n",
            "   [ 0.25   ]\n",
            "   [ 0.75   ]\n",
            "   [ 0.     ]\n",
            "   [-0.375  ]\n",
            "   [-0.5    ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.75   ]\n",
            "   [ 0.     ]\n",
            "   [-0.1875 ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.25   ]\n",
            "   [-0.25   ]\n",
            "   [ 0.     ]\n",
            "   [-0.1875 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.25   ]\n",
            "   [ 0.     ]\n",
            "   [-0.15625]\n",
            "   [-0.21875]\n",
            "   [-0.15625]\n",
            "   [-0.5    ]\n",
            "   [ 0.1875 ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.75   ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.5    ]\n",
            "   [ 0.25   ]]\n",
            "\n",
            "  [[ 0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.625  ]\n",
            "   [ 0.     ]\n",
            "   [-0.625  ]\n",
            "   [-0.375  ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.     ]\n",
            "   [ 0.15625]\n",
            "   [-0.4375 ]\n",
            "   [ 0.1875 ]\n",
            "   [-0.75   ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.21875]\n",
            "   [-0.15625]\n",
            "   [-0.21875]\n",
            "   [-0.1875 ]\n",
            "   [ 0.5    ]\n",
            "   [-0.3125 ]\n",
            "   [ 0.625  ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.4375 ]\n",
            "   [-0.5    ]\n",
            "   [-0.625  ]\n",
            "   [ 0.25   ]\n",
            "   [-0.75   ]\n",
            "   [ 0.25   ]\n",
            "   [-0.375  ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [-0.125  ]\n",
            "   [-0.375  ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.625  ]\n",
            "   [ 0.5    ]\n",
            "   [-0.5    ]\n",
            "   [ 0.     ]\n",
            "   [-0.375  ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.15625]\n",
            "   [-0.1875 ]\n",
            "   [ 0.15625]\n",
            "   [ 0.375  ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.375  ]\n",
            "   [-0.75   ]\n",
            "   [ 0.5    ]]\n",
            "\n",
            "  [[ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.15625]\n",
            "   [ 0.4375 ]\n",
            "   [-0.21875]\n",
            "   [-0.1875 ]\n",
            "   [-0.25   ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.1875 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.3125 ]\n",
            "   [-0.25   ]\n",
            "   [-0.5    ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [-0.625  ]\n",
            "   [ 0.21875]\n",
            "   [ 0.21875]\n",
            "   [ 0.4375 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.5    ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.15625]\n",
            "   [-0.15625]\n",
            "   [ 0.4375 ]\n",
            "   [-0.15625]\n",
            "   [-0.15625]\n",
            "   [-0.25   ]\n",
            "   [ 0.     ]\n",
            "   [ 0.125  ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.15625]\n",
            "   [ 0.875  ]\n",
            "   [ 0.625  ]\n",
            "   [-0.4375 ]\n",
            "   [-0.75   ]\n",
            "   [ 0.21875]\n",
            "   [ 0.375  ]\n",
            "   [ 0.375  ]\n",
            "   [-0.4375 ]\n",
            "   [ 0.21875]\n",
            "   [ 0.     ]\n",
            "   [-0.125  ]\n",
            "   [ 0.15625]\n",
            "   [-0.15625]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.3125 ]\n",
            "   [ 0.     ]\n",
            "   [ 0.     ]\n",
            "   [ 0.25   ]]]]\n",
            "[[[[-0.1875  -0.15625 -0.5     ... -0.375    0.3125   0.     ]\n",
            "   [-0.4375   0.       0.375   ...  0.21875  0.       0.     ]\n",
            "   [ 0.21875 -0.3125   0.3125  ...  0.15625 -0.625    0.21875]\n",
            "   ...\n",
            "   [ 0.      -0.1875  -0.3125  ... -0.3125  -0.15625 -1.5    ]\n",
            "   [ 0.875    0.375   -0.25    ...  0.5      0.       0.     ]\n",
            "   [-0.4375  -0.25     1.      ...  0.15625 -0.1875  -0.25   ]]]]\n",
            "[-1.75    -1.75    -1.25    -0.875   -1.25    -1.25     0.875   -1.5\n",
            " -1.25     0.      -2.      -2.5     -0.25    -0.625   -0.3125  -1.25\n",
            "  0.625    0.75    -1.75     0.75    -1.75    -1.25     0.      -0.75\n",
            "  0.375   -1.25    -1.      -2.       0.      -3.      -4.      -2.5\n",
            " -0.625   -0.875   -1.      -1.75    -1.5     -2.5     -1.25    -0.625\n",
            " -1.5     -1.25    -1.25    -2.       0.75     0.4375   0.625    0.\n",
            " -0.375   -0.5     -1.5      2.      -0.75    -0.125    0.      -1.75\n",
            " -1.25     0.      -1.25     0.375   -2.      -0.5     -1.5     -1.5\n",
            " -0.625    0.25    -1.75    -1.25    -1.5     -1.5     -0.125   -0.875\n",
            "  0.      -2.5     -2.      -2.       0.      -2.      -1.25    -0.4375\n",
            " -0.5     -0.375   -0.4375  -1.75     0.25     0.875    0.4375  -0.5\n",
            " -0.3125  -0.375    0.      -1.5     -1.5     -0.5     -1.75    -1.25\n",
            " -0.5     -3.       0.875   -2.       0.1875  -0.875    0.      -1.5\n",
            " -2.       0.875   -1.      -1.      -0.15625 -1.75    -0.25     0.875\n",
            " -1.      -0.375   -0.625   -0.375   -2.5     -0.75     1.75    -0.875  ]\n",
            "> 40.240\n"
          ]
        }
      ],
      "source": [
        "print_model (model)\n",
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GmFfu4r-dFdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "separable_conv2d (SeparableC (None, 32, 32, 40)        187       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 40)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 40)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 40)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_1 (Separabl (None, 16, 16, 60)        2820      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 60)        240       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 60)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 60)          0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_2 (Separabl (None, 8, 8, 120)         7860      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 120)         480       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 120)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 120)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               230520    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1210      \n",
            "=================================================================\n",
            "Total params: 243,477\n",
            "Trainable params: 243,037\n",
            "Non-trainable params: 440\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /home/yarib/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /home/yarib/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-12 01:46:36.796048: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp5n017j_l/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-12 01:46:44.706374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-12 01:46:44.716559: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2021-11-12 01:46:44.733558: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-11-12 01:46:44.947134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-12 01:46:44.953471: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563d716398c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-12 01:46:44.953511: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 860M, Compute Capability 5.0\n",
            "2021-11-12 01:46:44.956240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-12 01:46:44.957026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-12 01:46:45.058831: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:45.066374: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:45.066501: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-12 01:46:45.066557: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-12 01:46:45.073292: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:45.073494: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:45.079076: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:45.079107: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-12 01:46:45.079151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-12 01:46:45.079162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-11-12 01:46:45.079177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2021-11-12 01:46:45.149235: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2021-11-12 01:46:45.149283: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 1.196ms.\n",
            "2021-11-12 01:46:45.149295: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.003ms.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-12 01:46:45.461392: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\n",
            "2021-11-12 01:46:45.461449: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\n",
            "2021-11-12 01:46:45.556964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-12 01:46:45.558010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-12 01:46:45.558311: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:45.558690: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:45.558785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-12 01:46:45.558852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-12 01:46:45.558972: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:45.559094: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:45.559214: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:45.559229: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-12 01:46:45.559255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-12 01:46:45.559265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-11-12 01:46:45.559273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, utils\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "  print(\"Folder \" + filename + \" does not exist.\")\n",
        "  exit()\n",
        "\n",
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "model = tf.keras.models.load_model(filename + \"/\" + filename + '.h5')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(model, filename + \"/\" + filename + \".png\", show_shapes=True, show_layer_names=True, expand_nested=True)\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255 , test_images / 255\n",
        "\n",
        "train_images = tf.cast(train_images, tf.float32)\n",
        "cifar_ds = tf.data.Dataset.from_tensor_slices((train_images)).batch(1)\n",
        "def representative_dataset():\n",
        "  for input_value in cifar_ds.take(100):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "#converter.representative_dataset = representative_dataset\n",
        "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.float32  # or tf.uint8\n",
        "converter.inference_output_type = tf.float32  # or tf.uint8\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open(filename + \"/\" + filename + \"_f32\" + '.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "INb151fxeI6B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpok_ev0an/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpok_ev0an/assets\n",
            "2021-11-12 01:46:56.350979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-12 01:46:56.351668: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2021-11-12 01:46:56.351777: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-11-12 01:46:56.352611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-12 01:46:56.353273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\n",
            "coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
            "2021-11-12 01:46:56.353403: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:56.353489: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:56.353523: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-12 01:46:56.353545: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-12 01:46:56.353603: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:56.353665: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:56.353727: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-11-12 01:46:56.353736: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-11-12 01:46:56.353750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-12 01:46:56.353756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-11-12 01:46:56.353761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2021-11-12 01:46:56.356921: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2021-11-12 01:46:56.356950: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
            "2021-11-12 01:46:56.356956: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
            "2021-11-12 01:46:56.459029: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\n",
            "2021-11-12 01:46:56.459077: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.float32  # or tf.uint8\n",
        "converter.inference_output_type = tf.float32  # or tf.uint8\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open(filename + \"/\" + filename + \"_i8\" + '.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pZ4KikJ-fkaU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=filename + \"/\" + filename + \"_i8\" + '.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TpXHwv2Tf3yI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Lite Predicted: [[0.0078125  0.0078125  0.09375    0.13671875 0.1796875  0.15625\n",
            "  0.33984375 0.05078125 0.015625   0.0078125 ]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], x)\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print('TensorFlow Lite Predicted:', output_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "quantized_training.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3ba63467901cd6d3991f497c38810e6d1156dd2dfb6eb0edc80f01dd9606bacd"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
